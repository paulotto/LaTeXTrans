@inproceedings{codevilla2018end,
  title={End-to-end driving via conditional imitation learning},
  author={Codevilla, Felipe and M{\"u}ller, Matthias and L{\'o}pez, Antonio and Koltun, Vladlen and Dosovitskiy, Alexey},
  booktitle={2018 IEEE international conference on robotics and automation (ICRA)},
  pages={4693--4700},
  year={2018},
  organization={IEEE}
}
@inproceedings{codevilla2019exploring,
  title={Exploring the limitations of behavior cloning for autonomous driving},
  author={Codevilla, Felipe and Santana, Eder and L{\'o}pez, Antonio M and Gaidon, Adrien},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={9329--9338},
  year={2019}
}
@article{pomerleau1988alvinn,
  title={Alvinn: An autonomous land vehicle in a neural network},
  author={Pomerleau, Dean A},
  journal={Advances in neural information processing systems},
  volume={1},
  year={1988}
}
@inproceedings{prakash2021multi,
  title={Multi-modal fusion transformer for end-to-end autonomous driving},
  author={Prakash, Aditya and Chitta, Kashyap and Geiger, Andreas},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={7077--7087},
  year={2021}
}
@inproceedings{cui2021lookout,
  title={Lookout: Diverse multi-future prediction and planning for self-driving},
  author={Cui, Alexander and Casas, Sergio and Sadat, Abbas and Liao, Renjie and Urtasun, Raquel},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={16107--16116},
  year={2021}
}
@inproceedings{sadat2020perceive,
  title={Perceive, predict, and plan: Safe motion planning through interpretable semantic representations},
  author={Sadat, Abbas and Casas, Sergio and Ren, Mengye and Wu, Xinyu and Dhawan, Pranaab and Urtasun, Raquel},
  booktitle={Computer Vision--ECCV 2020: 16th European Conference, Glasgow, UK, August 23--28, 2020, Proceedings, Part XXIII 16},
  pages={414--430},
  year={2020},
  organization={Springer}
}

@inproceedings{lss,
  title={Lift, splat, shoot: Encoding images from arbitrary camera rigs by implicitly unprojecting to 3d},
  author={Philion, Jonah and Fidler, Sanja},
  booktitle={Computer Vision--ECCV 2020: 16th European Conference, Glasgow, UK, August 23--28, 2020, Proceedings, Part XIV 16},
  pages={194--210},
  year={2020},
  organization={Springer}
}
@article{bevdet,
  title={Bevdet: High-performance multi-camera 3d object detection in bird-eye-view},
  author={Huang, Junjie and Huang, Guan and Zhu, Zheng and Ye, Yun and Du, Dalong},
  journal={arXiv preprint arXiv:2112.11790},
  year={2021}
}
@article{bevdet4d,
  title={Bevdet4d: Exploit temporal cues in multi-camera 3d object detection},
  author={Huang, Junjie and Huang, Guan},
  journal={arXiv preprint arXiv:2203.17054},
  year={2022}
}
@inproceedings{bevdepth,
  title={Bevdepth: Acquisition of reliable depth for multi-view 3d object detection},
  author={Li, Yinhao and Ge, Zheng and Yu, Guanyi and Yang, Jinrong and Wang, Zengran and Shi, Yukang and Sun, Jianjian and Li, Zeming},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={37},
  number={2},
  pages={1477--1485},
  year={2023}
}
@inproceedings{bevstereo,
  title={Bevstereo: Enhancing depth estimation in multi-view 3d object detection with temporal stereo},
  author={Li, Yinhao and Bao, Han and Ge, Zheng and Yang, Jinrong and Sun, Jianjian and Li, Zeming},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={37},
  number={2},
  pages={1486--1494},
  year={2023}
}
@inproceedings{bevfusion,
  title={Bevfusion: Multi-task multi-sensor fusion with unified bird's-eye view representation},
  author={Liu, Zhijian and Tang, Haotian and Amini, Alexander and Yang, Xinyu and Mao, Huizi and Rus, Daniela L and Han, Song},
  booktitle={2023 IEEE international conference on robotics and automation (ICRA)},
  pages={2774--2781},
  year={2023},
  organization={IEEE}
}
@article{bevpoolv2,
  title={Bevpoolv2: A cutting-edge implementation of bevdet toward deployment},
  author={Huang, Junjie and Huang, Guan},
  journal={arXiv preprint arXiv:2211.17111},
  year={2022}
}
@inproceedings{bevformer,
  title={Bevformer: Learning birdâ€™s-eye-view representation from multi-camera images via spatiotemporal transformers},
  author={Li, Zhiqi and Wang, Wenhai and Li, Hongyang and Xie, Enze and Sima, Chonghao and Lu, Tong and Qiao, Yu and Dai, Jifeng},
  booktitle={European conference on computer vision},
  pages={1--18},
  year={2022},
  organization={Springer}
}
@inproceedings{bevformerv2,
  title={BEVFormer v2: Adapting modern image backbones to bird's-eye-view recognition via perspective supervision},
  author={Yang, Chenyu and Chen, Yuntao and Tian, Hao and Tao, Chenxin and Zhu, Xizhou and Zhang, Zhaoxiang and Huang, Gao and Li, Hongyang and Qiao, Yu and Lu, Lewei and others},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={17830--17839},
  year={2023}
}
@inproceedings{polarformer,
  title={Polarformer: Multi-camera 3d object detection with polar transformer},
  author={Jiang, Yanqin and Zhang, Li and Miao, Zhenwei and Zhu, Xiatian and Gao, Jin and Hu, Weiming and Jiang, Yu-Gang},
  booktitle={Proceedings of the AAAI conference on Artificial Intelligence},
  volume={37},
  number={1},
  pages={1042--1050},
  year={2023}
}
@article{gkt,
  title={Efficient and robust 2d-to-bev representation learning via geometry-guided kernel transformer},
  author={Chen, Shaoyu and Cheng, Tianheng and Wang, Xinggang and Meng, Wenming and Zhang, Qian and Liu, Wenyu},
  journal={arXiv preprint arXiv:2206.04584},
  year={2022}
}
@inproceedings{petr,
  title={Petr: Position embedding transformation for multi-view 3d object detection},
  author={Liu, Yingfei and Wang, Tiancai and Zhang, Xiangyu and Sun, Jian},
  booktitle={European Conference on Computer Vision},
  pages={531--548},
  year={2022},
  organization={Springer}
}
@inproceedings{petrv2,
  title={Petrv2: A unified framework for 3d perception from multi-camera images},
  author={Liu, Yingfei and Yan, Junjie and Jia, Fan and Li, Shuailin and Gao, Aqi and Wang, Tiancai and Zhang, Xiangyu},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={3262--3272},
  year={2023}
}
@inproceedings{streampetr,
  title={Exploring object-centric temporal modeling for efficient multi-view 3d object detection},
  author={Wang, Shihao and Liu, Yingfei and Wang, Tiancai and Li, Ying and Zhang, Xiangyu},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={3621--3631},
  year={2023}
}
@article{sparse4d,
  title={Sparse4d: Multi-view 3d object detection with sparse spatial-temporal fusion},
  author={Lin, Xuewu and Lin, Tianwei and Pei, Zixiang and Huang, Lichao and Su, Zhizhong},
  journal={arXiv preprint arXiv:2211.10581},
  year={2022}
}
@article{sparse4dv2,
  title={Sparse4d v2: Recurrent temporal fusion with sparse model},
  author={Lin, Xuewu and Lin, Tianwei and Pei, Zixiang and Huang, Lichao and Su, Zhizhong},
  journal={arXiv preprint arXiv:2305.14018},
  year={2023}
}
@article{sparse4dv3,
  title={Sparse4d v3: Advancing end-to-end 3d detection and tracking},
  author={Lin, Xuewu and Pei, Zixiang and Lin, Tianwei and Huang, Lichao and Su, Zhizhong},
  journal={arXiv preprint arXiv:2311.11722},
  year={2023}
}
@inproceedings{motr,
  title={Motr: End-to-end multiple-object tracking with transformer},
  author={Zeng, Fangao and Dong, Bin and Zhang, Yuang and Wang, Tiancai and Zhang, Xiangyu and Wei, Yichen},
  booktitle={European Conference on Computer Vision},
  pages={659--675},
  year={2022},
  organization={Springer}
}
@inproceedings{motrv2,
  title={Motrv2: Bootstrapping end-to-end multi-object tracking by pretrained object detectors},
  author={Zhang, Yuang and Wang, Tiancai and Zhang, Xiangyu},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={22056--22065},
  year={2023}
}
@article{motrv3,
  title={Motrv3: Release-fetch supervision for end-to-end multi-object tracking},
  author={Yu, En and Wang, Tiancai and Li, Zhuoling and Zhang, Yuang and Zhang, Xiangyu and Tao, Wenbing},
  journal={arXiv preprint arXiv:2305.14298},
  year={2023}
}
@inproceedings{trackformer,
  title={Trackformer: Multi-object tracking with transformers},
  author={Meinhardt, Tim and Kirillov, Alexander and Leal-Taixe, Laura and Feichtenhofer, Christoph},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={8844--8854},
  year={2022}
}
@article{transtrack,
  title={Transtrack: Multiple object tracking with transformer},
  author={Sun, Peize and Cao, Jinkun and Jiang, Yi and Zhang, Rufeng and Xie, Enze and Yuan, Zehuan and Wang, Changhu and Luo, Ping},
  journal={arXiv preprint arXiv:2012.15460},
  year={2020}
}
@inproceedings{detr,
  title={End-to-end object detection with transformers},
  author={Carion, Nicolas and Massa, Francisco and Synnaeve, Gabriel and Usunier, Nicolas and Kirillov, Alexander and Zagoruyko, Sergey},
  booktitle={European conference on computer vision},
  pages={213--229},
  year={2020},
  organization={Springer}
}
@inproceedings{mutr3d,
  title={Mutr3d: A multi-camera tracking framework via 3d-to-2d queries},
  author={Zhang, Tianyuan and Chen, Xuanyao and Wang, Yue and Wang, Yilun and Zhao, Hang},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={4537--4546},
  year={2022}
}
@inproceedings{hdmapnet,
  title={Hdmapnet: An online hd map construction and evaluation framework},
  author={Li, Qi and Wang, Yue and Wang, Yilun and Zhao, Hang},
  booktitle={2022 International Conference on Robotics and Automation (ICRA)},
  pages={4628--4634},
  year={2022},
  organization={IEEE}
}
@inproceedings{vectormapnet,
  title={Vectormapnet: End-to-end vectorized hd map learning},
  author={Liu, Yicheng and Yuan, Tianyuan and Wang, Yue and Wang, Yilun and Zhao, Hang},
  booktitle={International Conference on Machine Learning},
  pages={22352--22369},
  year={2023},
  organization={PMLR}
}
@inproceedings{maptr,
  title={MapTR: Structured Modeling and Learning for Online Vectorized HD Map Construction},
  author={Liao, Bencheng and Chen, Shaoyu and Wang, Xinggang and Cheng, Tianheng and Zhang, Qian and Liu, Wenyu and Huang, Chang},
  booktitle={The Eleventh International Conference on Learning Representations},
  year={2022}
}
@inproceedings{bemapnet,
  title={End-to-end vectorized hd-map construction with piecewise bezier curve},
  author={Qiao, Limeng and Ding, Wenjie and Qiu, Xi and Zhang, Chi},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={13218--13228},
  year={2023}
}
@inproceedings{streammapnet,
  title={Streammapnet: Streaming mapping network for vectorized online hd map construction},
  author={Yuan, Tianyuan and Liu, Yicheng and Wang, Yue and Wang, Yilun and Zhao, Hang},
  booktitle={Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision},
  pages={7356--7365},
  year={2024}
}
@inproceedings{faf,
  title={Fast and furious: Real time end-to-end 3d detection, tracking and motion forecasting with a single convolutional net},
  author={Luo, Wenjie and Yang, Bin and Urtasun, Raquel},
  booktitle={Proceedings of the IEEE conference on Computer Vision and Pattern Recognition},
  pages={3569--3577},
  year={2018}
}
@inproceedings{intentnet,
  title={Intentnet: Learning to predict intention from raw sensor data},
  author={Casas, Sergio and Luo, Wenjie and Urtasun, Raquel},
  booktitle={Conference on Robot Learning},
  pages={947--956},
  year={2018},
  organization={PMLR}
}
@inproceedings{pnpnet,
  title={Pnpnet: End-to-end perception and prediction with tracking in the loop},
  author={Liang, Ming and Yang, Bin and Zeng, Wenyuan and Chen, Yun and Hu, Rui and Casas, Sergio and Urtasun, Raquel},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={11553--11562},
  year={2020}
}
@inproceedings{vip3d,
  title={Vip3d: End-to-end visual trajectory prediction via 3d agent queries},
  author={Gu, Junru and Hu, Chenxu and Zhang, Tianyuan and Chen, Xuanyao and Wang, Yilun and Wang, Yue and Zhao, Hang},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={5496--5506},
  year={2023}
}
@article{pip,
  title={Perceive, interact, predict: Learning dynamic and static clues for end-to-end motion prediction},
  author={Jiang, Bo and Chen, Shaoyu and Wang, Xinggang and Liao, Bencheng and Cheng, Tianheng and Chen, Jiajie and Zhou, Helong and Zhang, Qian and Liu, Wenyu and Huang, Chang},
  journal={arXiv preprint arXiv:2212.02181},
  year={2022}
}
@inproceedings{mp3,
  title={Mp3: A unified model to map, perceive, predict and plan},
  author={Casas, Sergio and Sadat, Abbas and Urtasun, Raquel},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={14403--14412},
  year={2021}
}
@inproceedings{stp3,
  title={St-p3: End-to-end vision-based autonomous driving via spatial-temporal feature learning},
  author={Hu, Shengchao and Chen, Li and Wu, Penghao and Li, Hongyang and Yan, Junchi and Tao, Dacheng},
  booktitle={European Conference on Computer Vision},
  pages={533--549},
  year={2022},
  organization={Springer}
}
@inproceedings{uniad,
  title={Planning-oriented autonomous driving},
  author={Hu, Yihan and Yang, Jiazhi and Chen, Li and Li, Keyu and Sima, Chonghao and Zhu, Xizhou and Chai, Siqi and Du, Senyao and Lin, Tianwei and Wang, Wenhai and others},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={17853--17862},
  year={2023}
}
@inproceedings{vad,
  title={Vad: Vectorized scene representation for efficient autonomous driving},
  author={Jiang, Bo and Chen, Shaoyu and Xu, Qing and Liao, Bencheng and Chen, Jiajie and Zhou, Helong and Zhang, Qian and Liu, Wenyu and Huang, Chang and Wang, Xinggang},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={8340--8350},
  year={2023}
}
@inproceedings{nuscenes,
  title={nuscenes: A multimodal dataset for autonomous driving},
  author={Caesar, Holger and Bankiti, Varun and Lang, Alex H and Vora, Sourabh and Liong, Venice Erin and Xu, Qiang and Krishnan, Anush and Pan, Yu and Baldan, Giancarlo and Beijbom, Oscar},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={11621--11631},
  year={2020}
}
@article{qd3dt,
  title={Monocular quasi-dense 3d object tracking},
  author={Hu, Hou-Ning and Yang, Yung-Hsu and Fischer, Tobias and Darrell, Trevor and Yu, Fisher and Sun, Min},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume={45},
  number={2},
  pages={1992--2008},
  year={2022},
  publisher={IEEE}
}
@inproceedings{ff,
  title={Safe local motion planning with self-supervised freespace forecasting},
  author={Hu, Peiyun and Huang, Aaron and Dolan, John and Held, David and Ramanan, Deva},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={12732--12741},
  year={2021}
}
@inproceedings{eo,
  title={Differentiable raycasting for self-supervised occupancy forecasting},
  author={Khurana, Tarasha and Hu, Peiyun and Dave, Achal and Ziglar, Jason and Held, David and Ramanan, Deva},
  booktitle={European Conference on Computer Vision},
  pages={353--369},
  year={2022},
  organization={Springer}
}
@inproceedings{resnet,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}
@article{ego,
  title={Is Ego Status All You Need for Open-Loop End-to-End Autonomous Driving?},
  author={Li, Zhiqi and Yu, Zhiding and Lan, Shiyi and Li, Jiahan and Kautz, Jan and Lu, Tong and Alvarez, Jose M},
  journal={arXiv preprint arXiv:2312.03031},
  year={2023}
}
@article{admlp,
  title={Rethinking the open-loop evaluation of end-to-end autonomous driving in nuscenes},
  author={Zhai, Jiang-Tian and Feng, Ze and Du, Jinhao and Mao, Yongqiang and Liu, Jiang-Jiang and Tan, Zichang and Zhang, Yifu and Ye, Xiaoqing and Wang, Jingdong},
  journal={arXiv preprint arXiv:2305.10430},
  year={2023}
}
@article{adamw,
  title={Decoupled weight decay regularization},
  author={Loshchilov, Ilya and Hutter, Frank},
  journal={arXiv preprint arXiv:1711.05101},
  year={2017}
}
@article{cosine,
  title={Sgdr: Stochastic gradient descent with warm restarts},
  author={Loshchilov, Ilya and Hutter, Frank},
  journal={arXiv preprint arXiv:1608.03983},
  year={2016}
}
@article{graphad,
  title={GraphAD: Interaction Scene Graph for End-to-end Autonomous Driving},
  author={Zhang, Yunpeng and Qian, Deheng and Li, Ding and Pan, Yifeng and Chen, Yong and Liang, Zhenbao and Zhang, Zhiyao and Zhang, Shurui and Li, Hongxu and Fu, Maolei and others},
  journal={arXiv preprint arXiv:2403.19098},
  year={2024}
}
@article{fusionad,
  title={Fusionad: Multi-modality fusion for prediction and planning tasks of autonomous driving},
  author={Ye, Tengju and Jing, Wei and Hu, Chunyong and Huang, Shikun and Gao, Lingping and Li, Fangzhen and Wang, Jingke and Guo, Ke and Xiao, Wencong and Mao, Weibo and others},
  journal={arXiv preprint arXiv:2308.01006},
  year={2023}
}
@article{genad,
  title={GenAD: Generative End-to-End Autonomous Driving},
  author={Zheng, Wenzhao and Song, Ruiqi and Guo, Xianda and Chen, Long},
  journal={arXiv preprint arXiv:2402.11502},
  year={2024}
}
@article{flashattention,
  title={Flashattention: Fast and memory-efficient exact attention with io-awareness},
  author={Dao, Tri and Fu, Dan and Ermon, Stefano and Rudra, Atri and R{\'e}, Christopher},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={16344--16359},
  year={2022}
}
@inproceedings{focalloss,
  title={Focal loss for dense object detection},
  author={Lin, Tsung-Yi and Goyal, Priya and Girshick, Ross and He, Kaiming and Doll{\'a}r, Piotr},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={2980--2988},
  year={2017}
}