
\section{Experiments} \label{experiments}
Our experiments are conducted on challenging nuScenes\cite{nuscenes} dataset, which contains 1000 complex driving scenes, and each lasts for about 20 seconds. Evaluation metrics of each task are described in Appendix \ref{app:metric}. We have two variants of the model, which only differ in backbone network and input image resolution. For our small model SparseDrive-S, we use ResNet50\cite{resnet} as backbone network and the input image size is 256$\times$704. For our base model, SparseDrive-B, we change backbone network to ResNet101 and input image size to 512$\times$1408. All experiments are conducted on 8 NVIDIA RTX 4090 24GB GPUs. More configuration details are provided in Appendix \ref{app:imp_detail}.

\subsection{Main Results}
We compare with prior state-of-the-arts, both modularized and end-to-end methods. Among end-to-end methods, our lightweight model SparseDrive-S has surpassed previous SOTAs in all tasks, while our base model SparseDrive-B pushes the performance boundaries one step further. The main metrics for each task are marked in grey background in Tables.

\paragraph{Perception.} For 3D detection in Tab. \ref{tab:detection}, SparseDrive achieves \textbf{49.6\%} mAP and \textbf{58.8\%} NDS, yielding a significant improvement of \textbf{+11.6\%} mAP and \textbf{+9.0\%} NDS compared to UniAD\cite{uniad}. For multi-object tracking in Tab. \ref{tab:tracking}, SparseDrive achieves \textbf{50.1\%} AMOTA, and lowest ID switch of \textbf{632}, which surpasses UniAD\cite{uniad} by \textbf{+14.2\%} in terms of AMOTA and gets a \textbf{30.2\%} reduction for ID switch, showing the temporal consistency of tracking tracklet. For online mapping in Tab. \ref{tab:online_mapping}, SparseDrive gets a mAP of \textbf{56.2\%}, also surpassing previous end-to-end method VAD\cite{vad} by \textbf{+8.6\%}.

\input{Tabels/perception_results}

\paragraph{Prediction.} For motion prediction in Tab. \ref{tab:motion}, SparseDrive achieves the best performance with \textbf{0.60m} minADE, \textbf{0.96m} minFDE, \textbf{13.2\%} MissRate and \textbf{0.555} EPA. Compared with UniAD\cite{uniad}, SparseDrive reduces errors by \textbf{15.5\%} and \textbf{5.9\%} on minADE and minFDE respectively.

\paragraph{Planning.} For planning in Tab. \ref{tab:planning}, among all methods, SparseDrive achieves a remarkable planning performance, with the lowest L2 error of \textbf{0.58m} and collision rate of \textbf{0.06\%}. Compared with previous SOTA VAD\cite{vad}, SparseDrive reduces L2 error by \textbf{19.4\%} and collision rate by \textbf{71.4\%}, demonstrating the effectiveness and safety of our method. 

\paragraph{Efficiency.} As shown in Tab. \ref{tab:efficiency}, besides the excellent performance, SparseDrive also achieves much higher efficiency for both training and inference. With the same backbone network, our base model achieves \textbf{4.8$\times$} faster in training and \textbf{4.1$\times$} faster in inference, compared with UniAD\cite{uniad}. Our lightweight model can achieve \textbf{7.2 $\times$} and \textbf{5.0$\times$} faster in training and inference. \textbf{}

\input{Tabels/motion_planning_results}

\input{Tabels/efficiency_comparision}

\subsection{Ablation Study}
We conduct extensive ablation studies to demonstrate the effectiveness of our design choices. We use SparseDrive-S as the default model for ablation experiments.

\paragraph{Effect of designs in Motion Planner.}
To underscore the significance of considering similarity between prediction and planning, we devised several specific experiments, as shown in Tab. \ref{tab:ablation_motion_planner}. ID-2 ignores the impact of ego vehicle on surrounding agents by changing the parallel design for prediction and planning to sequential order, leading to worse performance for motion prediction and collision rate. ID-3 randomly initializes ego instance feature and set all parameters of ego anchor to 0. Removing the semantic and geometric information of ego instance leads to performance degradation in both L2 error and collision rate. ID-4 takes planning as a deterministic problem and only outputs one certain trajectory, resulting in highest collision rate. Moreover, ID-5 removes the instance-level agent-temporal cross-attention, seriously degrading the L2 error to 0.77m. For collision-aware rescore, we have detailed discussion in the following paragraph.

\paragraph{Collision-Aware Rescore.} In previous methods\cite{uniad, graphad}, a post-optimization strategy is adopted to ensure safety based on perception results. However, we argue that this strategy breaks the end-to-end paradigm, resulting in serious degradation in L2 error, as shown in Tab. \ref{tab:ablation_CAR}. Moreover, under our re-implemented collision rate metric, the post-optimization does not make planning safer, but rather more dangerous. By contrast, our collision-aware rescore module reduces collision rate from 0.12\% to 0.08\%, with negligible increase in L2 error, showing the superiority of our method.

\paragraph{Multi-modal planning.}
We conduct experiments on the number of planning modes. As shown in Tab. \ref{tab:ablation_planning_mode}, with the number of planning modes increases, the planning performance improves continuously until saturated at 6 modes, again proving the importance of multi-modal planning.

\input{Tabels/ablation_motion_planner}
\input{Tabels/ablation_rescore}
\input{Tabels/ablation_planning_mode}


% \subsection{Qualitative Results}
% \input{Figures/vis}
% We visualize the results of all tasks in Fig. \ref{fig:vis}. More visualizations are provided in Appendix \ref{app:vis}.
