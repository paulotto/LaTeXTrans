\section{Related Work}
\subsection{Multi-view 3D Detection}
Multi-view 3D detection is a prerequisite for the safety of autonomous driving system. LSS\cite{lss} utilizes depth estimation to lift image features to 3D space and splats features to BEV plane. Follow-up works apply lift-splat operation to the field of 3D detection, and have made significant improvement in accuracy\cite{bevdet, bevdet4d, bevdepth, bevstereo} and efficiency\cite{bevfusion, bevpoolv2}. Some works\cite{bevformer, bevformerv2, polarformer, gkt} predefine a set of BEV queries and project them to perspective view for feature sampling. Another line of research removes the dependency for dense BEV features. PETR series\cite{petr, petrv2, streampetr} introduce 3D positional encoding and global attention to learn view transformation implicitly. Sparse4D series\cite{sparse4d, sparse4dv2, sparse4dv3} set explicit anchors in 3D space, projecting them to image view to aggregate local features and refine anchors in an iterative fashion.

\subsection{End-to-End Tracking}
Most multi-object tracking (MOT) methods adopt the tracking-by-detection fashion, which relies on post-processing like data association. Such pipeline cannot fully leverage the capabilities of neural networks. Inspired by object queries in \cite{detr}, some works\cite{motr, motrv2, motrv3, trackformer, transtrack, mutr3d} introduce track queries to model the tracked instances in streaming manner. MOTR\cite{motr} proposes tracklet-aware label assignment, which forces the track query to continuously detect the same target and suffers from the conflict between detection and association\cite{motrv2, motrv3}. Sparse4Dv3 demonstrates that the temporally propagated instances already have identity consistency, and achieves SOTA tracking performance with a simple ID assignment process.

\subsection{Online Mapping}
Online mapping is proposed as an alternative of HD map, due to the high cost and vast human efforts in HD map construction. HDMapNet\cite{hdmapnet} groups BEV semantic segmentation with post-processing to get vectorized map instances. VectorMapNet\cite{vectormapnet} utilizes a two-stage auto-regressive transformer for online map construction. MapTR\cite{maptr} models map element as a point set of equivalent permutations, which avoids definition ambiguity of map element. BeMapNet adopts piecewise Bezier curve to describe the details of map elements. StreamMapNet\cite{streammapnet} introduces BEV fusion and query propagation for temporal modeling.

\subsection{End-to-End Motion Prediction}
End-to-end motion prediction is proposed to avoid the cascading error in traditional pipelines. FaF\cite{faf} employs a single convolution network to predict both current and future bounding boxes. IntentNet\cite{intentnet} takes one step further to reason both high level behavior and long term trajectories. PnPNet\cite{pnpnet} introduces an online tracking module to aggregate trajectory level features for motion prediction. ViP3D\cite{vip3d} employs agent queries to perform tracking and prediction, taking images and HD map as input. PIP\cite{pip} replaces human-annotated HD map with local vectorized map.

\subsection{End-to-End Planning}
The research of end-to-end planning has been ongoing since last century\cite{pomerleau1988alvinn}. Early works\cite{codevilla2018end, codevilla2019exploring, prakash2021multi} omit intermediate tasks like perception and motion prediction, which lack interpretability and are difficult to optimize. Some works\cite{stp3, mp3, sadat2020perceive, cui2021lookout} construct explicit cost map from perception or prediction results to enhance interpretability, but rely on hand-crafted rules to select the best trajectory with minimum cost. Recently, UniAD\cite{uniad} proposes a unified query design to integrate various tasks into a goal-oriented model, achieving remarkable performance in perception, prediction and planning. VAD\cite{vad} employs vectorized representation for scene learning and planning constraints. GraphAD\cite{graphad} utilizes graph model for complex interactions in traffic scenes. FusionAD\cite{fusionad} extends end-to-end driving to multi-sensor input. However, previous methods mainly focus on scene learning, and adopt a straightforward design for prediction and planning, without fully considering the similarity between these two tasks, greatly limiting the performance.