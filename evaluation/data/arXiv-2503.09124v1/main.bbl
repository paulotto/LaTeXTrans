\begin{thebibliography}{56}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Szegedy et~al.(2014)Szegedy, Zaremba, Sutskever, Bruna, Erhan, Goodfellow, and Fergus]{42503}
C.~Szegedy, W.~Zaremba, I.~Sutskever, J.~Bruna, D.~Erhan, I.~Goodfellow, and R.~Fergus.
\newblock Intriguing properties of neural networks.
\newblock In \emph{International Conference on Learning Representations}, 2014.

\bibitem[Goodfellow et~al.(2015)Goodfellow, Shlens, and Szegedy]{goodfellow2014explaining}
I.~Goodfellow, J.~Shlens, and C.~Szegedy.
\newblock Explaining and harnessing adversarial examples.
\newblock In \emph{International Conference on Learning Representations}, 2015.

\bibitem[Yuan et~al.(2019)Yuan, He, Zhu, and Li]{yuan2019adversarial}
X.~Yuan, P.~He, Q.~Zhu, and X.~Li.
\newblock Adversarial examples: Attacks and defenses for deep learning.
\newblock \emph{IEEE Transactions on Neural Networks and Learning Systems}, 30\penalty0 (9):\penalty0 2805--2824, 2019.

\bibitem[Naseer et~al.(2020)Naseer, Khan, Hayat, Khan, and Porikli]{naseer2020self}
M.~Naseer, S.~Khan, M.~Hayat, F.~S. Khan, and F.~Porikli.
\newblock A self-supervised approach for adversarial robustness.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 262--271, 2020.

\bibitem[Lee and Kim(2023)]{lee2023robust}
M.~Lee and D.~Kim.
\newblock Robust evaluation of diffusion-based adversarial purification.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision}, pages 134--144, 2023.

\bibitem[Singh et~al.(2024)Singh, Croce, and Hein]{singh2024revisiting}
N.~D. Singh, F.~Croce, and M.~Hein.
\newblock Revisiting adversarial training for imagenet: Architectures, training and generalization across threat models.
\newblock \emph{Advances in Neural Information Processing Systems}, 36, 2024.

\bibitem[Luo et~al.(2023)Luo, Kong, Huang, Hu, Kang, and Kot]{luo2023beyond}
A.~Luo, C.~Kong, J.~Huang, Y.~Hu, X.~Kang, and A.~C Kot.
\newblock Beyond the prior forgery knowledge: Mining critical clues for general face forgery detection.
\newblock \emph{IEEE Transactions on Information Forensics and Security}, 19:\penalty0 1168--1182, 2023.

\bibitem[Tramèr et~al.(2018)Tramèr, Kurakin, Papernot, Goodfellow, Boneh, and McDaniel]{tramèr2018ensemble}
F.~Tramèr, A.~Kurakin, N.~Papernot, I.~Goodfellow, D.~Boneh, and P.~McDaniel.
\newblock Ensemble adversarial training: Attacks and defenses.
\newblock In \emph{International Conference on Learning Representations}, 2018.

\bibitem[Salman et~al.(2020{\natexlab{a}})Salman, Ilyas, Engstrom, Kapoor, and Madry]{salman2020adversarially}
H.~Salman, A.~Ilyas, L.~Engstrom, A.~Kapoor, and A.~Madry.
\newblock Do adversarially robust imagenet models transfer better?
\newblock \emph{Advances in Neural Information Processing Systems}, 33:\penalty0 3533--3545, 2020{\natexlab{a}}.

\bibitem[Luo et~al.(2021)Luo, Li, Liu, Kang, and Wang]{luo2021capsule}
A.~Luo, E.~Li, Y.~Liu, X.~Kang, and Z~J. Wang.
\newblock A capsule network based approach for detection of audio spoofing attacks.
\newblock In \emph{ICASSP 2021-2021 IEEE International Conference on Acoustics, Speech and Signal Processing}, pages 6359--6363. IEEE, 2021.

\bibitem[Cohen et~al.(2019)Cohen, Rosenfeld, and Kolter]{cohen2019certified}
J.~Cohen, E.~Rosenfeld, and Z.~Kolter.
\newblock Certified adversarial robustness via randomized smoothing.
\newblock In \emph{International Conference on Machine Learning}, pages 1310--1320. PMLR, 2019.

\bibitem[Madry et~al.(2018)Madry, Makelov, Schmidt, Tsipras, and Vladu]{madry2018towards}
A.~Madry, A.~Makelov, L.~Schmidt, D.~Tsipras, and A.~Vladu.
\newblock Towards deep learning models resistant to adversarial attacks.
\newblock \emph{International Conference on Learning Representations}, 2018.

\bibitem[Dong et~al.(2018)Dong, Liao, Pang, Su, Zhu, Hu, and Li]{dong2018boosting}
Y.~Dong, F.~Liao, T.~Pang, H.~Su, J.~Zhu, X.~Hu, and J.~Li.
\newblock Boosting adversarial attacks with momentum.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition}, pages 9185--9193, 2018.

\bibitem[Zhang et~al.(2022)Zhang, Tan, Chen, Liu, Zhang, and Li]{zhang2022enhancing}
Y.~Zhang, Y.~Tan, T.~Chen, X.~Liu, Q.~Zhang, and Y.~Li.
\newblock Enhancing the transferability of adversarial examples with random patch.
\newblock In \emph{Proceedings of the Thirty-First International Joint Conference on Artificial Intelligence, IJCAI-22}, pages 1672--1678, 2022.

\bibitem[Wei et~al.(2023)Wei, Chen, Wu, and Jiang]{wei2023enhancing}
Z.~Wei, J.~Chen, Z.~Wu, and Y.~Jiang.
\newblock Enhancing the self-universality for transferable targeted attacks.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 12281--12290, 2023.

\bibitem[Sharif et~al.(2018)Sharif, Bauer, and Reiter]{sharif2018suitability}
M.~Sharif, L.~Bauer, and M.~Reiter.
\newblock On the suitability of lp-norms for creating and preventing adversarial examples.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops}, pages 1605--1613, 2018.

\bibitem[Carlini and Wagner(2017)]{carlini2017towards}
N.~Carlini and D.~Wagner.
\newblock Towards evaluating the robustness of neural networks.
\newblock In \emph{IEEE Symposium on Security and Privacy}, pages 39--57. IEEE, 2017.

\bibitem[Luo et~al.(2018)Luo, Liu, Wei, and Xu]{luo2018towards}
B.~Luo, Y.~Liu, L.~Wei, and Q.~Xu.
\newblock Towards imperceptible and robust adversarial example attacks against neural networks.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial Intelligence}, volume~32, 2018.

\bibitem[Zhao et~al.(2020)Zhao, Liu, and Larson]{zhao2020towards}
Z.~Zhao, Z.~Liu, and M.~Larson.
\newblock Towards large yet imperceptible adversarial image perturbations with perceptual color distance.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 1039--1048, 2020.

\bibitem[Laidlaw et~al.(2021)Laidlaw, Singla, and Feizi]{laidlaw2021perceptual}
C.~Laidlaw, S.~Singla, and S.~Feizi.
\newblock Perceptual adversarial robustness: Defense against unseen threat models.
\newblock In \emph{International Conference on Learning Representations}, 2021.

\bibitem[Duan et~al.(2021)Duan, Chen, Niu, Yang, Qin, and He]{duan2021advdrop}
R.~Duan, Y.~Chen, D.~Niu, Y.~Yang, A.~Qin, and Y.~He.
\newblock Advdrop: Adversarial attack to dnns by dropping information.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision}, pages 7506--7515, 2021.

\bibitem[Chen et~al.(2023{\natexlab{a}})Chen, Wang, Huang, Zhao, Liu, and Guan]{chen2023imperceptible}
Z.~Chen, Z.~Wang, J.~Huang, W.~Zhao, X.~Liu, and D.~Guan.
\newblock Imperceptible adversarial attack via invertible neural networks.
\newblock In \emph{Proceedings of the AAAI Conference on Artificial Intelligence}, volume~37, pages 414--424, 2023{\natexlab{a}}.

\bibitem[Jia et~al.(2022)Jia, Ma, Yao, Yin, Ding, and Yang]{jia2022exploring}
S.~Jia, C.~Ma, T.~Yao, B.~Yin, S.~Ding, and X.~Yang.
\newblock Exploring frequency adversarial attacks for face forgery detection.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 4103--4112, 2022.

\bibitem[Luo et~al.(2022)Luo, Lin, Xie, Wu, Xie, and Shen]{luo2022frequency}
C.~Luo, Q.~Lin, W.~Xie, B.~Wu, J.~Xie, and L.~Shen.
\newblock Frequency-driven imperceptible adversarial attack on semantic similarity.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}, pages 15315--15324, 2022.

\bibitem[Song et~al.(2018)Song, Shu, Kushman, and Ermon]{song2018constructing}
Y.~Song, R.~Shu, N.~Kushman, and S.~Ermon.
\newblock Constructing unrestricted adversarial examples with generative models.
\newblock \emph{Advances in neural information processing systems}, 31, 2018.

\bibitem[Ho et~al.(2020)Ho, Jain, and Abbeel]{ho2020denoising}
J.~Ho, A.~Jain, and P.~Abbeel.
\newblock Denoising diffusion probabilistic models.
\newblock \emph{Advances in neural information processing systems}, 33:\penalty0 6840--6851, 2020.

\bibitem[Song et~al.(2020{\natexlab{a}})Song, Meng, and Ermon]{song2020denoising}
J.~Song, C.~Meng, and S.~Ermon.
\newblock Denoising diffusion implicit models.
\newblock In \emph{International Conference on Learning Representations}, 2020{\natexlab{a}}.

\bibitem[Rombach et~al.(2022)Rombach, Blattmann, Lorenz, Esser, and Ommer]{rombach2022high}
R.~Rombach, A.~Blattmann, D.~Lorenz, P.~Esser, and B.~Ommer.
\newblock High-resolution image synthesis with latent diffusion models.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Cision and Pattern Recognition}, pages 10684--10695, 2022.

\bibitem[Chen et~al.(2023{\natexlab{b}})Chen, Gao, Zhao, Ye, and Xu]{chen2023advdiffuser}
X.~Chen, X.~Gao, J.~Zhao, K.~Ye, and C.~Xu.
\newblock Advdiffuser: Natural adversarial example synthesis with diffusion models.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision}, pages 4562--4572, 2023{\natexlab{b}}.

\bibitem[Xue et~al.(2023)Xue, Araujo, Hu, and Chen]{xue2023diffusion}
H.~Xue, A.~Araujo, B.~Hu, and Y.~Chen.
\newblock Diffusion-based adversarial sample generation for improved stealthiness and controllability.
\newblock In \emph{Thirty-seventh Conference on Neural Information Processing Systems}, 2023.

\bibitem[Chen et~al.(2023{\natexlab{c}})Chen, Chen, Chen, Zhang, Zou, and Shi]{chen2023diffusion}
J.~Chen, H.~Chen, K.~Chen, Y.~Zhang, Z.~Zou, and Z.~Shi.
\newblock Diffusion models for imperceptible and transferable adversarial attack.
\newblock \emph{arXiv preprint arXiv:2305.08192}, 2023{\natexlab{c}}.

\bibitem[Chen et~al.(2024)Chen, Li, Wu, Jiang, Ding, and Zhang]{chen2024content}
Z.~Chen, B.~Li, S.~Wu, K.~Jiang, S.~Ding, and W.~Zhang.
\newblock Content-based unrestricted adversarial attack.
\newblock \emph{Advances in Neural Information Processing Systems}, 36, 2024.

\bibitem[Dhariwal and Nichol(2021)]{dhariwal2021diffusion}
P.~Dhariwal and A.~Nichol.
\newblock Diffusion models beat gans on image synthesis.
\newblock \emph{Advances in neural information processing systems}, 34:\penalty0 8780--8794, 2021.

\bibitem[Song et~al.(2020{\natexlab{b}})Song, Sohl-Dickstein, Kingma, Kumar, Ermon, and Poole]{song2020score}
Y.~Song, J.~Sohl-Dickstein, D.~P. Kingma, A.~Kumar, S.~Ermon, and B.~Poole.
\newblock Score-based generative modeling through stochastic differential equations.
\newblock In \emph{International Conference on Learning Representations}, 2020{\natexlab{b}}.

\bibitem[Song and Ermon(2019)]{song2019generative}
Y.~Song and S.~Ermon.
\newblock Generative modeling by estimating gradients of the data distribution.
\newblock \emph{Advances in neural information processing systems}, 32, 2019.

\bibitem[Zhou et~al.(2016)Zhou, Khosla, Lapedriza, Oliva, and Torralba]{zhou2016learning}
B.~Zhou, A.~Khosla, A.~Lapedriza, A.~Oliva, and A.~Torralba.
\newblock Learning deep features for discriminative localization.
\newblock In \emph{Proceedings of the IEEE conference on computer vision and pattern recognition}, pages 2921--2929, 2016.

\bibitem[Selvaraju et~al.(2017)Selvaraju, Cogswell, Das, Vedantam, Parikh, and Batra]{selvaraju2017grad}
R.~R. Selvaraju, M.~Cogswell, A.~Das, R.~Vedantam, D.~Parikh, and D.~Batra.
\newblock Grad-cam: Visual explanations from deep networks via gradient-based localization.
\newblock In \emph{Proceedings of the IEEE International Conference on Computer Vision}, pages 618--626, 2017.

\bibitem[Krizhevsky et~al.(2012)Krizhevsky, Sutskever, and Hinton]{krizhevsky2012imagenet}
A.~Krizhevsky, I.~Sutskever, and G.~E Hinton.
\newblock Imagenet classification with deep convolutional neural networks.
\newblock \emph{Advances in neural information processing systems}, 25, 2012.

\bibitem[Ioffe and Szegedy(2015)]{ioffe2015batch}
S.~Ioffe and C.~Szegedy.
\newblock Batch normalization: Accelerating deep network training by reducing internal covariate shift.
\newblock In \emph{International conference on machine learning}, pages 448--456. pmlr, 2015.

\bibitem[Yuan et~al.(2022)Yuan, Zhang, Gao, Cheng, and Song]{yuan2022natural}
S.~Yuan, Q.~Zhang, L.~Gao, Y.~Cheng, and J.~Song.
\newblock Natural color fool: Towards boosting black-box unrestricted attacks.
\newblock \emph{Advances in Neural Information Processing Systems}, 35:\penalty0 7546--7560, 2022.

\bibitem[Russakovsky et~al.(2015)Russakovsky, Deng, Su, Krause, Satheesh, Ma, Huang, Karpathy, Khosla, Bernstein, et~al.]{russakovsky2015imagenet}
O.~Russakovsky, J.~Deng, H.~Su, J.~Krause, S.~Satheesh, S.~Ma, Z.~Huang, A.~Karpathy, A.~Khosla, M.~Bernstein, et~al.
\newblock Imagenet large scale visual recognition challenge.
\newblock \emph{International journal of computer vision}, 115:\penalty0 211--252, 2015.

\bibitem[He et~al.(2016)He, Zhang, Ren, and Sun]{he2016deep}
K.~He, X.~Zhang, S.~Ren, and J.~Sun.
\newblock Deep residual learning for image recognition.
\newblock In \emph{Proceedings of the IEEE Conference on Computer VVision and pattern recognition}, pages 770--778, 2016.

\bibitem[Liu et~al.(2022)Liu, Mao, Wu, Feichtenhofer, Darrell, and Xie]{liu2022convnet}
Z.~Liu, H.~Mao, C.~Y. Wu, C.~Feichtenhofer, T.~Darrell, and S.~Xie.
\newblock A convnet for the 2020s.
\newblock In \emph{Proceedings of the IEEE/CVF conference on computer vision and pattern recognition}, pages 11976--11986, 2022.

\bibitem[Liu et~al.(2021)Liu, Lin, Cao, Hu, Wei, Zhang, Lin, and Guo]{liu2021swin}
Z.~Liu, Y.~Lin, Y.~Cao, H.~Hu, Y.~Wei, Z.~Zhang, S.~Lin, and B.~Guo.
\newblock Swin transformer: Hierarchical vision transformer using shifted windows.
\newblock In \emph{Proceedings of the IEEE/CVF International Conference on Computer Vision}, pages 10012--10022, 2021.

\bibitem[Vaswani et~al.(2017)Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez, Kaiser, and Polosukhin]{vaswani2017attention}
A.~Vaswani, N.~Shazeer, N.~Parmar, J.~Uszkoreit, L.~Jones, A.~N. Gomez, {\L}ukasz Kaiser, and Illia Polosukhin.
\newblock Attention is all you need.
\newblock \emph{Advances in neural information processing systems}, 30, 2017.

\bibitem[Zhu et~al.(2024)Zhu, Liao, Zhang, Wang, Liu, and Wang]{zhu2024vision}
L.~Zhu, B.~Liao, Q.~Zhang, X.~Wang, W.~Liu, and X.~Wang.
\newblock Vision mamba: Efficient visual representation learning with bidirectional state space model.
\newblock In \emph{International conference on machine learning}, 2024.

\bibitem[Gu and Dao(2023)]{gu2023mamba}
A.~Gu and T.~Dao.
\newblock Mamba: Linear-time sequence modeling with selective state spaces.
\newblock \emph{arXiv preprint arXiv:2312.00752}, 2023.

\bibitem[Wang et~al.(2004)Wang, Bovik, Sheikh, and Simoncelli]{wang2004image}
Z.~Wang, A.~C. Bovik, H.~R. Sheikh, and E.~P. Simoncelli.
\newblock Image quality assessment: from error visibility to structural similarity.
\newblock \emph{IEEE Transactions on Image Processing}, 13\penalty0 (4):\penalty0 600--612, 2004.

\bibitem[Zhang et~al.(2018)Zhang, Isola, Efros, Shechtman, and Wang]{zhang2018unreasonable}
R.~Zhang, P.~Isola, A.~A. Efros, E.~Shechtman, and O.~Wang.
\newblock The unreasonable effectiveness of deep features as a perceptual metric.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition}, pages 586--595, 2018.

\bibitem[Heusel et~al.(2017)Heusel, Ramsauer, Unterthiner, Nessler, and Hochreiter]{heusel2017gans}
M.~Heusel, H.~Ramsauer, T.~Unterthiner, B.~Nessler, and S.~Hochreiter.
\newblock Gans trained by a two time-scale update rule converge to a local nash equilibrium.
\newblock \emph{Advances in neural information processing systems}, 30, 2017.

\bibitem[Ke et~al.(2021)Ke, Wang, Wang, Milanfar, and Yang]{ke2021musiq}
J.~Ke, Q.~Wang, Y.~Wang, P.~Milanfar, and F.~Yang.
\newblock Musiq: Multi-scale image quality transformer.
\newblock In \emph{Proceedings of the IEEE/CVF international conference on computer vision}, pages 5148--5157, 2021.

\bibitem[Salman et~al.(2020{\natexlab{b}})Salman, Sun, Yang, Kapoor, and Kolter]{salman2020denoised}
H.~Salman, M.~Sun, G.~Yang, A.~Kapoor, and J~Z. Kolter.
\newblock Denoised smoothing: A provable defense for pretrained classifiers.
\newblock \emph{Advances in Neural Information Processing Systems}, 33:\penalty0 21945--21957, 2020{\natexlab{b}}.

\bibitem[Liu et~al.(2023)Liu, Dong, Xiang, Yang, Su, Zhu, Chen, He, Xue, and Zheng]{liu2023comprehensive}
C.~Liu, Y.~Dong, W.~Xiang, X.~Yang, H.~Su, J.~Zhu, Y.~Chen, Y.~He, H.~Xue, and S.~Zheng.
\newblock A comprehensive study on robustness of image classification models: Benchmarking and rethinking.
\newblock \emph{arXiv preprint arXiv:2302.14301}, 2023.

\bibitem[Das et~al.(2018)Das, Shanbhogue, Chen, Hohman, Li, Chen, Kounavis, and Chau]{das2018shield}
N.~Das, M.~Shanbhogue, S.~Chen, F.~Hohman, S.~Li, L.~Chen, M.~E. Kounavis, and D.~Chau.
\newblock Shield: Fast, practical defense and vaccination for deep learning using jpeg compression.
\newblock In \emph{Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery \& Data Mining}, pages 196--204, 2018.

\bibitem[Guo et~al.(2018)Guo, Rana, Cisse, and van~der Maaten]{guo2018countering}
C.~Guo, M.~Rana, M.~Cisse, and L.~van~der Maaten.
\newblock Countering adversarial images using input transformations.
\newblock In \emph{International Conference on Learning Representations}, 2018.

\bibitem[Sandler et~al.(2018)Sandler, Howard, Zhu, Zhmoginov, and Chen]{sandler2018mobilenetv2}
M.~Sandler, A.~Howard, M.~Zhu, A.~Zhmoginov, and L.~Chen.
\newblock Mobilenetv2: Inverted residuals and linear bottlenecks.
\newblock In \emph{Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition}, pages 4510--4520, 2018.

\end{thebibliography}
