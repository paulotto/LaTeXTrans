\section{Conclusions}
\label{sec:conclusions}

We derive effective learning dynamics for the minimal example of emergent localization in a neural receptive field given by \textcite{ingrosso2022data}. 
The analytical approach we take relies on the assumption that the \emph{conditional} preactivation is Gaussian, a refinement of previous work that assumes Gaussianity of the unconditioned preactivation as asserted by the \emph{Gaussian equivalence property} targeted by \textcite{ingrosso2022data}.
This approach may prove extensible beyond our specialized setting and may enable further analysis of how statistics of an input task drive emergent structure in neural network learning.

Emergence as an alternative mechanism to top-down constraints like sparsity
is in line with recent work that reformulates data-distributional properties as a driver for complex behavior~\parencite{chan2022data}. 
Via these analytical effective dynamics, we observe that specific data properties---the covariance structure 
and the marginals---shape localization in neural receptive fields.
Though we cannot capture dynamical interactions between neurons that may shape receptive fields in other settings with the single-neuron analytical model, our empirical validations with many neurons suggest that these interactions do not, in fact, play a significant role in shaping localization~\cite[\cf][]{harsh2020placecell}.

The data model we consider is a simplified abstraction of the task faced by early sensory systems, and, as a consequence, we do not yet capture certain features of receptive fields that are observed in early sensory systems.
In particular, we do not observe orientation nor phase selectivity, features of simple-cell receptive fields in early sensory cortices and in artificial neural networks that can be seen in a subset of receptive fields in \cref{fig:sim-real-gabors} (left and center, respectively).
To capture orientation selectivity, it may be fruitful to follow the approach of \textcite{karklin2011efficient}, who tie orientation selectivity in a population-based efficient-coding framework to the presence of noise.
Furthermore, on-center-off-surround-filtering input data, including the idealized data, gives receptive fields with subfields in our simulations, but is difficult to analyze.
Lastly, we do not yet look at the distribution of receptive field shapes and do not validate against other models of receptive field learning beyond a brief comparison with ICA~\parencite[\cf][]{saxe2011unsupervised}, but these are exciting avenues for future work.
