\begin{thebibliography}{30}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Ahmadian et~al.(2024)Ahmadian, Cremer, Gallé, Fadaee, Kreutzer, Pietquin, Üstün, and Hooker]{ahmadian2024basicsrevisitingreinforcestyle}
Arash Ahmadian, Chris Cremer, Matthias Gallé, Marzieh Fadaee, Julia Kreutzer, Olivier Pietquin, Ahmet Üstün, and Sara Hooker.
\newblock Back to basics: Revisiting reinforce style optimization for learning from human feedback in llms, 2024.
\newblock URL \url{https://arxiv.org/abs/2402.14740}.

\bibitem[Anthropic(2024)]{claude35sonnet}
Anthropic.
\newblock Claude 3.5 sonnet, 2024.
\newblock URL \url{https://www.anthropic.com/news/claude-3-5-sonnet}.

\bibitem[Brown et~al.(2020)Brown, Mann, Ryder, Subbiah, Kaplan, Dhariwal, Neelakantan, Shyam, Sastry, Askell, et~al.]{gpt3}
Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared~D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et~al.
\newblock Language models are few-shot learners.
\newblock \emph{Advances in neural information processing systems}, 33:\penalty0 1877--1901, 2020.

\bibitem[Chowdhery et~al.(2023)Chowdhery, Narang, Devlin, Bosma, Mishra, Roberts, Barham, Chung, Sutton, Gehrmann, et~al.]{chowdhery2023palm}
Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, Hyung~Won Chung, Charles Sutton, Sebastian Gehrmann, et~al.
\newblock Palm: Scaling language modeling with pathways.
\newblock \emph{Journal of Machine Learning Research}, 24\penalty0 (240):\penalty0 1--113, 2023.

\bibitem[DeepMind(2024)]{gemini-thinking}
Google DeepMind.
\newblock Gemini 2.0 flash thinking, 2024.
\newblock URL \url{https://deepmind.google/technologies/gemini/flash-thinking/}.

\bibitem[DeepSeek-AI(2025)]{deepseekai2025deepseekr1incentivizingreasoningcapability}
DeepSeek-AI.
\newblock Deepseek-r1: Incentivizing reasoning capability in llms via reinforcement learning, 2025.
\newblock URL \url{https://arxiv.org/abs/2501.12948}.

\bibitem[Good and Fletcher(1981)]{explained_variance}
Ron Good and Harold~J. Fletcher.
\newblock Reporting explained variance.
\newblock \emph{Journal of Research in Science Teaching}, 18\penalty0 (1):\penalty0 1--7, 1981.
\newblock \doi{https://doi.org/10.1002/tea.3660180102}.
\newblock URL \url{https://onlinelibrary.wiley.com/doi/abs/10.1002/tea.3660180102}.

\bibitem[Hu(2025)]{hu2025reinforce++}
Jian Hu.
\newblock Reinforce++: A simple and efficient approach for aligning large language models.
\newblock \emph{arXiv preprint arXiv:2501.03262}, 2025.

\bibitem[Hu et~al.(2025)Hu, Zhang, Han, Jiang, Zhang, and Shum]{hu2025openreasonerzeroopensourceapproach}
Jingcheng Hu, Yinmin Zhang, Qi~Han, Daxin Jiang, Xiangyu Zhang, and Heung-Yeung Shum.
\newblock Open-reasoner-zero: An open source approach to scaling up reinforcement learning on the base model, 2025.
\newblock URL \url{https://arxiv.org/abs/2503.24290}.

\bibitem[Kool et~al.(2019)Kool, van Hoof, and Welling]{rloo}
Wouter Kool, Herke van Hoof, and Max Welling.
\newblock Buy 4 {REINFORCE} samples, get a baseline for free!
\newblock In \emph{Deep Reinforcement Learning Meets Structured Prediction, {ICLR} 2019 Workshop, New Orleans, Louisiana, United States, May 6, 2019}. OpenReview.net, 2019.
\newblock URL \url{https://openreview.net/forum?id=r1lgTGL5DE}.

\bibitem[Liu et~al.(2024)Liu, Feng, Xue, Wang, Wu, Lu, Zhao, Deng, Zhang, Ruan, et~al.]{dsv3}
Aixin Liu, Bei Feng, Bing Xue, Bingxuan Wang, Bochao Wu, Chengda Lu, Chenggang Zhao, Chengqi Deng, Chenyu Zhang, Chong Ruan, et~al.
\newblock Deepseek-v3 technical report.
\newblock \emph{arXiv preprint arXiv:2412.19437}, 2024.

\bibitem[Liu et~al.(2025)Liu, Chen, Li, Qi, Pang, Du, Lee, and Lin]{liu2025understandingr1zeroliketrainingcritical}
Zichen Liu, Changyu Chen, Wenjun Li, Penghui Qi, Tianyu Pang, Chao Du, Wee~Sun Lee, and Min Lin.
\newblock Understanding r1-zero-like training: A critical perspective, 2025.
\newblock URL \url{https://arxiv.org/abs/2503.20783}.

\bibitem[Mei et~al.(2025)Mei, Fu, Li, Wang, Zhang, and Wu]{areal}
Zhiyu Mei, Wei Fu, Kaiwei Li, Guangju Wang, Huanchen Zhang, and Yi~Wu.
\newblock Real: Efficient rlhf training of large language models with parameter reallocation.
\newblock In \emph{Proceedings of the Eighth Conference on Machine Learning and Systems, MLSys 2025, Santa Clara, CA, USA, May 12-15, 2025}. mlsys.org, 2025.

\bibitem[Oh et~al.(2018)Oh, Guo, Singh, and Lee]{SIL}
Junhyuk Oh, Yijie Guo, Satinder Singh, and Honglak Lee.
\newblock Self-imitation learning.
\newblock In Jennifer Dy and Andreas Krause, editors, \emph{Proceedings of the 35th International Conference on Machine Learning}, volume~80 of \emph{Proceedings of Machine Learning Research}, pages 3878--3887. PMLR, 10--15 Jul 2018.
\newblock URL \url{https://proceedings.mlr.press/v80/oh18b.html}.

\bibitem[OpenAI(2023)]{gpt4}
OpenAI.
\newblock {GPT4} technical report.
\newblock \emph{arXiv preprint arXiv:2303.08774}, 2023.

\bibitem[OpenAI(2024)]{o1}
OpenAI.
\newblock Learning to reason with llms, 2024.
\newblock URL \url{https://openai.com/index/learning-to-reason-with-llms/}.

\bibitem[Ouyang et~al.(2022{\natexlab{a}})Ouyang, Wu, Jiang, Almeida, Wainwright, Mishkin, Zhang, Agarwal, Slama, Ray, et~al.]{ouyang2022training}
Long Ouyang, Jeffrey Wu, Xu~Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et~al.
\newblock Training language models to follow instructions with human feedback.
\newblock \emph{Advances in neural information processing systems}, 35:\penalty0 27730--27744, 2022{\natexlab{a}}.

\bibitem[Ouyang et~al.(2022{\natexlab{b}})Ouyang, Wu, Jiang, Almeida, Wainwright, Mishkin, Zhang, Agarwal, Slama, Ray, et~al.]{rlhf}
Long Ouyang, Jeffrey Wu, Xu~Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et~al.
\newblock Training language models to follow instructions with human feedback.
\newblock \emph{Advances in neural information processing systems}, 35:\penalty0 27730--27744, 2022{\natexlab{b}}.

\bibitem[Qwen(2024)]{qwq}
Qwen.
\newblock Qwq-32b: Embracing the power of reinforcement learning, 2024.
\newblock URL \url{https://qwenlm.github.io/blog/qwq-32b/}.

\bibitem[Schulman et~al.(2015)Schulman, Moritz, Levine, Jordan, and Abbeel]{schulman2015high}
John Schulman, Philipp Moritz, Sergey Levine, Michael Jordan, and Pieter Abbeel.
\newblock High-dimensional continuous control using generalized advantage estimation.
\newblock \emph{arXiv preprint arXiv:1506.02438}, 2015.

\bibitem[Schulman et~al.(2017)Schulman, Wolski, Dhariwal, Radford, and Klimov]{ppo}
John Schulman, Filip Wolski, Prafulla Dhariwal, Alec Radford, and Oleg Klimov.
\newblock Proximal policy optimization algorithms.
\newblock \emph{arXiv preprint arXiv:1707.06347}, 2017.

\bibitem[Shao et~al.(2024)Shao, Wang, Zhu, Xu, Song, Zhang, Li, Wu, and Guo]{shao2024deepseekmath}
Zhihong Shao, Peiyi Wang, Qihao Zhu, Runxin Xu, Junxiao Song, Mingchuan Zhang, YK~Li, Yu~Wu, and Daya Guo.
\newblock Deepseekmath: Pushing the limits of mathematical reasoning in open language models.
\newblock \emph{arXiv preprint arXiv:2402.03300}, 2024.

\bibitem[Shen et~al.(2025)Shen, Liu, Wu, Zhu, Yang, Xin, Yue, and Yan]{rlhf-sw}
Wei Shen, Guanlin Liu, Zheng Wu, Ruofei Zhu, Qingping Yang, Chao Xin, Yu~Yue, and Lin Yan.
\newblock Exploring data scaling trends and effects in reinforcement learning from human feedback.
\newblock \emph{arXiv preprint arXiv:2503.22230}, 2025.

\bibitem[Sutton et~al.(1998)Sutton, Barto, et~al.]{sutton1998rl}
Richard~S Sutton, Andrew~G Barto, et~al.
\newblock \emph{Reinforcement learning: An introduction}, volume~1.
\newblock MIT press Cambridge, 1998.

\bibitem[Team et~al.(2023)Team, Anil, Borgeaud, Wu, Alayrac, Yu, Soricut, Schalkwyk, Dai, Hauth, et~al.]{team2023gemini}
Gemini Team, Rohan Anil, Sebastian Borgeaud, Yonghui Wu, Jean-Baptiste Alayrac, Jiahui Yu, Radu Soricut, Johan Schalkwyk, Andrew~M Dai, Anja Hauth, et~al.
\newblock Gemini: a family of highly capable multimodal models.
\newblock \emph{arXiv preprint arXiv:2312.11805}, 2023.

\bibitem[Team et~al.(2025)Team, Du, Gao, Xing, Jiang, Chen, Li, Xiao, Du, Liao, et~al.]{k1.5}
Kimi Team, Angang Du, Bofei Gao, Bowei Xing, Changjiu Jiang, Cheng Chen, Cheng Li, Chenjun Xiao, Chenzhuang Du, Chonghua Liao, et~al.
\newblock Kimi k1. 5: Scaling reinforcement learning with llms.
\newblock \emph{arXiv preprint arXiv:2501.12599}, 2025.

\bibitem[Wei et~al.(2022)Wei, Wang, Schuurmans, Bosma, Ichter, Xia, Chi, Le, and Zhou]{cot_2022}
Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian Ichter, Fei Xia, Ed~H. Chi, Quoc~V. Le, and Denny Zhou.
\newblock Chain-of-thought prompting elicits reasoning in large language models.
\newblock In Sanmi Koyejo, S.~Mohamed, A.~Agarwal, Danielle Belgrave, K.~Cho, and A.~Oh, editors, \emph{Advances in Neural Information Processing Systems 35: Annual Conference on Neural Information Processing Systems 2022, NeurIPS 2022, New Orleans, LA, USA, November 28 - December 9, 2022}, 2022.

\bibitem[XAI(2024)]{grok}
XAI.
\newblock Grok 3 beta — the age of reasoning agents, 2024.
\newblock URL \url{https://x.ai/news/grok-3}.

\bibitem[Yu et~al.(2025)Yu, Zhang, Zhu, Yuan, Zuo, Yue, Fan, Liu, Liu, Liu, Lin, Lin, Ma, Sheng, Tong, Zhang, Zhang, Zhang, Zhu, Zhu, Chen, Chen, Wang, Yu, Dai, Song, Wei, Zhou, Liu, Ma, Zhang, Yan, Qiao, Wu, and Wang]{dapo}
Qiying Yu, Zheng Zhang, Ruofei Zhu, Yufeng Yuan, Xiaochen Zuo, Yu~Yue, Tiantian Fan, Gaohong Liu, Lingjun Liu, Xin Liu, Haibin Lin, Zhiqi Lin, Bole Ma, Guangming Sheng, Yuxuan Tong, Chi Zhang, Mofan Zhang, Wang Zhang, Hang Zhu, Jinhua Zhu, Jiaze Chen, Jiangjie Chen, Chengyi Wang, Hongli Yu, Weinan Dai, Yuxuan Song, Xiangpeng Wei, Hao Zhou, Jingjing Liu, Wei-Ying Ma, Ya-Qin Zhang, Lin Yan, Mu~Qiao, Yonghui Wu, and Mingxuan Wang.
\newblock Dapo: An open-source llm reinforcement learning system at scale, 2025.
\newblock URL \url{https://arxiv.org/abs/2503.14476}.

\bibitem[Yuan et~al.(2025)Yuan, Yue, Zhu, Fan, and Yan]{vc-ppo}
Yufeng Yuan, Yu~Yue, Ruofei Zhu, Tiantian Fan, and Lin Yan.
\newblock What's behind ppo's collapse in long-cot? value optimization holds the secret, 2025.
\newblock URL \url{https://arxiv.org/abs/2503.01491}.

\end{thebibliography}
