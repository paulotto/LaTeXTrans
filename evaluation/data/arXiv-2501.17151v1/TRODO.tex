\documentclass[final]{article}


\usepackage[nonatbib]{neurips_2024}

% ------------------------------------------------------------
%  2) Explicitly load natbib with numeric style:
% ------------------------------------------------------------
\usepackage[numbers,sort&compress]{natbib}

% ------------------------------------------------------------
% 3) Choose a numeric bibliography style for consistency:
%    (abbrvnat, unsrtnat, plainnat, etc. all work with natbib)
%    We'll set this at the end with \bibliographystyle{abbrvnat}.
% ------------------------------------------------------------

% ------------------------------------------------------------
% 4) Standard math & other packages (remove duplicates):
% ------------------------------------------------------------
\usepackage{amsmath,amssymb,amsfonts,amsthm}
\usepackage{colortbl}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{arydshln}
\usepackage{graphicx}
\usepackage{multirow}
\usepackage{textcomp}
\usepackage{pgfplots}
\usepackage{xcolor}
\usepackage{dsfont}
\usepackage[utf8]{inputenc} 
\usepackage[T1]{fontenc}
\usepackage{url}
\usepackage{booktabs}
\usepackage{nicefrac}
\usepackage{microtype}
\usepackage{tabularx}
\usepackage{array}
\usepackage{hyperref}


\newcolumntype{C}[1]{>{\centering\arraybackslash}p{#1}}
\newcommand{\mn}[1]{\textcolor{blue}{X: #1}}
\newcommand{\graytext}[1]{\textcolor{gray}{\scriptsize #1}}
\newcommand{\ms}[1]{\textcolor{red}{Mohammad: #1}}
\newcommand{\bd}[1]{\textcolor{violet}{Bahar: #1}}
\newcommand{\ali}[1]{\textcolor{teal}{Ali: #1}}
\newcommand{\moein}[1]{\textcolor{purple}{Moein: #1}}
\newcommand{\kian}[1]{\textcolor{magenta}{Kian: #1}}

\newcommand{\theHalgorithm}{\arabic{algorithm}}

\DeclareMathOperator{\poly}{poly}
\DeclareMathOperator{\tr}{tr}
\DeclareMathOperator*{\argmin}{arg\,min}

\title{Scanning Trojaned Models Using Out-of-Distribution Samples}


% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to LaTeX to determine where to break the
% lines. Using \AND forces a line break at that point. So, if LaTeX puts 3 of 4
% authors names on the first line, and the last on the se  Detecting Backdoor Attacks on Deep Neural Networks by


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% THEOREMS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{condition}[theorem]{Condition}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{assumption}[theorem]{Assumption}
\theoremstyle{remark}
\newtheorem{remark}{Remark}


\pgfplotsset{compat=1.18}

\begin{document}
\pdfoutput=1


% \author{%
% \small
%   Hossein Mirzaei \thanks{Department of Computer Engineering, Sharif University of Technology, Tehran, Iran} \\
%   \And
%   Ali Ansari \footnotemark[1] \thanks{Equal contribution.} \\
%   \And
%   Bahar Dibaei Nia \footnotemark[1] \footnotemark[2]\\
%   \And
%   Mojtaba Nafez \footnotemark[1] \thanks{Equal contribution.} \\
%   \And
%   Moein Madadi \footnotemark[1] \footnotemark[3]\\
%   \And
%   Sepehr Rezaee \footnotemark[1] \footnotemark[3]\\
%   \And
%   Zeinab Sadat Taghavi \footnotemark[1] \\
%   \And
%   Arad Maleki \footnotemark[1]\\
%   \And
%   Kian Shamsaie \footnotemark[1]\\
%   \And
%   Mahdi Hajialilue \footnotemark[1]\\
%   \And
%   Jafar Habibi \footnotemark[1]\\
%   \And
%   Mohammad Sabokrou 
%   % \thanks{Okinawa Institute of Science and Technology, Okinawa, Japan}
%   \\
%   \And
%   Mohammad Hossein Rohban \footnotemark[1]\\
% }
% 
\begingroup
   \renewcommand{\thefootnote}{}% temporarily clear the footnote symbol
   \footnotetext{For correspondence, please contact: <\texttt{rohban@sharif.edu}>,%
  \quad <\texttt{hossein.mirzaeisadeghlou@epfl.ch}>.}
\endgroup

\author{
Hossein Mirzaei$^{1}$ \quad Ali Ansari$^{2}$ \thanks{Equal Contribution} \quad Bahar Dibaei Nia$^{2}$ \footnotemark[1] \\ \\
\textbf{Mojtaba Nafez}$^2$ \thanks{Equal Contribution} \quad \textbf{Moein Madadi} $^2$ \footnotemark[2] \quad
\textbf{Sepehr Rezaee}$^3$ \footnotemark[2] \\ \\
\quad \textbf{Zeinab Sadat Taghavi}$^2$ \quad \textbf{Arad Maleki}$^2$ \quad \textbf{Kian Shamsaie}$^2$ \quad \textbf{Mahdi Hajialilue}$^2$ \\ \\ \quad \textbf{Jafar Habibi}$^2$ \quad \textbf{Mohammad Sabokrou}$^3$ \quad \textbf{ Mohammad Hossein Rohban}$^2$\\
\\
$^1$École Polytechnique Fédérale de Lausanne (EPFL) \quad $^2$Sharif University of Technology \\ \quad $^3$Shahid Beheshti University  \quad $^4$Okinawa Institute of Science and Technology\\
% \texttt{\{yangk,tianjunz,jegonzal,klein\}@berkeley.edu}\\
% \texttt{\{cummins,bcui,benoitsteiner,yuandongt\}@fb.com}\\
% \texttt{linnan\_wang@brown.edu}
}

\maketitle



\begin{abstract}
Scanning for trojan (backdoor) in deep neural networks is crucial due to their significant real-world applications. There has been an increasing focus on developing effective general trojan scanning methods across various trojan attacks. Despite advancements, there remains a shortage of methods that perform effectively without preconceived assumptions about the backdoor attack method. Additionally, we have observed that current methods struggle to identify classifiers trojaned using adversarial training. Motivated by these challenges, our study introduces a novel scanning method named \textbf{TRODO} (\textbf{TRO}jan scanning by \textbf{D}etection of adversarial shifts in \textbf{O}ut-of-distribution samples). TRODO leverages the concept of "blind spots"—regions where trojaned classifiers erroneously identify out-of-distribution (OOD) samples as in-distribution (ID). We scan for these blind spots by adversarially shifting OOD samples towards in-distribution. The increased likelihood of perturbed OOD samples being classified as ID serves as a signature for trojan detection. TRODO is both trojan and label mapping agnostic, effective even against adversarially trained trojaned classifiers. It is applicable even in scenarios where training data is absent, demonstrating high accuracy and adaptability across various scenarios and datasets, highlighting its potential as a robust trojan scanning strategy. The code repository is available at: \url{https://github.com/rohban-lab/TRODO}.
% Scanning trojaned deep learning models is a critical task due to their widespread real-world applications. Recently, there has been a growing focus on developing general trojan scanning methods that can perform effectively across various strategies used to trojanize input models. Despite advancements in proposed scanning methods, still there is a lack of a scanning method that performs effectively without any preassumptions about the input trojaned classifier. Moreover, we experimentally observe that existing scanning methods fall short in identifying trojaned classifiers that have been trojanized with adversarial training. Motivated by this, our study proposes a novel scanning method, TRODO (\textbf{TRO}janed scanning by \textbf{D}etection of Adversarial Shifts in \textbf{O}OD Samples), which leverages the concept of "blind spots"—regions where trojaned classifiers misclassify out-of-distribution (OOD) samples as in-distribution (ID). TRODO identifies these blind spots by adversarially perturbing OOD samples to shift them toward ID. The changes in the likelihood of perturbed OOD samples belonging to ID serve as a signature for trojan detection. TRODO is general, both trojan and target label agnostic, and effective even against adversarially trained trojaned classifiers. Extensive evaluations demonstrate TRODO's high accuracy and adaptability across various scenarios and datasets, highlighting its potential as a general trojan scanning strategy.
% Deep Neural Network (DNN)-based models are extensively utilized in critical applications such as image classification, face recognition, and autonomous driving. However, their reliability is increasingly challenged by trojan attacks, where adversaries introduce malicious samples into the training data, causing the model to perform normally on clean data but fail on trojaned samples. Existing defense strategies, such as trojaned model scanning, have limitations in their generality and effectiveness, particularly against adversarially trained models. This study proposes a novel scanning method, TRODO (TROjaned model scanning by Detection of Adversarial Shifts in OOD Samples), which leverages the concept of "blind spots"—regions where trojaned classifiers misclassify out-of-distribution (OOD) samples as in-distribution (ID). TRODO identifies these blind spots by adversarially perturbing OOD samples to mimic trojan triggers, significantly increasing their ID scores. This method is general, trojan and trigger agnostic, and effective even against adversarially trained classifiers. Extensive evaluations demonstrate TRODO's high accuracy and adaptability across various scenarios and datasets, highlighting its potential as a robust trojan detection strategy.
\end{abstract}
\input{Sec/Introduction}
\input{Figures/Main}
\input{Sec/Related_Work}
\input{Figures/BlindSpot}
\input{Sec/Threat_Model}
\input{Sec/Method}

\input{Sec/Theories}

\input{Sec/Experiments}
    
\input{Sec/Ablation_Study}

% \input{Sec/Limitation}

\input{Sec/Conclusion}
% \input{Appendix/Appendix}

\newpage
{\small
\setlength{\bibsep}{2pt}
\bibliographystyle{unsrtnat}
\bibliography{TRODO}
%\bibliographystyle{abbrv}
}
\newpage
% \section*{Appendix}
\maketitle
% \input{Appendix/Appendix}
% \input{Appendix/Appendix}
\input{Appendix/appendix}

% \input{Checklist}




\end{document}