\begin{table*}\centering
\centering
\resizebox{0.7\textwidth}{!}{
\begin{tabular}{lccc}\toprule
\textbf{Model Name} &\textbf{Type} &\textbf{Model Size} &\textbf{Modalities} \\\midrule
kakaobrain/align-base \cite{jia2021scaling} & Encoder & 176 & image, text \\ 
blip2-pretrain \cite{li2023blip2} & Encoder & 1173 & image, text \\ 
blip2-finetune-coco \cite{li2023blip2} & Encoder & 1173 & image, text \\ 
Salesforce/blip-vqa-base \cite{li2022blip} & Encoder & 247 & image, text \\ 
Salesforce/blip-vqa-capfilt-large \cite{li2022blip} & Encoder & 247 & image, text \\ 
Salesforce/blip-itm-base-coco \cite{li2022blip} & Encoder & 247 & image, text \\ 
Salesforce/blip-itm-large-coco \cite{li2022blip} & Encoder & 470 & image, text \\ 
Salesforce/blip-itm-base-flickr \cite{li2022blip} & Encoder & 247 & image, text \\ 
Salesforce/blip-itm-large-flickr \cite{li2022blip} & Encoder & 470 & image, text \\ 
openai/clip-vit-large-patch14 \cite{radford2021learning} & Encoder & 428 & image, text \\ 
openai/clip-vit-base-patch32 \cite{radford2021learning} & Encoder & 151 & image, text \\ 
openai/clip-vit-base-patch16 \cite{radford2021learning} & Encoder & 151 & image, text \\ 
facebook/dinov2-small \cite{oquab2024dinov2} & Encoder & 22 & image \\ 
facebook/dinov2-base \cite{oquab2024dinov2} & Encoder & 86 & image \\ 
facebook/dinov2-large \cite{oquab2024dinov2} & Encoder & 304 & image \\ 
facebook/dinov2-giant \cite{oquab2024dinov2} & Encoder & 1140 & image \\ 
royokong/e5-v \cite{jiang2024e5} & MLLM & 8360 & image, text \\ 
QuanSun/EVA02-CLIP-B-16 \cite{sun2023eva} & Encoder & 149 & image, text \\ 
QuanSun/EVA02-CLIP-L-14 \cite{sun2023eva} & Encoder & 428 & image, text \\ 
QuanSun/EVA02-CLIP-bigE-14 \cite{sun2023eva} & Encoder & 4700 & image, text \\ 
QuanSun/EVA02-CLIP-bigE-14-plus \cite{sun2023eva} & Encoder & 5000 & image, text \\ 
jinaai/jina-clip-v1 \cite{koukounas2024jina} & Encoder & 223 & image, text \\ 
nyu-visionx/moco-v3-vit-b \cite{chen2021empirical} & Encoder & 86 & image \\ 
nyu-visionx/moco-v3-vit-l \cite{chen2021empirical} & Encoder & 304 & image \\ 
nomic-ai/nomic-embed-vision-v1.5 \cite{nussbaum2024nomic, nomicembedv2024nomic} & Encoder & 92 & image, text \\ 
laion/CLIP-ViT-L-14-DataComp.XL-s13B-b90K \cite{gadre2024datacomp} & Encoder & 428 & image, text \\ 
laion/CLIP-ViT-B-32-DataComp.XL-s13B-b90K \cite{gadre2024datacomp} & Encoder & 151 & image, text \\ 
laion/CLIP-ViT-B-16-DataComp.XL-s13B-b90K \cite{gadre2024datacomp} & Encoder & 150 & image, text \\ 
laion/CLIP-ViT-bigG-14-laion2B-39B-b160k \cite{cherti2023reproducible} & Encoder & 2540 & image, text \\ 
laion/CLIP-ViT-g-14-laion2B-s34B-b88K \cite{cherti2023reproducible} & Encoder & 1367 & image, text \\ 
laion/CLIP-ViT-H-14-laion2B-s32B-b79K \cite{cherti2023reproducible} & Encoder & 986 & image, text \\ 
laion/CLIP-ViT-L-14-laion2B-s32B-b82K \cite{cherti2023reproducible} & Encoder & 428 & image, text \\ 
laion/CLIP-ViT-B-32-laion2B-s34B-b79K \cite{cherti2023reproducible} & Encoder & 151 & image, text \\ 
Alibaba-NLP/gme-Qwen2-VL-2B-Instruct \cite{zhang2024gme} & Encoder & 2210 & image, text \\ 
Alibaba-NLP/gme-Qwen2-VL-7B-Instruct \cite{zhang2024gme} & Encoder & 8290 & image, text \\ 
google/siglip-so400m-patch14-224 \cite{zhai2023sigmoid} & Encoder & 877 & image, text \\ 
google/siglip-so400m-patch14-384 \cite{zhai2023sigmoid} & Encoder & 878 & image, text \\ 
google/siglip-so400m-patch16-256-i18n \cite{zhai2023sigmoid} & Encoder & 1130 & image, text \\ 
google/siglip-base-patch16-256-multilingual \cite{zhai2023sigmoid} & Encoder & 371 & image, text \\ 
google/siglip-base-patch16-256 \cite{zhai2023sigmoid} & Encoder & 203 & image, text \\ 
google/siglip-base-patch16-512 \cite{zhai2023sigmoid} & Encoder & 204 & image, text \\ 
google/siglip-base-patch16-384 \cite{zhai2023sigmoid} & Encoder & 203 & image, text \\ 
google/siglip-base-patch16-224 \cite{zhai2023sigmoid} & Encoder & 203 & image, text \\ 
google/siglip-large-patch16-256 \cite{zhai2023sigmoid} & Encoder & 652 & image, text \\ 
google/siglip-large-patch16-384 \cite{zhai2023sigmoid} & Encoder & 652 & image, text \\ 
BAAI/bge-visualized-base \cite{zhou2024vista} & Encoder & 196 & image, text \\ 
BAAI/bge-visualized-m3 \cite{zhou2024vista} & Encoder & 873 & image, text \\ 
TIGER-Lab/VLM2Vec-LoRA \cite{jiang2024vlm2vec} & MLLM & 4150 & image, text \\ 
TIGER-Lab/VLM2Vec-Full \cite{jiang2024vlm2vec} & MLLM & 4150 & image, text \\ 
voyageai/voyage-multimodal-3 \cite{voyagemultimodal2024voyage} & MLLM & N/A & image, text \\ 
\bottomrule
\end{tabular}}
\caption{\textbf{List of all models evaluated in MIEB.} Model sizes are in millions of parameters.}\label{tab: list of models}
\end{table*}