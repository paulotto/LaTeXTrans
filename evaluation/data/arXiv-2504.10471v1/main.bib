@inproceedings{huang2020embedding,
  title={Embedding-based retrieval in facebook search},
  author={Huang, Jui-Ting and Sharma, Ashish and Sun, Shuying and Xia, Li and Zhang, David and Pronin, Philip and Padmanabhan, Janani and Ottaviano, Giuseppe and Yang, Linjun},
  booktitle={Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery \& Data Mining},
  pages={2553--2561},
  year={2020}
}

@inproceedings{geng2015learning,
  title={Learning image and user features for recommendation in social networks},
  author={Geng, Xue and Zhang, Hanwang and Bian, Jingwen and Chua, Tat-Seng},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={4274--4282},
  year={2015}
}

@article{jaech2024openai,
  title={Openai o1 system card},
  author={Jaech, Aaron and Kalai, Adam and Lerer, Adam and Richardson, Adam and El-Kishky, Ahmed and Low, Aiden and Helyar, Alec and Madry, Aleksander and Beutel, Alex and Carney, Alex and others},
  journal={arXiv preprint arXiv:2412.16720},
  year={2024}
}

@article{xu2024llava,
  title={Llava-o1: Let vision language models reason step-by-step},
  author={Xu, Guowei and Jin, Peng and Hao, Li and Song, Yibing and Sun, Lichao and Yuan, Li},
  journal={arXiv preprint arXiv:2411.10440},
  year={2024}
}

@article{hu2022lora,
  title={Lora: Low-rank adaptation of large language models.},
  author={Hu, Edward J and Shen, Yelong and Wallis, Phillip and Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang, Lu and Chen, Weizhu and others},
  journal={ICLR},
  volume={1},
  number={2},
  pages={3},
  year={2022}
}

@misc{liu2023improvedllava,
      title={Improved Baselines with Visual Instruction Tuning}, 
      author={Liu, Haotian and Li, Chunyuan and Li, Yuheng and Lee, Yong Jae},
      publisher={arXiv:2310.03744},
      year={2023},
}

@article{mcinnes2018umap,
  title={Umap: Uniform manifold approximation and projection for dimension reduction},
  author={McInnes, Leland and Healy, John and Melville, James},
  journal={arXiv preprint arXiv:1802.03426},
  year={2018}
}

@article{mcinnes2017hdbscan,
  title={hdbscan: Hierarchical density based clustering.},
  author={McInnes, Leland and Healy, John and Astels, Steve and others},
  journal={J. Open Source Softw.},
  volume={2},
  number={11},
  pages={205},
  year={2017}
}

@article{muennighoff2025s1,
  title={s1: Simple test-time scaling},
  author={Muennighoff, Niklas and Yang, Zitong and Shi, Weijia and Li, Xiang Lisa and Fei-Fei, Li and Hajishirzi, Hannaneh and Zettlemoyer, Luke and Liang, Percy and Cand{\`e}s, Emmanuel and Hashimoto, Tatsunori},
  journal={arXiv preprint arXiv:2501.19393},
  year={2025}
}

@article{enevoldsen2024scandinavian,
  title={The scandinavian embedding benchmarks: Comprehensive assessment of multilingual and monolingual text embedding},
  author={Enevoldsen, Kenneth and Kardos, M{\'a}rton and Muennighoff, Niklas and Nielbo, Kristoffer L},
  journal={Advances in Neural Information Processing Systems},
  volume={37},
  pages={40336--40358},
  year={2024}
}

@article{guo2025deepseek,
  title={Deepseek-r1: Incentivizing reasoning capability in llms via reinforcement learning},
  author={Guo, Daya and Yang, Dejian and Zhang, Haowei and Song, Junxiao and Zhang, Ruoyu and Xu, Runxin and Zhu, Qihao and Ma, Shirong and Wang, Peiyi and Bi, Xiao and others},
  journal={arXiv preprint arXiv:2501.12948},
  year={2025}
}

@article{liu2023visual,
  title={Visual instruction tuning},
  author={Liu, Haotian and Li, Chunyuan and Wu, Qingyang and Lee, Yong Jae},
  journal={Advances in neural information processing systems},
  volume={36},
  pages={34892--34916},
  year={2023}
}

@article{neelakantan2022text,
  title={Text and code embeddings by contrastive pre-training},
  author={Neelakantan, Arvind and Xu, Tao and Puri, Raul and Radford, Alec and Han, Jesse Michael and Tworek, Jerry and Yuan, Qiming and Tezak, Nikolas and Kim, Jong Wook and Hallacy, Chris and others},
  journal={arXiv preprint arXiv:2201.10005},
  year={2022}
}

@article{muennighoff2022sgpt,
  title={Sgpt: Gpt sentence embeddings for semantic search},
  author={Muennighoff, Niklas},
  journal={arXiv preprint arXiv:2202.08904},
  year={2022}
}

@article{dosovitskiy2020image,
  title={An image is worth 16x16 words: Transformers for image recognition at scale},
  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others},
  journal={arXiv preprint arXiv:2010.11929},
  year={2020}
}

@article{studholme1999overlap,
  title={An overlap invariant entropy measure of 3D medical image alignment},
  author={Studholme, Colin and Hill, Derek LG and Hawkes, David J},
  journal={Pattern recognition},
  volume={32},
  number={1},
  pages={71--86},
  year={1999},
  publisher={Elsevier}
}

@inproceedings{collignon1995automated,
  title={Automated multi-modality image registration based on information theory},
  author={Collignon, Andr{\'e} and Maes, Frederik and Delaere, Dominique and Vandermeulen, Dirk and Suetens, Paul and Marchal, Guy and others},
  booktitle={Information processing in medical imaging},
  volume={3},
  number={6},
  pages={263--274},
  year={1995},
  organization={Citeseer}
}

@article{datta2008image,
  title={Image retrieval: Ideas, influences, and trends of the new age},
  author={Datta, Ritendra and Joshi, Dhiraj and Li, Jia and Wang, James Z},
  journal={ACM Computing Surveys (Csur)},
  volume={40},
  number={2},
  pages={1--60},
  year={2008},
  publisher={ACM New York, NY, USA}
}

@inproceedings{pinterest,
author = {Zhai, Andrew and Wu, Hao-Yu and Tzeng, Eric and Park, Dong Huk and Rosenberg, Charles},
title = {Learning a Unified Embedding for Visual Search at Pinterest},
year = {2019},
isbn = {9781450362016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3292500.3330739},
doi = {10.1145/3292500.3330739},
booktitle = {Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery \& Data Mining},
pages = {2412–2420},
numpages = {9},
keywords = {embedding, multi-task learning, recommendation systems, visual search},
location = {Anchorage, AK, USA},
series = {KDD '19}
}

@misc{enevoldsen2025mmtebmassivemultilingualtext,
      title={MMTEB: Massive Multilingual Text Embedding Benchmark}, 
      author={Kenneth Enevoldsen and Isaac Chung and Imene Kerboua and Márton Kardos and Ashwin Mathur and David Stap and Jay Gala and Wissam Siblini and Dominik Krzemiński and Genta Indra Winata and Saba Sturua and Saiteja Utpala and Mathieu Ciancone and Marion Schaeffer and Gabriel Sequeira and Diganta Misra and Shreeya Dhakal and Jonathan Rystrøm and Roman Solomatin and Ömer Çağatan and Akash Kundu and Martin Bernstorff and Shitao Xiao and Akshita Sukhlecha and Bhavish Pahwa and Rafał Poświata and Kranthi Kiran GV and Shawon Ashraf and Daniel Auras and Björn Plüster and Jan Philipp Harries and Loïc Magne and Isabelle Mohr and Mariya Hendriksen and Dawei Zhu and Hippolyte Gisserot-Boukhlef and Tom Aarsen and Jan Kostkan and Konrad Wojtasik and Taemin Lee and Marek Šuppa and Crystina Zhang and Roberta Rocca and Mohammed Hamdy and Andrianos Michail and John Yang and Manuel Faysse and Aleksei Vatolin and Nandan Thakur and Manan Dey and Dipam Vasani and Pranjal Chitale and Simone Tedeschi and Nguyen Tai and Artem Snegirev and Michael Günther and Mengzhou Xia and Weijia Shi and Xing Han Lù and Jordan Clive and Gayatri Krishnakumar and Anna Maksimova and Silvan Wehrli and Maria Tikhonova and Henil Panchal and Aleksandr Abramov and Malte Ostendorff and Zheng Liu and Simon Clematide and Lester James Miranda and Alena Fenogenova and Guangyu Song and Ruqiya Bin Safi and Wen-Ding Li and Alessia Borghini and Federico Cassano and Hongjin Su and Jimmy Lin and Howard Yen and Lasse Hansen and Sara Hooker and Chenghao Xiao and Vaibhav Adlakha and Orion Weller and Siva Reddy and Niklas Muennighoff},
      year={2025},
      eprint={2502.13595},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2502.13595}, 
}

@misc{bai2023qwenvlversatilevisionlanguagemodel,
      title={Qwen-VL: A Versatile Vision-Language Model for Understanding, Localization, Text Reading, and Beyond}, 
      author={Jinze Bai and Shuai Bai and Shusheng Yang and Shijie Wang and Sinan Tan and Peng Wang and Junyang Lin and Chang Zhou and Jingren Zhou},
      year={2023},
      eprint={2308.12966},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2308.12966}, 
}

@misc{liu2023visualinstructiontuning,
      title={Visual Instruction Tuning}, 
      author={Haotian Liu and Chunyuan Li and Qingyang Wu and Yong Jae Lee},
      year={2023},
      eprint={2304.08485},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2304.08485}, 
}

@misc{kornblith2019betterimagenetmodelstransfer,
      title={Do Better ImageNet Models Transfer Better?}, 
      author={Simon Kornblith and Jonathon Shlens and Quoc V. Le},
      year={2019},
      eprint={1805.08974},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1805.08974}, 
}

@article{muennighoff2024generative,
  title={Generative representational instruction tuning},
  author={Muennighoff, Niklas and Su, Hongjin and Wang, Liang and Yang, Nan and Wei, Furu and Yu, Tao and Singh, Amanpreet and Kiela, Douwe},
  journal={arXiv preprint arXiv:2402.09906},
  year={2024}
}

@article{xiao2024rar,
  title={RAR-b: Reasoning as Retrieval Benchmark},
  author={Xiao, Chenghao and Hudson, G Thomas and Moubayed, Noura Al},
  journal={arXiv preprint arXiv:2404.06347},
  year={2024}
}

@inproceedings{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International conference on machine learning},
  pages={8748--8763},
  year={2021},
  organization={PMLR}
}

@article{koukounas2024jina,
  title={Jina CLIP: Your CLIP Model Is Also Your Text Retriever},
  author={Koukounas, Andreas and Mastrapas, Georgios and G{\"u}nther, Michael and Wang, Bo and Martens, Scott and Mohr, Isabelle and Sturua, Saba and Akram, Mohammad Kalim and Mart{\'\i}nez, Joan Fontanals and Ognawala, Saahil and others},
  journal={arXiv preprint arXiv:2405.20204},
  year={2024}
}

@inproceedings{zhai2023sigmoid,
  title={Sigmoid loss for language image pre-training},
  author={Zhai, Xiaohua and Mustafa, Basil and Kolesnikov, Alexander and Beyer, Lucas},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={11975--11986},
  year={2023}
}

@article{wei2023uniir,
  title={{UniIR}: Training and benchmarking universal multimodal information retrievers},
  author={Wei, Cong and Chen, Yang and Chen, Haonan and Hu, Hexiang and Zhang, Ge and Fu, Jie and Ritter, Alan and Chen, Wenhu},
  journal={arXiv preprint arXiv:2311.17136},
  year={2023}
}

@article{wang2019superglue,
  title={Superglue: A stickier benchmark for general-purpose language understanding systems},
  author={Wang, Alex and Pruksachatkun, Yada and Nangia, Nikita and Singh, Amanpreet and Michael, Julian and Hill, Felix and Levy, Omer and Bowman, Samuel},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@inproceedings{hendrycks2020measuring,
  title={Measuring Massive Multitask Language Understanding},
  author={Hendrycks, Dan and Burns, Collin and Basart, Steven and Zou, Andy and Mazeika, Mantas and Song, Dawn and Steinhardt, Jacob},
  booktitle={International Conference on Learning Representations},
  year={2020}
}

@inproceedings{reimers2019sentence,
  title={Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks},
  author={Reimers, Nils and Gurevych, Iryna},
  booktitle={Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)},
  pages={3982--3992},
  year={2019}
}

@inproceedings{thakur2021beir,
  title={BEIR: A Heterogeneous Benchmark for Zero-shot Evaluation of Information Retrieval Models},
  author={Thakur, Nandan and Reimers, Nils and R{\"u}ckl{\'e}, Andreas and Srivastava, Abhishek and Gurevych, Iryna},
  booktitle={Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track (Round 2)},
  year={2021}
}

@inproceedings{li2022blip,
  title={Blip: Bootstrapping language-image pre-training for unified vision-language understanding and generation},
  author={Li, Junnan and Li, Dongxu and Xiong, Caiming and Hoi, Steven},
  booktitle={International conference on machine learning},
  pages={12888--12900},
  year={2022},
  organization={PMLR}
}

@inproceedings{li2023blip2,
author = {Li, Junnan and Li, Dongxu and Savarese, Silvio and Hoi, Steven},
title = {BLIP-2: bootstrapping language-image pre-training with frozen image encoders and large language models},
year = {2023},
publisher = {JMLR.org},
abstract = {The cost of vision-and-language pre-training has become increasingly prohibitive due to end-to-end training of large-scale models. This paper proposes BLIP-2, a generic and efficient pretraining strategy that bootstraps vision-language pre-training from off-the-shelf frozen pretrained image encoders and frozen large language models. BLIP-2 bridges the modality gap with a lightweight Querying Transformer, which is pretrained in two stages. The first stage bootstraps vision-language representation learning from a frozen image encoder. The second stage bootstraps vision-to-language generative learning from a frozen language model. BLIP-2 achieves state-of-the-art performance on various vision-language tasks, despite having significantly fewer trainable parameters than existing methods. For example, our model outperforms Flamingo80B by 8.7\% on zero-shot VQAv2 with 54x fewer trainable parameters. We also demonstrate the model's capabilities of zero-shot image-to-text generation that can follow natural language instructions.},
booktitle = {Proceedings of the 40th International Conference on Machine Learning},
articleno = {814},
numpages = {13},
location = {Honolulu, Hawaii, USA},
series = {ICML'23}
}

@article{tong2024cambrian,
  title={Cambrian-1: A Fully Open, Vision-Centric Exploration of Multimodal LLMs},
  author={Tong, Shengbang and Brown, Ellis and Wu, Penghao and Woo, Sanghyun and Middepogu, Manoj and Akula, Sai Charitha and Yang, Jihan and Yang, Shusheng and Iyer, Adithya and Pan, Xichen and others},
  journal={arXiv preprint arXiv:2406.16860},
  year={2024}
}

@misc{faysse2024colpali,
      title={ColPali: Efficient Document Retrieval with Vision Language Models}, 
      author={Manuel Faysse and Hugues Sibille and Tony Wu and Bilel Omrani and Gautier Viaud and Céline Hudelot and Pierre Colombo},
      year={2024},
      eprint={2407.01449},
      archivePrefix={arXiv},
      primaryClass={cs.IR},
      url={https://arxiv.org/abs/2407.01449}, 
}

@inproceedings{
  yuksekgonul2023aro,
  title={When and why Vision-Language Models behave like  Bags-of-Words, and what to do about it?},
  author={Mert Yuksekgonul and Federico Bianchi and Pratyusha   Kalluri and Dan Jurafsky and James Zou},
  booktitle={International Conference on Learning Representations},
  year={2023},
  url={https://openreview.net/forum?id=KRLUvxh8uaX}
}

@inproceedings{ypsilantis2023towards,
  title={Towards universal image embeddings: A large-scale dataset and challenge for generic image representations},
  author={Ypsilantis, Nikolaos-Antonios and Chen, Kaifeng and Cao, Bingyi and Lipovsk{\`y}, M{\'a}rio and Dogan-Sch{\"o}nberger, Pelin and Makosa, Grzegorz and Bluntschli, Boris and Seyedhosseini, Mojtaba and Chum, Ond{\v{r}}ej and Araujo, Andr{\'e}},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={11290--11301},
  year={2023}
}

@article{zhou2024vista,
  title={VISTA: Visualized Text Embedding For Universal Multi-Modal Retrieval},
  author={Zhou, Junjie and Liu, Zheng and Xiao, Shitao and Zhao, Bo and Xiong, Yongping},
  journal={arXiv preprint arXiv:2406.04292},
  year={2024}
}


@inproceedings{jia2021scaling,
  title={Scaling up visual and vision-language representation learning with noisy text supervision},
  author={Jia, Chao and Yang, Yinfei and Xia, Ye and Chen, Yi-Ting and Parekh, Zarana and Pham, Hieu and Le, Quoc and Sung, Yun-Hsuan and Li, Zhen and Duerig, Tom},
  booktitle={International conference on machine learning},
  pages={4904--4916},
  year={2021},
  organization={PMLR}
}

@article{gadre2024datacomp,
  title={Datacomp: In search of the next generation of multimodal datasets},
  author={Gadre, Samir Yitzhak and Ilharco, Gabriel and Fang, Alex and Hayase, Jonathan and Smyrnis, Georgios and Nguyen, Thao and Marten, Ryan and Wortsman, Mitchell and Ghosh, Dhruba and Zhang, Jieyu and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{sun2023eva,
  title={Eva-clip: Improved training techniques for clip at scale},
  author={Sun, Quan and Fang, Yuxin and Wu, Ledell and Wang, Xinlong and Cao, Yue},
  journal={arXiv preprint arXiv:2303.15389},
  year={2023}
}

@article{jiang2024e5,
  title={E5-v: Universal embeddings with multimodal large language models},
  author={Jiang, Ting and Song, Minghui and Zhang, Zihan and Huang, Haizhen and Deng, Weiwei and Sun, Feng and Zhang, Qi and Wang, Deqing and Zhuang, Fuzhen},
  journal={arXiv preprint arXiv:2407.12580},
  year={2024}
}

@article{jiang2024vlm2vec,
  title={VLM2Vec: Training Vision-Language Models for Massive Multimodal Embedding Tasks},
  author={Jiang, Ziyan and Meng, Rui and Yang, Xinyi and Yavuz, Semih and Zhou, Yingbo and Chen, Wenhu},
  journal={arXiv preprint arXiv:2410.05160},
  year={2024}
}

@inproceedings{chen2021empirical,
  title={An empirical study of training self-supervised vision transformers},
  author={Chen, Xinlei and Xie, Saining and He, Kaiming},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={9640--9649},
  year={2021}
}

@article{oquab2024dinov2,
  title={DINOv2: Learning Robust Visual Features without Supervision},
  author={Oquab, Maxime and Darcet, Timoth{\'e}e and Moutakanni, Th{\'e}o and Vo, Huy and Szafraniec, Marc and Khalidov, Vasil and Fernandez, Pierre and Haziza, Daniel and Massa, Francisco and El-Nouby, Alaaeldin and others},
  journal={Transactions on Machine Learning Research Journal},
  pages={1--31},
  year={2024}
}

@inproceedings{muennighoff2023mteb,
  title={{MTEB}: Massive Text Embedding Benchmark},
  author={Muennighoff, Niklas and Tazi, Nouamane and Magne, Loic and Reimers, Nils},
  booktitle={Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics},
  pages={2014--2037},
  year={2023}
}

@article{xiao2024pixel,
  title={Pixel Sentence Representation Learning},
  author={Xiao, Chenghao and Huang, Zhuoxu and Chen, Danlu and Hudson, G Thomas and Li, Yizhi and Duan, Haoran and Lin, Chenghua and Fu, Jie and Han, Jungong and Moubayed, Noura Al},
  journal={arXiv preprint arXiv:2402.08183},
  year={2024}
}

@article{chen2024bge,
  title={Bge m3-embedding: Multi-lingual, multi-functionality, multi-granularity text embeddings through self-knowledge distillation},
  author={Chen, Jianlv and Xiao, Shitao and Zhang, Peitian and Luo, Kun and Lian, Defu and Liu, Zheng},
  journal={arXiv preprint arXiv:2402.03216},
  year={2024}
}

@article{xiao2023c,
  title={C-pack: Packaged resources to advance general chinese embedding},
  author={Xiao, Shitao and Liu, Zheng and Zhang, Peitian and Muennighof, Niklas},
  journal={arXiv preprint arXiv:2309.07597},
  year={2023}
}

@inproceedings{liu2023edis,
  title={EDIS: Entity-Driven Image Search over Multimodal Web Content},
  author={Liu, Siqi and Feng, Weixi and Fu, Tsu-Jui and Chen, Wenhu and Wang, William},
  booktitle={Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing},
  pages={4877--4894},
  year={2023}
}

@inproceedings{cherti2023reproducible,
  title={Reproducible scaling laws for contrastive language-image learning},
  author={Cherti, Mehdi and Beaumont, Romain and Wightman, Ross and Wortsman, Mitchell and Ilharco, Gabriel and Gordon, Cade and Schuhmann, Christoph and Schmidt, Ludwig and Jitsev, Jenia},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={2818--2829},
  year={2023}
}

@inproceedings{wang2022language,
  title={What language model architecture and pretraining objective works best for zero-shot generalization?},
  author={Wang, Thomas and Roberts, Adam and Hesslow, Daniel and Le Scao, Teven and Chung, Hyung Won and Beltagy, Iz and Launay, Julien and Raffel, Colin},
  booktitle={International Conference on Machine Learning},
  pages={22964--22984},
  year={2022},
  organization={PMLR}
}

@inproceedings{deng2009imagenet,
  title={Imagenet: A large-scale hierarchical image database},
  author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
  booktitle={2009 IEEE conference on computer vision and pattern recognition},
  pages={248--255},
  year={2009},
  organization={Ieee}
}

@inproceedings{hsieh2023sugarcrepe,
  title={SugarCrepe: Fixing Hackable Benchmarks for Vision-Language Compositionality},
  author={Hsieh, Cheng-Yu and Zhang, Jieyu and Ma, Zixian and Kembhavi, Aniruddha and Krishna, Ranjay},
  booktitle={Thirty-Seventh Conference on Neural Information Processing Systems Datasets and Benchmarks Track},
  year={2023}
}

@InProceedings{Thrush_2022_CVPR,
    author    = {Thrush, Tristan and Jiang, Ryan and Bartolo, Max and Singh, Amanpreet and Williams, Adina and Kiela, Douwe and Ross, Candace},
    title     = {Winoground: Probing Vision and Language Models for Visio-Linguistic Compositionality},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    month     = {June},
    year      = {2022},
    pages     = {5238-5248}
}

@inproceedings{wu2024scimmir,
  title={SciMMIR: Benchmarking Scientific Multi-modal Information Retrieval},
  author={Wu, Siwei and Li, Yizhi and Zhu, Kang and Zhang, Ge and Liang, Yiming and Ma, Kaijing and Xiao, Chenghao and Zhang, Haoran and Yang, Bohao and Chen, Wenhu and  Huang, Wenhao and  Moubayed, Noura Al and  Fu, Jie and Lin, Chenghua},
  booktitle    = {Proceedings of the 62nd Annual Meeting of the Association for Computational
                  Linguistics (ACL), findings},
  year={2024}
}

@misc{liu2024ocrbench,
      title={OCRBench: On the Hidden Mystery of OCR in Large Multimodal Models}, 
      author={Yuliang Liu and Zhang Li and Mingxin Huang and Biao Yang and Wenwen Yu and Chunyuan Li and Xucheng Yin and Cheng-lin Liu and Lianwen Jin and Xiang Bai},
      year={2024},
      eprint={2305.07895},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2305.07895}, 
}

@InProceedings{Johnson_2017_CVPR,
author = {Johnson, Justin and Hariharan, Bharath and van der Maaten, Laurens and Fei-Fei, Li and Lawrence Zitnick, C. and Girshick, Ross},
title = {CLEVR: A Diagnostic Dataset for Compositional Language and Elementary Visual Reasoning},
booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {July},
year = {2017}
}

@inproceedings{jin2024mm,
  title={MM-Soc: Benchmarking Multimodal Large Language Models in Social Media Platforms},
  author={Jin, Yiqiao and Choi, Minje and Verma, Gaurav and Wang, Jindong and Kumar, Srijan},
  booktitle={ACL},
  year={2024}
}

@misc{LAIONAICLIPbenchmark,
  author={LAION-AI},
  title={CLIP Benchmark},
  year={2024},
url={https://github.com/LAION-AI/CLIP_benchmark},
  note={Accessed: 2024-11-11},
  howpublished={\url{https://github.com/LAION-AI/CLIP_benchmark}},
  publisher={GitHub}
}

@inproceedings{thapliyal2022crossmodal,
  title={Crossmodal-3600: A Massively Multilingual Multimodal Evaluation Dataset},
  author={Thapliyal, Ashish V and Tuset, Jordi Pont and Chen, Xi and Soricut, Radu},
  booktitle={Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing},
  pages={715--729},
  year={2022}
}

@article{chen2020simclr,
  title={A Simple Framework for Contrastive Learning of Visual Representations},
  author={Chen, Ting and Kornblith, Simon and Norouzi, Mohammad and Hinton, Geoffrey},
  journal={arXiv preprint arXiv:2002.05709},
  year={2020}
}

@Article{he2019moco,
  author  = {Kaiming He and Haoqi Fan and Yuxin Wu and Saining Xie and Ross Girshick},
  title   = {Momentum Contrast for Unsupervised Visual Representation Learning},
  journal = {arXiv preprint arXiv:1911.05722},
  year    = {2019},
}

@article{cifar10,
title= {CIFAR-10 (Canadian Institute for Advanced Research)},
journal= {},
author= {Alex Krizhevsky and Vinod Nair and Geoffrey Hinton},
year= {},
url= {http://www.cs.toronto.edu/~kriz/cifar.html}
}


@article{yang2024law,
  title={Law of Vision Representation in MLLMs},
  author={Yang, Shijia and Zhai, Bohan and You, Quanzeng and Yuan, Jianbo and Yang, Hongxia and Xu, Chenfeng},
  journal={arXiv preprint arXiv:2408.16357},
  year={2024}
}

@InProceedings{Radenović_2018_CVPR,
author = {Radenović, Filip and Iscen, Ahmet and Tolias, Giorgos and Avrithis, Yannis and Chum, Ondřej},
title = {Revisiting Oxford and Paris: Large-Scale Image Retrieval Benchmarking},
booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2018}
}

@InProceedings{Weyand_2020_CVPR,
author = {Weyand, Tobias and Araujo, Andre and Cao, Bingyi and Sim, Jack},
title = {Google Landmarks Dataset v2 - A Large-Scale Benchmark for Instance-Level Recognition and Retrieval},
booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2020}
}


@InProceedings{pmlr-v162-bugliarello22a,
  title = 	 {{IGLUE}: A Benchmark for Transfer Learning across Modalities, Tasks, and Languages},
  author =       {Bugliarello, Emanuele and Liu, Fangyu and Pfeiffer, Jonas and Reddy, Siva and Elliott, Desmond and Ponti, Edoardo Maria and Vuli{\'c}, Ivan},
  booktitle = 	 {Proceedings of the 39th International Conference on Machine Learning},
  pages = 	 {2370--2392},
  year = 	 {2022},
  editor = 	 {Chaudhuri, Kamalika and Jegelka, Stefanie and Song, Le and Szepesvari, Csaba and Niu, Gang and Sabato, Sivan},
  volume = 	 {162},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {17--23 Jul},
  publisher =    {PMLR},
  pdf = 	 {https://proceedings.mlr.press/v162/bugliarello22a/bugliarello22a.pdf},
  url = 	 {https://proceedings.mlr.press/v162/bugliarello22a.html}
}

@article{Danon_2005_NMI,
   title={Comparing community structure identification},
   volume={2005},
   ISSN={1742-5468},
   url={http://dx.doi.org/10.1088/1742-5468/2005/09/P09008},
   DOI={10.1088/1742-5468/2005/09/p09008},
   number={09},
   journal={Journal of Statistical Mechanics: Theory and Experiment},
   publisher={IOP Publishing},
   author={Danon, Leon and Díaz-Guilera, Albert and Duch, Jordi and Arenas, Alex},
   year={2005},
   month=sep, pages={P09008–P09008} }

@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}

@inproceedings{kornblith2019better,
  title={Do better imagenet models transfer better?},
  author={Kornblith, Simon and Shlens, Jonathon and Le, Quoc V},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={2661--2671},
  year={2019}
}

@inproceedings{wang2020understanding,
  title={Understanding contrastive representation learning through alignment and uniformity on the hypersphere},
  author={Wang, Tongzhou and Isola, Phillip},
  booktitle={International conference on machine learning},
  pages={9929--9939},
  year={2020},
  organization={PMLR}
}

@misc{alain2018understandingintermediatelayersusing,
      title={Understanding intermediate layers using linear classifier probes}, 
      author={Guillaume Alain and Yoshua Bengio},
      year={2018},
      eprint={1610.01644},
      archivePrefix={arXiv},
      primaryClass={stat.ML},
      url={https://arxiv.org/abs/1610.01644}, 
}

@inproceedings{williams-etal-2018-broad,
    title = "A Broad-Coverage Challenge Corpus for Sentence Understanding through Inference",
    author = "Williams, Adina  and
      Nangia, Nikita  and
      Bowman, Samuel",
    editor = "Walker, Marilyn  and
      Ji, Heng  and
      Stent, Amanda",
    booktitle = "Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)",
    month = jun,
    year = "2018",
    address = "New Orleans, Louisiana",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N18-1101/",
    doi = "10.18653/v1/N18-1101",
    pages = "1112--1122",
}

@inproceedings{bowman-etal-2015-large,
    title = "A large annotated corpus for learning natural language inference",
    author = "Bowman, Samuel R.  and
      Angeli, Gabor  and
      Potts, Christopher  and
      Manning, Christopher D.",
    editor = "M{\`a}rquez, Llu{\'i}s  and
      Callison-Burch, Chris  and
      Su, Jian",
    booktitle = "Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing",
    month = sep,
    year = "2015",
    address = "Lisbon, Portugal",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D15-1075/",
    doi = "10.18653/v1/D15-1075",
    pages = "632--642"
}

@inproceedings{cer-etal-2017-semeval,
    title = "{S}em{E}val-2017 Task 1: Semantic Textual Similarity Multilingual and Crosslingual Focused Evaluation",
    author = "Cer, Daniel  and
      Diab, Mona  and
      Agirre, Eneko  and
      Lopez-Gazpio, I{\~n}igo  and
      Specia, Lucia",
    editor = "Bethard, Steven  and
      Carpuat, Marine  and
      Apidianaki, Marianna  and
      Mohammad, Saif M.  and
      Cer, Daniel  and
      Jurgens, David",
    booktitle = "Proceedings of the 11th International Workshop on Semantic Evaluation ({S}em{E}val-2017)",
    month = aug,
    year = "2017",
    address = "Vancouver, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/S17-2001/",
    doi = "10.18653/v1/S17-2001",
    pages = "1--14",
}

@inproceedings{agirre-etal-2013-sem,
    title = "*{SEM} 2013 shared task: Semantic Textual Similarity",
    author = "Agirre, Eneko  and
      Cer, Daniel  and
      Diab, Mona  and
      Gonzalez-Agirre, Aitor  and
      Guo, Weiwei",
    editor = "Diab, Mona  and
      Baldwin, Tim  and
      Baroni, Marco",
    booktitle = "Second Joint Conference on Lexical and Computational Semantics (*{SEM}), Volume 1: Proceedings of the Main Conference and the Shared Task: Semantic Textual Similarity",
    month = jun,
    year = "2013",
    address = "Atlanta, Georgia, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/S13-1004/",
    pages = "32--43"
}

@InProceedings{Berg_2014_CVPR,
        author = {Berg, Thomas and Liu, Jiongxin and Woo Lee, Seung and Alexander, Michelle L. and Jacobs, David W. and Belhumeur, Peter N.},
        title = {Birdsnap: Large-scale Fine-grained Visual Categorization of Birds},
        booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
        month = {June},
        year = {2014}
        }

@INPROCEEDINGS{caltech101,
        author={Li Fei-Fei and Fergus, R. and Perona, P.},
        booktitle={2004 Conference on Computer Vision and Pattern Recognition Workshop}, 
        title={Learning Generative Visual Models from Few Training Examples: An Incremental Bayesian Approach Tested on 101 Object Categories}, 
        year={2004},
        volume={},
        number={},
        pages={178-178},
        keywords={Bayesian methods;Testing;Humans;Maximum likelihood estimation;Assembly;Shape;Machine vision;Image recognition;Parameter estimation;Image databases},
        doi={10.1109/CVPR.2004.383}}

@TECHREPORT{Krizhevsky09learningcifar,
            author = {Alex Krizhevsky},
            title = {Learning multiple layers of features from tiny images},
            institution = {},
            year = {2009}
        }

@InProceedings{cimpoi14describing,
            Author    = {M. Cimpoi and S. Maji and I. Kokkinos and S. Mohamed and and A. Vedaldi},
            Title     = {Describing Textures in the Wild},
            Booktitle = {Proceedings of the {IEEE} Conf. on Computer Vision and Pattern Recognition ({CVPR})},
            Year      = {2014}}


@ARTICLE{Helber2019,
        author={Helber, Patrick and Bischke, Benjamin and Dengel, Andreas and Borth, Damian},
        journal={IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing}, 
        title={EuroSAT: A Novel Dataset and Deep Learning Benchmark for Land Use and Land Cover Classification}, 
        year={2019},
        volume={12},
        number={7},
        pages={2217-2226},
        keywords={Satellites;Earth;Remote sensing;Machine learning;Spatial resolution;Feature extraction;Benchmark testing;Dataset;deep convolutional neural network;deep learning;earth observation;land cover classification;land use classification;machine learning;remote sensing;satellite image classification;satellite images},
        doi={10.1109/JSTARS.2019.2918242}}


@misc{goodfellow2015,
        title={Explaining and Harnessing Adversarial Examples}, 
        author={Ian J. Goodfellow and Jonathon Shlens and Christian Szegedy},
        year={2015},
        eprint={1412.6572},
        archivePrefix={arXiv},
        primaryClass={stat.ML},
        url={https://arxiv.org/abs/1412.6572}, 
        }

@misc{maji2013aircraft,
            title={Fine-Grained Visual Classification of Aircraft}, 
            author={Subhransu Maji and Esa Rahtu and Juho Kannala and Matthew Blaschko and Andrea Vedaldi},
            year={2013},
            eprint={1306.5151},
            archivePrefix={arXiv},
            primaryClass={cs.CV},
            url={https://arxiv.org/abs/1306.5151}, 
        }

@inproceedings{bossard14,
        title = {Food-101 -- Mining Discriminative Components with Random Forests},
        author = {Bossard, Lukas and Guillaumin, Matthieu and Van Gool, Luc},
        booktitle = {European Conference on Computer Vision},
        year = {2014}
        }

@INPROCEEDINGS{Stallkamp2011,
  author={Stallkamp, Johannes and Schlipsing, Marc and Salmen, Jan and Igel, Christian},
  booktitle={The 2011 International Joint Conference on Neural Networks}, 
  title={The German Traffic Sign Recognition Benchmark: A multi-class classification competition}, 
  year={2011},
  volume={},
  number={},
  pages={1453-1460},
  keywords={Humans;Training;Image color analysis;Benchmark testing;Lead;Histograms;Image resolution},
  doi={10.1109/IJCNN.2011.6033395}}

@article{lecun2010mnist,
        title={MNIST handwritten digit database},
        author={LeCun, Yann and Cortes, Corinna and Burges, CJ},
        journal={ATT Labs [Online]. Available: http://yann.lecun.com/exdb/mnist},
        volume={2},
        year={2010}
        }

@INPROCEEDINGS{Nilsback2008,
  author={Nilsback, Maria-Elena and Zisserman, Andrew},
  booktitle={2008 Sixth Indian Conference on Computer Vision, Graphics \& Image Processing}, 
  title={Automated Flower Classification over a Large Number of Classes}, 
  year={2008},
  volume={},
  number={},
  pages={722-729},
  keywords={Shape;Kernel;Distributed computing;Support vector machines;Support vector machine classification;object classification;segmentation},
  doi={10.1109/ICVGIP.2008.47}}

@INPROCEEDINGS{Parkhi2012,
  author={Parkhi, Omkar M and Vedaldi, Andrea and Zisserman, Andrew and Jawahar, C. V.},
  booktitle={2012 IEEE Conference on Computer Vision and Pattern Recognition}, 
  title={Cats and dogs}, 
  year={2012},
  volume={},
  number={},
  pages={3498-3505},
  keywords={Positron emission tomography;Image segmentation;Cats;Dogs;Layout;Deformable models;Head},
  doi={10.1109/CVPR.2012.6248092}}

@article{lu2025retro,
  title={Retro-Search: Exploring Untaken Paths for Deeper and Efficient Reasoning},
  author={Lu, Ximing and Han, Seungju and Acuna, David and Kim, Hyunwoo and Jung, Jaehun and Prabhumoye, Shrimai and Muennighoff, Niklas and Patwary, Mostofa and Shoeybi, Mohammad and Catanzaro, Bryan and others},
  journal={arXiv preprint arXiv:2504.04383},
  year={2025}
}

@article{su2024bright,
  title={Bright: A realistic and challenging benchmark for reasoning-intensive retrieval},
  author={Su, Hongjin and Yen, Howard and Xia, Mengzhou and Shi, Weijia and Muennighoff, Niklas and Wang, Han-yu and Liu, Haisu and Shi, Quan and Siegel, Zachary S and Tang, Michael and others},
  journal={arXiv preprint arXiv:2407.12883},
  year={2024}
}

@InProceedings{veeling2018,
author="Veeling, Bastiaan S.
and Linmans, Jasper
and Winkens, Jim
and Cohen, Taco
and Welling, Max",
editor="Frangi, Alejandro F.
and Schnabel, Julia A.
and Davatzikos, Christos
and Alberola-L{\'o}pez, Carlos
and Fichtinger, Gabor",
title="Rotation Equivariant CNNs for Digital Pathology",
booktitle="Medical Image Computing and Computer Assisted Intervention -- MICCAI 2018",
year="2018",
publisher="Springer International Publishing",
address="Cham",
pages="210--218",
abstract="We propose a new model for digital pathology segmentation, based on the observation that histopathology images are inherently symmetric under rotation and reflection. Utilizing recent findings on rotation equivariant CNNs, the proposed model leverages these symmetries in a principled manner. We present a visual analysis showing improved stability on predictions, and demonstrate that exploiting rotation equivariance significantly improves tumor detection performance on a challenging lymph node metastases dataset. We further present a novel derived dataset to enable principled comparison of machine learning models, in combination with an initial benchmark. Through this dataset, the task of histopathology diagnosis becomes accessible as a challenging benchmark for fundamental machine learning research.",
isbn="978-3-030-00934-2"
}

@ARTICLE{cheng2017,
        author={Cheng, Gong and Han, Junwei and Lu, Xiaoqiang},
        journal={Proceedings of the IEEE}, 
        title={Remote Sensing Image Scene Classification: Benchmark and State of the Art}, 
        year={2017},
        volume={105},
        number={10},
        pages={1865-1883},
        keywords={Remote sensing;Benchmark testing;Spatial resolution;Social network services;Satellites;Image analysis;Machine learning;Unsupervised learning;Classification;Benchmark data set;deep learning;handcrafted features;remote sensing image;scene classification;unsupervised feature learning},
        doi={10.1109/JPROC.2017.2675998}}

@inproceedings{Krause2013CollectingAL,
        title={Collecting a Large-scale Dataset of Fine-grained Cars},
        author={Jonathan Krause and Jia Deng and Michael Stark and Li Fei-Fei},
        year={2013},
        url={https://api.semanticscholar.org/CorpusID:16632981}
        }

@InProceedings{pmlr-v15-coates11a,
        title = 	 {An Analysis of Single-Layer Networks in Unsupervised Feature Learning},
        author = 	 {Coates, Adam and Ng, Andrew and Lee, Honglak},
        booktitle = 	 {Proceedings of the Fourteenth International Conference on Artificial Intelligence and Statistics},
        pages = 	 {215--223},
        year = 	 {2011},
        editor = 	 {Gordon, Geoffrey and Dunson, David and Dudík, Miroslav},
        volume = 	 {15},
        series = 	 {Proceedings of Machine Learning Research},
        address = 	 {Fort Lauderdale, FL, USA},
        month = 	 {11--13 Apr},
        publisher =    {PMLR},
        pdf = 	 {http://proceedings.mlr.press/v15/coates11a/coates11a.pdf},
        url = 	 {https://proceedings.mlr.press/v15/coates11a.html},
        }

@INPROCEEDINGS{5539970,
        author={Xiao, Jianxiong and Hays, James and Ehinger, Krista A. and Oliva, Aude and Torralba, Antonio},
        booktitle={2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition}, 
        title={SUN database: Large-scale scene recognition from abbey to zoo}, 
        year={2010},
        volume={},
        number={},
        pages={3485-3492},
        doi={10.1109/CVPR.2010.5539970}}

@misc{soomro2012ucf101dataset101human,
      title={UCF101: A Dataset of 101 Human Actions Classes From Videos in The Wild}, 
      author={Khurram Soomro and Amir Roshan Zamir and Mubarak Shah},
      year={2012},
      eprint={1212.0402},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/1212.0402}, 
}

@Article{Everingham10,
            author = "Everingham, M. and Van~Gool, L. and Williams, C. K. I. and Winn, J. and Zisserman, A.",
            title = "The Pascal Visual Object Classes (VOC) Challenge",
            journal = "International Journal of Computer Vision",
            volume = "88",
            year = "2010",
            number = "2",
            month = jun,
            pages = "303--338",
        }

@inproceedings{Le2015TinyIV,
  title={Tiny ImageNet Visual Recognition Challenge},
  author={Ya Le and Xuan S. Yang},
  year={2015},
  url={https://api.semanticscholar.org/CorpusID:16664790}
}

@inproceedings{chang2022webqa,
      title={Webqa: Multihop and multimodal qa},
      author={Chang, Yingshan and Narang, Mridu and Suzuki, Hisami and Cao, Guihong and Gao, Jianfeng and Bisk, Yonatan},
      booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
      pages={16495--16504},
       year={2022}
      }

@InProceedings{Goyal_2017_CVPR,
author = {Goyal, Yash and Khot, Tejas and Summers-Stay, Douglas and Batra, Dhruv and Parikh, Devi},
title = {Making the v in VQA Matter: Elevating the Role of Image Understanding in Visual Question Answering},
booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {July},
year = {2017}
}

@inproceedings{gurari2018vizwiz,
  title={Vizwiz grand challenge: Answering visual questions from blind people},
  author={Gurari, Danna and Li, Qing and Stangl, Abigale J and Guo, Anhong and Lin, Chi and Grauman, Kristen and Luo, Jiebo and Bigham, Jeffrey P},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={3608--3617},
  year={2018}
}

@inproceedings{liu2021visual,
  title={Visual News: Benchmark and Challenges in News Image Captioning},
  author={Liu, Fuxiao and Wang, Yinghan and Wang, Tianlu and Ordonez, Vicente},
  booktitle={Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing},
  pages={6761--6771},
  year={2021}
}

@article{eitz2012humans,
  title={How do humans sketch objects?},
  author={Eitz, Mathias and Hays, James and Alexa, Marc},
  journal={ACM Transactions on graphics (TOG)},
  volume={31},
  number={4},
  pages={1--10},
  year={2012},
  publisher={Acm New York, NY, USA}
}

@inproceedings{oh2016deep,
  title={Deep metric learning via lifted structured feature embedding},
  author={Oh Song, Hyun and Xiang, Yu and Jegelka, Stefanie and Savarese, Silvio},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={4004--4012},
  year={2016}
}

@inproceedings{ypsilantis2021met,
  title={The {Met} dataset: Instance-level recognition for artworks},
  author={Ypsilantis, Nikolaos-Antonios and Garcia, Noa and Han, Guangxing and Ibrahimi, Sarah and Van Noord, Nanne and Tolias, Giorgos},
  booktitle={Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track (Round 2)},
  year={2021}
}

@article{peng2020rp2k,
  title={RP2K: A large-scale retail product dataset for fine-grained image classification},
  author={Peng, Jingtian and Xiao, Chang and Li, Yifan},
  journal={arXiv preprint arXiv:2006.12634},
  year={2020}
}

@inproceedings{hu2023open,
  title={Open-domain visual entity recognition: Towards recognizing millions of wikipedia entities},
  author={Hu, Hexiang and Luan, Yi and Chen, Yang and Khandelwal, Urvashi and Joshi, Mandar and Lee, Kenton and Toutanova, Kristina and Chang, Ming-Wei},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={12065--12075},
  year={2023}
}

@article{fu2024dreamsim,
  title={DreamSim: Learning New Dimensions of Human Visual Similarity using Synthetic Data},
  author={Fu, Stephanie and Tamir, Netanel and Sundaram, Shobhita and Chai, Lucy and Zhang, Richard and Dekel, Tali and Isola, Phillip},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@inproceedings{lin2014microsoft,
        title={Microsoft coco: Common objects in context},
        author={Lin, Tsung-Yi and Maire, Michael and Belongie, Serge and Hays, James and Perona, Pietro and Ramanan, Deva and Doll{\'a}r, Piotr and Zitnick, C Lawrence},
        booktitle={Computer Vision--ECCV 2014: 13th European Conference, Zurich, Switzerland, September 6-12, 2014, Proceedings, Part V 13},
        pages={740--755},
        year={2014},
        organization={Springer}
        }

@inproceedings{sharma2020semeval,
  title={SemEval-2020 Task 8: Memotion Analysis-the Visuo-Lingual Metaphor!},
  author={Sharma, Chhavi and Bhageria, Deepesh and Scott, William and Pykl, Srinivas and Das, Amitava and Chakraborty, Tanmoy and Pulabaigari, Viswanath and Gamb{\"a}ck, Bj{\"o}rn},
  booktitle={Proceedings of the Fourteenth Workshop on Semantic Evaluation},
  pages={759--773},
  year={2020}
}

@inproceedings{chen2023can,
  title={Can Pre-trained Vision and Language Models Answer Visual Information-Seeking Questions?},
  author={Chen, Yang and Hu, Hexiang and Luan, Yi and Sun, Haitian and Changpinyo, Soravit and Ritter, Alan and Chang, Ming-Wei},
  booktitle={Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing},
  pages={14948--14968},
  year={2023}
}

@article{krojer2022image,
  title={Image retrieval from contextual descriptions},
  author={Krojer, Benno and Adlakha, Vaibhav and Vineet, Vibhav and Goyal, Yash and Ponti, Edoardo and Reddy, Siva},
  journal={arXiv preprint arXiv:2203.15867},
  year={2022}
}

@article{kiela2020hateful,
  title={The hateful memes challenge: Detecting hate speech in multimodal memes},
  author={Kiela, Douwe and Firooz, Hamed and Mohan, Aravind and Goswami, Vedanuj and Singh, Amanpreet and Ringshia, Pratik and Testuggine, Davide},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={2611--2624},
  year={2020}
}

@misc{wu2023forbflatobjectretrieval,
            title={FORB: A Flat Object Retrieval Benchmark for Universal Image Embedding}, 
            author={Pengxiang Wu and Siman Wang and Kevin Dela Rosa and Derek Hao Hu},
            year={2023},
            eprint={2309.16249},
            archivePrefix={arXiv},
            primaryClass={cs.CV},
            url={https://arxiv.org/abs/2309.16249}, 
        }

@article{Young2014FromID,
  title={From image descriptions to visual denotations: New similarity metrics for semantic inference over event descriptions},
  author={Peter Young and Alice Lai and Micah Hodosh and J. Hockenmaier},
  journal={Transactions of the Association for Computational Linguistics},
  year={2014},
  volume={2},
  pages={67-78},
  url={https://api.semanticscholar.org/CorpusID:3104920}
}

@inproceedings{wu2021fashion,
  title={Fashion iq: A new dataset towards retrieving images by natural language feedback},
  author={Wu, Hui and Gao, Yupeng and Guo, Xiaoxiao and Al-Halah, Ziad and Rennie, Steven and Grauman, Kristen and Feris, Rogerio},
  booktitle={Proceedings of the IEEE/CVF Conference on computer vision and pattern recognition},
  pages={11307--11317},
  year={2021}
}

@inproceedings{han2017automatic,
  title={Automatic spatially-aware fashion concept discovery},
  author={Han, Xintong and Wu, Zuxuan and Huang, Phoenix X and Zhang, Xiao and Zhu, Menglong and Li, Yuan and Zhao, Yang and Davis, Larry S},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={1463--1471},
  year={2017}
}

@article{Welinder2010,
        author = {Welinder, Peter and Branson, Steve and Mita, Takeshi and Wah, Catherine and Schroff, Florian and Belongie, Serge and Perona, Pietro},
        year = {2010},
        month = {09},
        pages = {},
        title = {Caltech-UCSD Birds 200}
        }

@inproceedings{liu2021image,
        title={Image retrieval on real-life images with pre-trained vision-and-language models},
        author={Liu, Zheyuan and Rodriguez-Opazo, Cristian and Teney, Damien and Gould, Stephen},
        booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
        pages={2125--2134},
        year={2021}
        }

@article{fu2024blink,
  title={Blink: Multimodal large language models can see but not perceive},
  author={Fu, Xingyu and Hu, Yushi and Li, Bangzheng and Feng, Yu and Wang, Haoyu and Lin, Xudong and Roth, Dan and Smith, Noah A and Ma, Wei-Chiu and Krishna, Ranjay},
  journal={arXiv preprint arXiv:2404.12390},
  year={2024}
}

@misc{nussbaum2024nomic,
      title={Nomic Embed: Training a Reproducible Long Context Text Embedder}, 
      author={Zach Nussbaum and John X. Morris and Brandon Duderstadt and Andriy Mulyar},
      year={2024},
      eprint={2402.01613},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{nomicembedv2024nomic,
  title = {Nomic Embed Vision: Expanding The Nomic Latent Space},
  howpublished = {\url{https://www.nomic.ai/blog/posts/nomic-embed-vision}}
}

@misc{voyagemultimodal2024voyage,
  title = {voyage-multimodal-3: all-in-one embedding model for interleaved text, images, and screenshots},
  howpublished = {\url{https://blog.voyageai.com/2024/11/12/voyage-multimodal-3/}}
}

@misc{zhang2024gme,
      title={GME: Improving Universal Multimodal Retrieval by Multimodal LLMs}, 
      author={Zhang, Xin and Zhang, Yanzhao and Xie, Wen and Li, Mingxin and Dai, Ziqi and Long, Dingkun and Xie, Pengjun and Zhang, Meishan and Li, Wenjie and Zhang, Min},
      year={2024},
      eprint={2412.16855},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={http://arxiv.org/abs/2412.16855}, 
}

@inproceedings{
lin2025mmembed,
title={{MM}-{EMBED}: {UNIVERSAL} {MULTIMODAL} {RETRIEVAL} {WITH} {MULTIMODAL} {LLMS}},
author={Sheng-Chieh Lin and Chankyu Lee and Mohammad Shoeybi and Jimmy Lin and Bryan Catanzaro and Wei Ping},
booktitle={The Thirteenth International Conference on Learning Representations},
year={2025},
url={https://openreview.net/forum?id=i45NQb2iKO}
}