\begin{abstract}
Room reidentification (ReID) is a challenging yet essential task with numerous applications in fields such as augmented reality (AR) and homecare robotics. Existing visual place recognition (VPR) methods, which typically rely on global descriptors or aggregate local features, often struggle in cluttered indoor environments densely populated with man-made objects. These methods tend to overlook the crucial role of object-oriented information. To address this, we propose AirRoom, an object-aware pipeline that integrates multi-level object-oriented information—from global context to object patches, object segmentation, and keypoints—utilizing a coarse-to-fine retrieval approach. Extensive experiments on four newly constructed datasets—MPReID, HMReID, GibsonReID, and ReplicaReID—demonstrate that AirRoom outperforms state-of-the-art (SOTA) models across nearly all evaluation metrics, with improvements ranging from 6\% to 80\%. Moreover, AirRoom exhibits significant flexibility, allowing various modules within the pipeline to be substituted with different alternatives without compromising overall performance. It also shows robust and consistent performance under diverse viewpoint variations. Project website: \href{https://sairlab.org/airroom/}{\textcolor[rgb]{0.3,0.5,1}{https://sairlab.org/airroom/}}.

% Room reidentification (ReID) is a critical yet challenging research area with growing applications in fields such as augmented reality (AR) and homecare robots. 
% This work addresses a key question: What truly matters in room ReID? We examine various visual place recognition methods, finding that relying solely on global descriptors or aggregating local features to form a global descriptor does not yield optimal results. Instead, our findings emphasize the importance of objects, a factor often overlooked by previous models, which substantially enhances room ReID performance. Based on this insight, we introduce AirRoom—a novel, object-aware pipeline that significantly outperforms state-of-the-art (SOTA) models across nearly all evaluation metrics. AirRoom also demonstrates high flexibility and robustness to diverse viewpoint variations.

% Room reidentification (ReID) is a critical but underexplored research area with increasing applications in many fields such as augmented reality (AR) and homecare robots. This study addresses a compelling question: What truly matters for room ReID? To answer this question, we investigate various visual place recognition methods, revealing that directly use global descriptor or aggregate local feature to obtain global descriptor does not yield optimal performance. In contrast, we find that incorporating explicit object encoding, which is often overlooked by previous models, can significantly enhance performance for room ReID. Building on this insight, we introduce AirRoom, a novel object-aware pipeline that achieves significant improvements across nearly all metrics compared to state-of-the-art (SOTA) room ReID models. Additionally, AirRoom exhibits great flexibility and strong resilience to diverse viewpoint variations.
\end{abstract}