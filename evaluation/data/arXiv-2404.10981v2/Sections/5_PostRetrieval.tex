\subsection{Re-Ranking}
As retrieval mechanisms often return a large number of potentially relevant documents, re-ranking methods are employed to reorder these documents, prioritizing those most likely to contribute meaningfully to the final output. By leveraging various strategies, including unsupervised techniques, supervised learning, and data augmentation, re-ranking aims to optimize the alignment between the retrieved content and the desired response, thereby improving the overall effectiveness of RAG systems \cite{zhu2023large}.

\paragraph{Unsupervised Re-ranking} Unsupervised re-rankers do not rely on labeled data for training. They use strategies such as pointwise, listwise, or pairwise methods to rank documents based on LLM outputs without the need for supervised fine-tuning. For example, In-Context RALM \cite{ram2023incontext} employs a zero-shot approach where an off-the-shelf language model is used to re-rank the top-k documents retrieved by a BM25 retriever. This process involves selecting the document that maximizes the likelihood of the generated text, effectively using the LM's semantic understanding to improve document relevance without requiring additional supervised training. The paper also explores training a dedicated re-ranker using self-supervised learning to further enhance the selection of relevant documents, demonstrating that training a re-ranker with domain-specific data can be more effective than zero-shot re-ranking.

\paragraph{Supervised Re-ranking} Supervised re-rankers involve fine-tuning LLMs on specific ranking datasets. This category can be further divided into models like BERT that process query-document pairs to compute relevance scores, models like T5 that treat ranking as a generation task and use generated tokens to determine relevance, and models like RankLLaMA \cite{ma2024finetuning} that employ a prompt-based approach, focusing on the last token's representation for relevance calculation \cite{zhu2023large}. For instance, the re-ranker in Re2G \cite{glass2022reg} is based on a BERT model trained on labeled data (such as MS MARCO) and fine-tuned to improve the relevance ranking of retrieved documents. FiD-Light \cite{hofst√§tter2023fidlight} employs a supervised approach where the model is fine-tuned on specific datasets to learn how to re-rank passages effectively using source pointers during autoregressive text generation. The model uses a listwise auto-regressive re-ranking mechanism, trained to identify and re-rank relevant passages based on the output generated during the text generation process. GenRT \cite{xu2024listaware} utilizes a combination of an encoder to capture global list-level features and a sequential decoder to reorder documents based on relevance. The model is trained to learn relevance scores through supervised learning, guided by labeled relevance data, ensuring that the most pertinent documents are prioritized in the final reranked list. Furthermore, ITER-RETGEN \cite{shao2023enhancing} proposes using a more capable re-ranker, which has access to model generations, to distill knowledge into a dense retriever. This knowledge distillation process optimizes the query encoder of the dense retriever, enabling it to better capture the semantic relevance of documents relative to the task input.

\paragraph{Data Augmentation for Re-ranking} Data augmentation for re-rankers focuses on enhancing the training process by generating additional training data, such as pseudo-relevance labels, using LLMs. This data augmentation provides more varied training examples, which helps improve the performance of re-ranking models. For example, DKS-RAC \cite{huang2023retrieval} introduces methods like Dense Knowledge Similarity (DKS) and Retriever as Answer Classifier (RAC), which focus on improving the retrieval process by incorporating rich answer encodings. These methods involve generating additional training signals or utilizing enriched data representations to improve the retrieval and ranking of documents. Additionally, the PROMPTAGATOR \cite{dai2023promptagator} framework utilizes synthetic data generated through LLM-based query generation to enhance the training of the reranker. This data augmentation approach allows the re-ranker to refine candidate passages more effectively, using a cross-attention model trained on these additional examples to boost retrieval accuracy.

\subsection{Filtering}
Filtering and re-ranking are distinct processes in the post-retrieval stage of RAG systems. Filtering focuses on eliminating irrelevant or low-quality documents from the retrieved set, thereby reducing the document set size and improving efficiency and effectiveness in subsequent processing. In contrast, re-ranking orders the remaining documents based on their relevance or utility for the task, often prioritizing those that enhance the quality of the generated output, especially in response-aware scenarios.

Several filtering methods have been developed to refine document sets in RAG systems, each with unique mechanisms but sharing common goals of improving relevance and reducing computational load. Self-RAG \cite{asai2024selfrag} employs a self-reflection mechanism, utilizing special ``reflection tokens'' generated by the model to evaluate the relevance and quality of retrieved passages and the model's own generated outputs. This self-reflection ensures that only the most pertinent documents are retained, leveraging the model's internal capabilities without relying on external models during inference. Similarly, BlendFilter \cite{wang2024blendfilter} utilizes the LLM itself as the filter, assessing and removing irrelevant or less useful documents by applying filtering separately to knowledge retrieved from original, externally augmented, and internally augmented queries. Both Self-RAG and BlendFilter highlight the model's intrinsic ability to perform filtering, reducing the need for additional models and enhancing computational efficiency.

In contrast, RECOMP \cite{xu2024recomp} and CRAG \cite{yan2024corrective} employ more external or structural strategies. RECOMP focuses on selective augmentation, where summaries generated from retrieved documents are selectively prepended to the input for the language model. If the retrieved documents are deemed irrelevant, the compressor can generate an empty summary, effectively filtering out unnecessary information. This method allows for a dynamic approach to filtering, where only helpful content is retained. CRAG, on the other hand, uses a decompose-then-recompose approach, where retrieved documents are split into finer knowledge strips. These strips are evaluated for relevance using a fine-tuned T5 model, and only the relevant strips are recomposed to form a refined set of information for the generation task. This granular filtering process ensures that the final document set is both relevant and concise, tailored specifically to the generation task.

Dynamic filtering techniques are also employed in methods like FiD-TF \cite{berchansky2023optimizing} and CoK \cite{li2024chainofknowledge}. FiD-TF introduces Token Filtering during the decoding process, where less relevant tokens are dynamically filtered out based on cross-attention scores. This approach reduces the computational load by eliminating tokens deemed uninformative for generating the final answer, enhancing efficiency with minimal impact on performance. CoK employs a filtering technique based on self-consistency, identifying and processing only those questions with ``uncertain'' answers. This method works by sampling various reasoning paths and answers, preserving only predictions with high consistency. Questions that do not meet the specified consistency threshold undergo further processing, effectively preventing the propagation of errors in the generation process.

Finally, FILCO \cite{wang2023learning} implements a comprehensive filtering approach using three distinct strategies: String Inclusion (STRINC) to match exact outputs, Lexical Overlap to measure word-level similarity, and Conditional Cross-Mutual Information (CXMI) to assess how much the context improves output likelihood. FILCO applies these filtering strategies at the sentence level, refining the retrieved content for better relevance. Additionally, FILCO trains a context filtering model using these strategies, which predicts the most useful context at inference time, thereby enhancing the accuracy and relevance of the generation model's output.