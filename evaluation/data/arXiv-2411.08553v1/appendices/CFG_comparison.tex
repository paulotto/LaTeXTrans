\section{Comparing CFG and \corrsyn{}}
\label{sec:compare_cfg_corrsyn_app}
\subsection{Computational overhead of CFG}
\label{app:compute_complexity}

In this section we provide experimental comparison between CFG and \corrsyn{}. We discuss the complexity of CFG and feasibility of comparison. 

\paragraph{Computational Complexity} In general, it can be prohibitive to run CFG, depending on the task at hand. Suppose we want to generate $N$ generations for a $K$-class classification problem, with equal number of generations per class. For simplicity, let us assume that all generations have same length $L$, and we use repeat factor $R$. \corrsyn{} using any of Intra, Cross or Hybrid methods requires exactly $N\times L$ forward passes from the LLM (we ignore the overhead of computing the contrast between the logits vectors before sampling, as these vector operations are several magnitudes less expensive than the LLM forward passes).

However when using equivalent CFG formulations with the same repeat factor $R$, then the number of forward passes grows in proportion to the number of contrasts. Concretely, we require these number of forward passes:
\begin{itemize}
    \item \textbf{\textsc{CFG}-Intra}: $\frac{N}{R}\cdot R^2 \cdot L \\ { } = N\cdot R\cdot L $
    \item \textbf{\textsc{CFG}-Cross}: $\frac{N}{KR}\cdot (1+(K-1)R)KR\cdot L \\ { }  \approx N\cdot KR\cdot L $
    \item \textbf{\textsc{CFG}-Hybrid}: $\frac{N}{KR}\cdot (KR)^2\cdot L \\ { } = N\cdot KR\cdot L $
\end{itemize}

Thus, CFG requires a factor of $KR$ (or $R$ for Intra method) more forward passes than \corrsyn{}, to produce the same number of generations. This can be prohibitively large for even moderate $K$. For example, consider the \ToIHeadlines{} task. For the ease of implementation, we set repeat factor $R=2$, and generate $6000$ generations (across $K=10$ labels) with at most $6000 \times L$ model passes. But for CFG-Hybrid we must make $6000 \times 20 \times L$ forward passes, i.e. a \textit{20x compute cost}. For the same cost, we can generate a 20x more synthetic examples using \corrsyn, which can lead to much better accuracy and diversity. 

\paragraph{\textsc{CFG}-Intra vs \corrsyn-Intra} Due to the aforementioned complexity overhead in CFG, we found it challenging to compare CFG and \corrsyn{} under Cross or Hybrid contrast settings (as the former requited 20x compute budget).  Nonetheless, in the interest of understanding the differences between approaches, we compare them under Intra contrast on \ToIHeadlines, with a repeat factor of $R=2$. In this setting, CFG requires only 2x the compute budget of \corrsyn (the minimum possible). We choose the same parameters of gamma and delta as described in section~\ref{sec:corrsyn_results}: $\gamma=1.0$ and $\delta = 0.5\times\gamma = 0.5$. 

\autoref{tab:cfg-vs-corr-results} notes the results of this comparison. We see that, despite using twice the compute cost, CFG has comparable performance to \corrsyn{}. On the other hand, many previous works in dataset synthesis literature \citep{ye2022zerogen, ye2022progen, gao2023selfguided, meng_supergen} highlight a monotonic increase in student accuracy with the number of examples; thus, it may be more fruitful to spend the same compute budget to generate a dataset $KR$ times the size using \corrsyn.


\subsection{Ablation: effect of plausibility constraint}

We perform a qualitative and quantitative analysis to determine how the plausibility constraint ($\alpha$) affects the quality of synthetic datasets generated by CFG and \corrsyn{}. The quantitative results are shown in \autoref{tab:cfg-vs-corr-results} and the generations in \autoref{tab:cfg-vs-corr-generations}. 

Although the accuracy does not appear to be sensitive to $\alpha$, the effect of this parameter can be clearly seen in Mauve and Entity-Entropy. Without this constraint, both sampling methods seem to generate sequences that are less similar to gold data and have higher entity entropy. 

Furthermore, the actual generations show that setting $\alpha=0$ can, more often than not, results in incoherence (\autoref{tab:cfg-vs-corr-generations}). Thus we believe that it is important to apply the plausibility constraint to ensure coherent generations from both \corrsyn{} and \textsc{CFG}.

\input{table/cfg_vs_corr_toi_results}
\input{table/cfg_vs_corr_toi_generations}