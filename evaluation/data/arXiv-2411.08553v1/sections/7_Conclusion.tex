\section{Conclusion}
In this work, we propose a novel technique \corrsyn\ which uses correlated sampling and intuition from classifier free guidance and contrastive decoding to generate strongly diverse datasets across a variety of tasks with good cross-label separations. We provide the mathematical intuition of our approach and back our theoretical discussion with empirical results. Our extensive experimentation across 4 datasets show the robustness of our approach in generating synthetic data. 

In the future, we would like to study the effect of including Intra-label contrasts while generating with the LLMs, and mixing up both cross-label and Intra-label contrasts (a hybrid approach) to see how the generations are affected with respect to both intrinsic and extrinsic evaluation.