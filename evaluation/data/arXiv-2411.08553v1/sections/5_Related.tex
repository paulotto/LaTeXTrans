\section{Related Work}
\textbf{Dataset synthesis using LLMs.} In recent years LLMs have exhibited strong generative capabilities \cite{NEURIPS2020_1457c0d6, Cobbe2021TrainingVT} to solve a diverse range of tasks. With well-designed prompts, large-scale LLMs have shown its notable zero-shot and few-shot learning ability \cite{shin-etal-2020-autoprompt, jiang-etal-2020-know, 10.1145/3411763.3451760}. 

More recently, these models have gained popularity in their superior ability to synthesize task-specific datasets \cite{Wang2021TowardsZL, Lee2021NeuralDA, kumar-etal-2020-data, puri-etal-2020-training, AnabyTavor2019DoNH}. LLMs such as GPT-3 \cite{wang-etal-2023-self-instruct, honovich-etal-2023-unnatural, west-etal-2022-symbolic} and chat-tuned models \cite{Yehudai2024GenieAH, yu2023large, wang-etal-2023-lets} have shown promising results on the task of generating synthetic data. Certain works like \citet{Meng2023TuningLM} fine-tune an LLM to generate NLU datasets, whereas our work is similar to \citet{schick-schutze-2021-generating,Meng2022GeneratingTD} which use frozen LLMs with task-dependent prompts to generate data, targeting text classification.

\textbf{Text classification dataset synthesis} employs class-specific prompts; previous studies explored zero-shot \cite{Ye2022ZeroGenEZ} and iterative few-shot prompting \cite{ye-etal-2022-progen}. However, only recently has the lack of diversity in synthetic classification datasets been recognized. \citet{yu2023large} advocated for using diverse prompts that explicitly introduce variations, such as subtopics and brands, resulting in more diverse conditioning. In contrast, our approach achieves diversity with a fixed prompt. \citet{divekar2024synthesizrr} employs retrieval augmentation to introduce variety into the dataset synthesis process by seeding the LLM with different content. However, the diversity here is constrained by the corpus availability, whereas our work improves diversity despite relying only on LLM parameters.

% \textbf{Retrieval-augmented Generation} bypasses numerous problems associated with generating solely from parametric memory, i.e. heightened bias towards “head” entities \cite{mallen-etal-2023-trust}, lower lexical diversity \cite{Holtzman2020The},  \cite{jentzsch-kersting-2023-chatgpt}, and hallucinated and confabulated information \cite{Zhang2023SirensSI}.  \cite{yu-etal-2023-regen} studied the retrieval-only setting for creation of topic and sentiment datasets. 

\textbf{Classifier-Free Guidance (CFG)} is a sampling technique introduced in diffusion literature~\cite{ho2021classifierfree} and later extended to autoregressive LLMs~\cite{sanchez2023stay}. CFG falls under general guidance based techniques, where a guidance distribution is used at inference to alter the sampling distribution towards the desired goal.In CFG, this guidance distribution is provided by the LLM itself but with a different prompt as described in \aref{sec:CFG}. Context-aware decoding~\citet{Shi2023TrustingYE} also uses the same formulation as CFG.

\textbf{Contrastive decoding (CD} refers to another family of guidance based methods that derive the guidance distribution from either a smaller LLM~\cite{o2023contrastive,li2023contrastive}, different layers of the same LLM~\cite{chuang2023dola,gera-etal-2023-benefits}. In all these methods from CFG to CD, the idea is essentially that to generate a sequence, a contrasting distribution is computed at inference. But different sequences are generated independently. In \corrsyn{}, although we borrow the general idea of a using a guidance-providing distribution at inference, the guidance distribution itself corresponds to a actual parallel generation providing both a) (anti-)correlation between multiple sequences as desired, b) compute efficiency. See \autoref{sec:method} and \autoref{sec:compare_cfg_corrsyn_app}.

