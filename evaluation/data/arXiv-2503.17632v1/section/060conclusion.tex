\section{Conclusion}
We investigate bias mitigation in NLU datasets by 
% introducing a new approach that makes the a learner undecided when encountering biased inputs while being confident when processing full intact inputs. Our debiasing framework 
formulating the debiasing problem within a contrastive learning framework, incorporating explicit and implicit perturbation techniques and introducing undecided learning. Through extensive experiments across a range of NLU tasks, we demonstrate the effectiveness of our method in achieving improved debiasing performance, while maintaining performance on in-domain test sets. We find that existing methods (including ours) are still sensitive to dataset biases, and our experiments show the limitations of these approaches in fully addressing dataset biases. These results necessitate investigating a more systematic evaluation benchmark for debiasing. 
%
Our approach can potentially be improved by
investigating more complex biases~\citep{yao2023large,gandikota2023erasing}, 
exploring alternative training paradigms such as curriculum learning~\citep{bengio2009curriculum,vakil-amiri-2022-generic}, and evaluating robustness to unseen biases~\citep{NEURIPS2023_b0d9ceb3}. 
Beyond NLU, our work can potentially be applied to a broader range of applications~\citep{cheng2024mu,Liu_2024_WACV}.
