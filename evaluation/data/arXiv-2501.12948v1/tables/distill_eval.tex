\begin{table}[h]
    \centering
    \resizebox{\linewidth}{!}{
    \begin{tabular}{@{}l *{6}{c} @{}}
    \toprule
    \multirow{3}{*}{\centering\textbf{Model}} & \multicolumn{2}{c}{\multirow{2}{*}{\textbf{AIME 2024}}} & \multirow{2}{*}{\textbf{MATH-500}} & \textbf{GPQA} & \textbf{LiveCode} & \multirow{2}{*}{\textbf{CodeForces}} \\
    &  &  &  & \textbf{Diamond} & \textbf{Bench} \\
    \cmidrule(lr){2-3}
     & pass@1 & cons@64 & pass@1 & pass@1 & pass@1 & rating \\
    \midrule
    \textbf{GPT-4o-0513} & 9.3 & 13.4 & 74.6  & 49.9 & 32.9 &  759\\
    \textbf{Claude-3.5-Sonnet-1022} & 16.0 & 26.7 & 78.3  & 65.0 & 38.9 &  717\\
    \textbf{OpenAI-o1-mini} & 63.6 & 80.0 & 90.0 &  60.0 & 53.8 &  \textbf{1820}\\
    \textbf{QwQ-32B-Preview} & 50.0 & 60.0 & 90.6 & 54.5 & 41.9 &  1316 \\
    \midrule
    \textbf{DeepSeek-R1-Distill-Qwen-1.5B} & 28.9 & 52.7 & 83.9 & 33.8 & 16.9 & 954 \\
    \textbf{DeepSeek-R1-Distill-Qwen-7B} & 55.5 & 83.3 & 92.8 & 49.1 & 37.6 & 1189 \\
    \textbf{DeepSeek-R1-Distill-Qwen-14B} & 69.7 & 80.0 & 93.9 &  59.1 & 53.1 & 1481 \\
    \textbf{DeepSeek-R1-Distill-Qwen-32B} & \textbf{72.6} & {83.3} & {94.3} & {62.1} & {57.2} & 1691 \\
    \textbf{DeepSeek-R1-Distill-Llama-8B} & 50.4 & 80.0 & 89.1 & 49.0 & 39.6 & 1205 \\
    \textbf{DeepSeek-R1-Distill-Llama-70B} & 70.0 & \textbf{86.7} & \textbf{94.5} & \textbf{65.2} & \textbf{57.5} & 1633 \\
    \bottomrule
    \end{tabular}
    }
    \caption{Comparison of DeepSeek-R1 distilled models and other comparable models on reasoning-related benchmarks.}
    \label{tab:distill}
\end{table}

