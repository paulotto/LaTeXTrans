\begin{figure*}[t!]
    \centering
    \captionsetup{type=figure}
    \begin{subfigure}[t]{0.33\linewidth}
        \input{graphs/early_late/early_vs_late_scaleflops_getty}
    \end{subfigure}
    \begin{subfigure}[t]{0.32\linewidth}
        \input{graphs/early_late/early_vs_late_scaleflops_obelics}
    \end{subfigure}
    \begin{subfigure}[t]{0.32\linewidth}
    \input{graphs/early_late/early_vs_late_scaleflops_dclm}
    \end{subfigure}
    \begin{center}
        \ref{sharedlegend}
    \end{center}
    \caption{\textbf{Early vs late fusion: scaling training FLOPs.} We compare
    early and late fusion models when scaling both the number of model parameters and the number
    of training tokens. Overall, early fusion shows a slight advantage, especially at smaller model sizes, and the gap decreases when scaling the number of parameters $N$.}
    \label{fig:early_vs_late_scaleflops}
    \vspace{3mm}
\end{figure*}