@inproceedings{
    loshchilov2018decoupled,
    title={Decoupled Weight Decay Regularization},
    author={Ilya Loshchilov and Frank Hutter},
    booktitle={International Conference on Learning Representations},
    year={2019},
    url={https://openreview.net/forum?id=Bkg6RiCqY7},
}

@misc{o1,
  title={Learning to reason with LLMs},
  author={OpenAI},
  year={2024},
  url = {https://openai.com/index/learning-to-reason-with-llms/}
}

@misc{grok,
  title={Grok 3 Beta — The Age of Reasoning Agents},
  author={XAI},
  year={2024},
  url = {https://x.ai/news/grok-3}
}

@misc{gemini-thinking,
  title={Gemini 2.0 Flash Thinking},
  author={Google DeepMind},
  year={2024},
  url = {https://deepmind.google/technologies/gemini/flash-thinking/}
}

@misc{qwq,
  title={QwQ-32B: Embracing the Power of Reinforcement Learning},
  author={Qwen},
  year={2024},
  url = {https://qwenlm.github.io/blog/qwq-32b/}
}

@article{k1.5,
  title={Kimi k1. 5: Scaling reinforcement learning with llms},
  author={Team, Kimi and Du, Angang and Gao, Bofei and Xing, Bowei and Jiang, Changjiu and Chen, Cheng and Li, Cheng and Xiao, Chenjun and Du, Chenzhuang and Liao, Chonghua and others},
  journal={arXiv preprint arXiv:2501.12599},
  year={2025}
}

@article{gpt4,
  title={{GPT4} technical report},
  author={OpenAI},
  journal={arXiv preprint arXiv:2303.08774},
  year={2023}
}
@article{gandhi2025cognitive,
  title={Cognitive Behaviors that Enable Self-Improving Reasoners, or, Four Habits of Highly Effective STaRs},
  author={Gandhi, Kanishk and Chakravarthy, Ayush and Singh, Anikait and Lile, Nathan and Goodman, Noah D},
  journal={arXiv preprint arXiv:2503.01307},
  year={2025}
}
@misc{claude35sonnet,
  title = {Claude 3.5 Sonnet},
  author = {Anthropic},
  url = {https://www.anthropic.com/news/claude-3-5-sonnet},
  year={2024}
}
@article{wang2025thoughts,
  title={Thoughts Are All Over the Place: On the Underthinking of o1-Like LLMs},
  author={Wang, Yue and Liu, Qiuzhi and Xu, Jiahao and Liang, Tian and Chen, Xingyu and He, Zhiwei and Song, Linfeng and Yu, Dian and Li, Juntao and Zhang, Zhuosheng and others},
  journal={arXiv preprint arXiv:2501.18585},
  year={2025}
}
@article{cuadron2025danger,
  title={The Danger of Overthinking: Examining the Reasoning-Action Dilemma in Agentic Tasks},
  author={Cuadron, Alejandro and Li, Dacheng and Ma, Wenjie and Wang, Xingyao and Wang, Yichuan and Zhuang, Siyuan and Liu, Shu and Schroeder, Luis Gaspar and Xia, Tian and Mao, Huanzhi and others},
  journal={arXiv preprint arXiv:2502.08235},
  year={2025}
}
@inproceedings{NEURIPS2022_b1efde53,
 author = {Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and Schulman, John and Hilton, Jacob and Kelton, Fraser and Miller, Luke and Simens, Maddie and Askell, Amanda and Welinder, Peter and Christiano, Paul F and Leike, Jan and Lowe, Ryan},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {S. Koyejo and S. Mohamed and A. Agarwal and D. Belgrave and K. Cho and A. Oh},
 pages = {27730--27744},
 publisher = {Curran Associates, Inc.},
 title = {Training language models to follow instructions with human feedback},
 url = {https://proceedings.neurips.cc/paper_files/paper/2022/file/b1efde53be364a73914f58805a001731-Paper-Conference.pdf},
 volume = {35},
 year = {2022}
}

@article{schulman2017proximal,
  title={Proximal policy optimization algorithms},
  author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal={arXiv preprint arXiv:1707.06347},
  year={2017}
}
@article{deepseekmath,
  title={Deepseekmath: Pushing the limits of mathematical reasoning in open language models},
  author={Shao, Zhihong and Wang, Peiyi and Zhu, Qihao and Xu, Runxin and Song, Junxiao and Zhang, Mingchuan and Li, YK and Wu, Y and Guo, Daya},
  journal={arXiv preprint arXiv:2402.03300},
  year={2024}
}

@article{guo2025deepseek,
  title={Deepseek-r1: Incentivizing reasoning capability in llms via reinforcement learning},
  author={Guo, Daya and Yang, Dejian and Zhang, Haowei and Song, Junxiao and Zhang, Ruoyu and Xu, Runxin and Zhu, Qihao and Ma, Shirong and Wang, Peiyi and Bi, Xiao and others},
  journal={arXiv preprint arXiv:2501.12948},
  year={2025}
}
@article{alphazero,
  author       = {David Silver and
                  Thomas Hubert and
                  Julian Schrittwieser and
                  Ioannis Antonoglou and
                  Matthew Lai and
                  Arthur Guez and
                  Marc Lanctot and
                  Laurent Sifre and
                  Dharshan Kumaran and
                  Thore Graepel and
                  Timothy P. Lillicrap and
                  Karen Simonyan and
                  Demis Hassabis},
  title        = {Mastering Chess and Shogi by Self-Play with a General Reinforcement
                  Learning Algorithm},
  journal      = {CoRR},
  volume       = {abs/1712.01815},
  year         = {2017},
  url          = {http://arxiv.org/abs/1712.01815},
  eprinttype    = {arXiv},
  eprint       = {1712.01815},
  timestamp    = {Mon, 13 Aug 2018 16:46:01 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1712-01815.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{yang2024qwen2,
  title={Qwen2. 5 technical report},
  author={Yang, An and Yang, Baosong and Zhang, Beichen and Hui, Binyuan and Zheng, Bo and Yu, Bowen and Li, Chengyuan and Liu, Dayiheng and Huang, Fei and Wei, Haoran and others},
  journal={arXiv preprint arXiv:2412.15115},
  year={2024}
}

@misc{kl,
  title={Approximating kl divergence},
  author={John Schulman},
  year={2020},
  url = {http://joschu.net/blog/kl-approx.html}
}

@article{le2022coderl,
  title={Coderl: Mastering code generation through pretrained models and deep reinforcement learning},
  author={Le, Hung and Wang, Yue and Gotmare, Akhilesh Deepak and Savarese, Silvio and Hoi, Steven Chu Hong},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={21314--21328},
  year={2022}
}

@article{trinh2024solving,
  title={Solving olympiad geometry without human demonstrations},
  author={Trinh, Trieu H and Wu, Yuhuai and Le, Quoc V and He, He and Luong, Thang},
  journal={Nature},
  volume={625},
  number={7995},
  pages={476--482},
  year={2024},
  publisher={Nature Publishing Group UK London}
}

@article{sheng2024hybridflow,
  title={Hybridflow: A flexible and efficient rlhf framework},
  author={Sheng, Guangming and Zhang, Chi and Ye, Zilingfeng and Wu, Xibin and Zhang, Wang and Zhang, Ru and Peng, Yanghua and Lin, Haibin and Wu, Chuan},
  journal={arXiv preprint arXiv:2409.19256},
  year={2024}
}

@misc{amodei2016concreteproblemsaisafety,
      title={Concrete Problems in AI Safety}, 
      author={Dario Amodei and Chris Olah and Jacob Steinhardt and Paul Christiano and John Schulman and Dan Mané},
      year={2016},
      eprint={1606.06565},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/1606.06565}, 
}

@misc{everitt2017reinforcementlearningcorruptedreward,
      title={Reinforcement Learning with a Corrupted Reward Channel}, 
      author={Tom Everitt and Victoria Krakovna and Laurent Orseau and Marcus Hutter and Shane Legg},
      year={2017},
      eprint={1705.08417},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/1705.08417}, 
}

@misc{everitt2021rewardtamperingproblemssolutions,
      title={Reward Tampering Problems and Solutions in Reinforcement Learning: A Causal Influence Diagram Perspective}, 
      author={Tom Everitt and Marcus Hutter and Ramana Kumar and Victoria Krakovna},
      year={2021},
      eprint={1908.04734},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/1908.04734}, 
}

@misc{google2020specialgaming,
  title={Specification gaming: the flip side of AI ingenuity},
  author={Victoria Krakovna and Jonathan Uesato and Vladimir Mikulik and Matthew Rahtz and Tom Everitt and Ramana Kumar and Zac Kenton and Jan Leike and Shane Legg},
  year={2020},
  url = {https://deepmind.google/discover/blog/specification-gaming-the-flip-side-of-ai-ingenuity/}
}

@misc{gao2022scalinglawsrewardmodel,
      title={Scaling Laws for Reward Model Overoptimization}, 
      author={Leo Gao and John Schulman and Jacob Hilton},
      year={2022},
      eprint={2210.10760},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2210.10760}, 
}

@misc{langosco2023goalmisgeneralizationdeepreinforcement,
      title={Goal Misgeneralization in Deep Reinforcement Learning}, 
      author={Lauro Langosco and Jack Koch and Lee Sharkey and Jacob Pfau and Laurent Orseau and David Krueger},
      year={2023},
      eprint={2105.14111},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2105.14111}, 
}

@misc{pan2022effectsrewardmisspecificationmapping,
      title={The Effects of Reward Misspecification: Mapping and Mitigating Misaligned Models}, 
      author={Alexander Pan and Kush Bhatia and Jacob Steinhardt},
      year={2022},
      eprint={2201.03544},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2201.03544}, 
}

@article{weng2024rewardhack,
  title   = "Reward Hacking in Reinforcement Learning.",
  author  = "Weng, Lilian",
  journal = "lilianweng.github.io",
  year    = "2024",
  month   = "Nov",
  url     = "https://lilianweng.github.io/posts/2024-11-28-reward-hacking/"
}


@misc{polu2020generativelanguagemodelingautomated,
      title={Generative Language Modeling for Automated Theorem Proving}, 
      author={Stanislas Polu and Ilya Sutskever},
      year={2020},
      eprint={2009.03393},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2009.03393}, 
}

@misc{gehring2025rlefgroundingcodellms,
      title={RLEF: Grounding Code LLMs in Execution Feedback with Reinforcement Learning}, 
      author={Jonas Gehring and Kunhao Zheng and Jade Copet and Vegard Mella and Quentin Carbonneaux and Taco Cohen and Gabriel Synnaeve},
      year={2025},
      eprint={2410.02089},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2410.02089}, 
}

@misc{shinn2023reflexionlanguageagentsverbal,
      title={Reflexion: Language Agents with Verbal Reinforcement Learning}, 
      author={Noah Shinn and Federico Cassano and Edward Berman and Ashwin Gopinath and Karthik Narasimhan and Shunyu Yao},
      year={2023},
      eprint={2303.11366},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2303.11366}, 
}

@misc{chen2023teachinglargelanguagemodels,
      title={Teaching Large Language Models to Self-Debug}, 
      author={Xinyun Chen and Maxwell Lin and Nathanael Schärli and Denny Zhou},
      year={2023},
      eprint={2304.05128},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2304.05128}, 
}

@misc{google2024alphageometry,
  title={AlphaGeometry: An Olympiad-level AI system for geometry},
  author={Trieu Trinh and Thang Luong},
  year={2024},
  url = {https://deepmind.google/discover/blog/alphageometry-an-olympiad-level-ai-system-for-geometry/}
}

@misc{google2024alphaproofandalphageometry,
  title={AI achieves silver-medal standard solving International Mathematical Olympiad problems},
  author={AlphaProof and AlphaGeometry Teams},
  year={2024},
  url = {https://deepmind.google/discover/blog/ai-solves-imo-problems-at-silver-medal-level/}
}

@misc{schulman2018highdimensionalcontinuouscontrolusing,
      title={High-Dimensional Continuous Control Using Generalized Advantage Estimation}, 
      author={John Schulman and Philipp Moritz and Sergey Levine and Michael Jordan and Pieter Abbeel},
      year={2018},
      eprint={1506.02438},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1506.02438}, 
}

@article{gpt3,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}

@article{chowdhery2023palm,
  title={Palm: Scaling language modeling with pathways},
  author={Chowdhery, Aakanksha and Narang, Sharan and Devlin, Jacob and Bosma, Maarten and Mishra, Gaurav and Roberts, Adam and Barham, Paul and Chung, Hyung Won and Sutton, Charles and Gehrmann, Sebastian and others},
  journal={Journal of Machine Learning Research},
  volume={24},
  number={240},
  pages={1--113},
  year={2023}
}

@article{dsv3,
  title={Deepseek-v3 technical report},
  author={Liu, Aixin and Feng, Bei and Xue, Bing and Wang, Bingxuan and Wu, Bochao and Lu, Chengda and Zhao, Chenggang and Deng, Chengqi and Zhang, Chenyu and Ruan, Chong and others},
  journal={arXiv preprint arXiv:2412.19437},
  year={2024}
}

@article{rendarl,
  title={An Empirical Study on Eliciting and Improving R1-like Reasoning Models},
  author={Chen, Zhipeng and Min, Yingqian and Zhang, Beichen and Chen, Jie and Jiang, Jinhao and Cheng, Daixuan and Zhao, Wayne Xin and Liu, Zheng and Miao, Xu and Lu, Yang and others},
  journal={arXiv preprint arXiv:2503.04548},
  year={2025}
}
@misc{OpenReasonerZero2025,
  title={Open-Reasoner-Zero: An Open Source Approach to Scaling Reinforcement Learning on the Base Model},
  author={Jingcheng Hu and Yinmin Zhang and Qi Han and Daxin Jiang and Xiangyu Zhang, Heung-Yeung Shum},
  year={2025},
  howpublished={\url{https://github.com/Open-Reasoner-Zero/Open-Reasoner-Zero}},
}

@article{hu2025reinforce++,
  title={REINFORCE++: A Simple and Efficient Approach for Aligning Large Language Models},
  author={Hu, Jian},
  journal={arXiv preprint arXiv:2501.03262},
  year={2025}
}

@article{cui2025process,
  title={Process reinforcement through implicit rewards},
  author={Cui, Ganqu and Yuan, Lifan and Wang, Zefan and Wang, Hanbin and Li, Wendi and He, Bingxiang and Fan, Yuchen and Yu, Tianyu and Xu, Qixin and Chen, Weize and others},
  journal={arXiv preprint arXiv:2502.01456},
  year={2025}
}

@article{lee2024token,
  title={Token-Supervised Value Models for Enhancing Mathematical Reasoning Capabilities of Large Language Models},
  author={Lee, Jung Hyun and Yang, June Yong and Heo, Byeongho and Han, Dongyoon and Yoo, Kang Min},
  journal={arXiv preprint arXiv:2407.12863},
  year={2024}
}

@article{kazemnejad2024vineppo,
  title={Vineppo: Unlocking rl potential for llm reasoning through refined credit assignment},
  author={Kazemnejad, Amirhossein and Aghajohari, Milad and Portelance, Eva and Sordoni, Alessandro and Reddy, Siva and Courville, Aaron and Roux, Nicolas Le},
  journal={arXiv preprint arXiv:2410.01679},
  year={2024}
}

@article{yuan2025s,
  title={What's Behind PPO's Collapse in Long-CoT? Value Optimization Holds the Secret},
  author={Yuan, Yufeng and Yue, Yu and Zhu, Ruofei and Fan, Tiantian and Yan, Lin},
  journal={arXiv preprint arXiv:2503.01491},
  year={2025}
}

