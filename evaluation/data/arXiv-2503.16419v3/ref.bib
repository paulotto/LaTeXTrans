
% Journals

% First the Full Name is given, then the abbreviation used in the AMS Math
% Reviews, with an indication if it could not be found there.
% Note the 2nd overwrites the 1st, so swap them if you want the full name.

 %{AMS}
 @String{AMSTrans = "American Mathematical Society Translations" }
 @String{AMSTrans = "Amer. Math. Soc. Transl." }
 @String{BullAMS = "Bulletin of the American Mathematical Society" }
 @String{BullAMS = "Bull. Amer. Math. Soc." }
 @String{ProcAMS = "Proceedings of the American Mathematical Society" }
 @String{ProcAMS = "Proc. Amer. Math. Soc." }
 @String{TransAMS = "Transactions of the American Mathematical Society" }
 @String{TransAMS = "Trans. Amer. Math. Soc." }

 %ACM
 @String{CACM = "Communications of the {ACM}" }
 @String{CACM = "Commun. {ACM}" }
 @String{CompServ = "Comput. Surveys" }
 @String{JACM = "J. ACM" }
 @String{ACMMathSoft = "{ACM} Transactions on Mathematical Software" }
 @String{ACMMathSoft = "{ACM} Trans. Math. Software" }
 @String{SIGNUM = "{ACM} {SIGNUM} Newsletter" }
 @String{SIGNUM = "{ACM} {SIGNUM} Newslett." }

 @String{AmerSocio = "American Journal of Sociology" }
 @String{AmerStatAssoc = "Journal of the American Statistical Association" }
 @String{AmerStatAssoc = "J. Amer. Statist. Assoc." }
 @String{ApplMathComp = "Applied Mathematics and Computation" }
 @String{ApplMathComp = "Appl. Math. Comput." }
 @String{AmerMathMonthly = "American Mathematical Monthly" }
 @String{AmerMathMonthly = "Amer. Math. Monthly" }
 @String{BIT = "{BIT}" }
 @String{BritStatPsych = "British Journal of Mathematical and Statistical
          Psychology" }
 @String{BritStatPsych = "Brit. J. Math. Statist. Psych." }
 @String{CanMathBull = "Canadian Mathematical Bulletin" }
 @String{CanMathBull = "Canad. Math. Bull." }
 @String{CompApplMath = "Journal of Computational and Applied Mathematics" }
 @String{CompApplMath = "J. Comput. Appl. Math." }
 @String{CompPhys = "Journal of Computational Physics" }
 @String{CompPhys = "J. Comput. Phys." }
 @String{CompStruct = "Computers and Structures" }
 @String{CompStruct = "Comput. \& Structures" }
 @String{CompJour = "The Computer Journal" }
 @String{CompJour = "Comput. J." }
 @String{CompSysSci = "Journal of Computer and System Sciences" }
 @String{CompSysSci = "J. Comput. System Sci." }
 @String{Computing = "Computing" }
 @String{ContempMath = "Contemporary Mathematics" }
 @String{ContempMath = "Contemp. Math." }
 @String{Crelle = "Crelle's Journal" }
 @String{GiornaleMath = "Giornale di Mathematiche" }
 @String{GiornaleMath = "Giorn. Mat." } % didn't find in AMS MR., ibid.

 %IEEE
 @String{Computer = "{IEEE} Computer" }
 @String{IEEETransComp = "{IEEE} Transactions on Computers" }
 @String{IEEETransComp = "{IEEE} Trans. Comput." }
 @String{IEEETransAC = "{IEEE} Transactions on Automatic Control" }
 @String{IEEETransAC = "{IEEE} Trans. Automat. Control" }
 @String{IEEESpec = "{IEEE} Spectrum" } % didn't find in AMS MR
 @String{ProcIEEE = "Proceedings of the {IEEE}" }
 @String{ProcIEEE = "Proc. {IEEE}" } % didn't find in AMS MR
 @String{IEEETransAeroElec = "{IEEE} Transactions on Aerospace and Electronic
     Systems" }
 @String{IEEETransAeroElec = "{IEEE} Trans. Aerospace Electron. Systems" }

 @String{IMANumerAna = "{IMA} Journal of Numerical Analysis" }
 @String{IMANumerAna = "{IMA} J. Numer. Anal." }
 @String{InfProcLet = "Information Processing Letters" }
 @String{InfProcLet = "Inform. Process. Lett." }
 @String{InstMathApp = "Journal of the Institute of Mathematics and
     its Applications" }
 @String{InstMathApp = "J. Inst. Math. Appl." }
 @String{IntControl = "International Journal of Control" }
 @String{IntControl = "Internat. J. Control" }
 @String{IntNumerEng = "International Journal for Numerical Methods in
     Engineering" }
 @String{IntNumerEng = "Internat. J. Numer. Methods Engrg." }
 @String{IntSuper = "International Journal of Supercomputing Applications" }
 @String{IntSuper = "Internat. J. Supercomputing Applic." } % didn't find
%% in AMS MR
 @String{Kibernetika = "Kibernetika" }
 @String{JResNatBurStand = "Journal of Research of the National Bureau
     of Standards" }
 @String{JResNatBurStand = "J. Res. Nat. Bur. Standards" }
 @String{LinAlgApp = "Linear Algebra and its Applications" }
 @String{LinAlgApp = "Linear Algebra Appl." }
 @String{MathAnaAppl = "Journal of Mathematical Analysis and Applications" }
 @String{MathAnaAppl = "J. Math. Anal. Appl." }
 @String{MathAnnalen = "Mathematische Annalen" }
 @String{MathAnnalen = "Math. Ann." }
 @String{MathPhys = "Journal of Mathematical Physics" }
 @String{MathPhys = "J. Math. Phys." }
 @String{MathComp = "Mathematics of Computation" }
 @String{MathComp = "Math. Comp." }
 @String{MathScand = "Mathematica Scandinavica" }
 @String{MathScand = "Math. Scand." }
 @String{TablesAidsComp = "Mathematical Tables and Other Aids to Computation" }
 @String{TablesAidsComp = "Math. Tables Aids Comput." }
 @String{NumerMath = "Numerische Mathematik" }
 @String{NumerMath = "Numer. Math." }
 @String{PacificMath = "Pacific Journal of Mathematics" }
 @String{PacificMath = "Pacific J. Math." }
 @String{ParDistComp = "Journal of Parallel and Distributed Computing" }
 @String{ParDistComp = "J. Parallel and Distrib. Comput." } % didn't find
%% in AMS MR
 @String{ParComputing = "Parallel Computing" }
 @String{ParComputing = "Parallel Comput." }
 @String{PhilMag = "Philosophical Magazine" }
 @String{PhilMag = "Philos. Mag." }
 @String{ProcNAS = "Proceedings of the National Academy of Sciences
                    of the USA" }
 @String{ProcNAS = "Proc. Nat. Acad. Sci. U. S. A." }
 @String{Psychometrika = "Psychometrika" }
 @String{QuartMath = "Quarterly Journal of Mathematics, Oxford, Series (2)" }
 @String{QuartMath = "Quart. J. Math. Oxford Ser. (2)" }
 @String{QuartApplMath = "Quarterly of Applied Mathematics" }
 @String{QuartApplMath = "Quart. Appl. Math." }
 @String{RevueInstStat = "Review of the International Statisical Institute" }
 @String{RevueInstStat = "Rev. Inst. Internat. Statist." }

 %SIAM
 @String{JSIAM = "Journal of the Society for Industrial and Applied
     Mathematics" }
 @String{JSIAM = "J. Soc. Indust. Appl. Math." }
 @String{JSIAMB = "Journal of the Society for Industrial and Applied
     Mathematics, Series B, Numerical Analysis" }
 @String{JSIAMB = "J. Soc. Indust. Appl. Math. Ser. B Numer. Anal." }
 @String{SIAMAlgMeth = "{SIAM} Journal on Algebraic and Discrete Methods" }
 @String{SIAMAlgMeth = "{SIAM} J. Algebraic Discrete Methods" }
 @String{SIAMAppMath = "{SIAM} Journal on Applied Mathematics" }
 @String{SIAMAppMath = "{SIAM} J. Appl. Math." }
 @String{SIAMComp = "{SIAM} Journal on Computing" }
 @String{SIAMComp = "{SIAM} J. Comput." }
 @String{SIAMMatrix = "{SIAM} Journal on Matrix Analysis and Applications" }
 @String{SIAMMatrix = "{SIAM} J. Matrix Anal. Appl." }
 @String{SIAMNumAnal = "{SIAM} Journal on Numerical Analysis" }
 @String{SIAMNumAnal = "{SIAM} J. Numer. Anal." }
 @String{SIAMReview = "{SIAM} Review" }
 @String{SIAMReview = "{SIAM} Rev." }
 @String{SIAMSciStat = "{SIAM} Journal on Scientific and Statistical
     Computing" }
 @String{SIAMSciStat = "{SIAM} J. Sci. Statist. Comput." }

 @String{SoftPracExp = "Software Practice and Experience" }
 @String{SoftPracExp = "Software Prac. Experience" } % didn't find in AMS MR
 @String{StatScience = "Statistical Science" }
 @String{StatScience = "Statist. Sci." }
 @String{Techno = "Technometrics" }
 @String{USSRCompMathPhys = "{USSR} Computational Mathematics and Mathematical
     Physics" }
 @String{USSRCompMathPhys = "{U. S. S. R.} Comput. Math. and Math. Phys." }
 @String{VLSICompSys = "Journal of {VLSI} and Computer Systems" }
 @String{VLSICompSys = "J. {VLSI} Comput. Syst." }
 @String{ZAngewMathMech = "Zeitschrift fur Angewandte Mathematik und
     Mechanik" }
 @String{ZAngewMathMech = "Z. Angew. Math. Mech." }
 @String{ZAngewMathPhys = "Zeitschrift fur Angewandte Mathematik und Physik" }
 @String{ZAngewMathPhys = "Z. Angew. Math. Phys." }

% Publishers % ================================================= |

 @String{Academic = "Academic Press" }
 @String{ACMPress = "{ACM} Press" }
 @String{AdamHilger = "Adam Hilger" }
 @String{AddisonWesley = "Addison-Wesley" }
 @String{AllynBacon = "Allyn and Bacon" }
 @String{AMS = "American Mathematical Society" }
 @String{Birkhauser = "Birkh{\"a}user" }
 @String{CambridgePress = "Cambridge University Press" }
 @String{Chelsea = "Chelsea" }
 @String{ClaredonPress = "Claredon Press" }
 @String{DoverPub = "Dover Publications" }
 @String{Eyolles = "Eyolles" }
 @String{HoltRinehartWinston = "Holt, Rinehart and Winston" }
 @String{Interscience = "Interscience" }
 @String{JohnsHopkinsPress = "The Johns Hopkins University Press" }
 @String{JohnWileySons = "John Wiley and Sons" }
 @String{Macmillan = "Macmillan" }
 @String{MathWorks = "The Math Works Inc." }
 @String{McGrawHill = "McGraw-Hill" }
 @String{NatBurStd = "National Bureau of Standards" }
 @String{NorthHolland = "North-Holland" }
 @String{OxfordPress = "Oxford University Press" }  %address Oxford or London?
 @String{PergamonPress = "Pergamon Press" }
 @String{PlenumPress = "Plenum Press" }
 @String{PrenticeHall = "Prentice-Hall" }
 @String{SIAMPub = "{SIAM} Publications" }
 @String{Springer = "Springer-Verlag" }
 @String{TexasPress = "University of Texas Press" }
 @String{VanNostrand = "Van Nostrand" }
 @String{WHFreeman = "W. H. Freeman and Co." }

%Entries

@article{hu2022lora,
  title={Lora: Low-rank adaptation of large language models.},
  author={Hu, Edward J and Shen, Yelong and Wallis, Phillip and Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang, Lu and Chen, Weizhu and others},
  journal={ICLR},
  volume={1},
  number={2},
  pages={3},
  year={2022}
}

@article{yu2024distilling,
  title={Distilling system 2 into system 1},
  author={Yu, Ping and Xu, Jing and Weston, Jason and Kulikov, Ilia},
  journal={arXiv preprint arXiv:2407.06023},
  year={2024}
}

@article{munkhbat2025self,
  title={Self-Training Elicits Concise Reasoning in Large Language Models},
  author={Munkhbat, Tergel and Ho, Namgyu and Kim, Seohyun and Yang, Yongjin and Kim, Yujin and Yun, Se-Young},
  journal={arXiv preprint arXiv:2502.20122},
  year={2025}
}

@article{kang2024c3ot,
  title={C3oT: Generating Shorter Chain-of-Thought without Compromising Effectiveness},
  author={Kang, Yu and Sun, Xianghui and Chen, Liangyu and Zou, Wei},
  journal={arXiv preprint arXiv:2412.11664},
  year={2024}
}

@article{liu2024can,
  title={Can language models learn to skip steps?},
  author={Liu, Tengxiao and Guo, Qipeng and Hu, Xiangkun and Jiayang, Cheng and Zhang, Yue and Qiu, Xipeng and Zhang, Zheng},
  journal={arXiv preprint arXiv:2411.01855},
  year={2024}
}

@article{xia2025tokenskip,
  title={Tokenskip: Controllable chain-of-thought compression in llms},
  author={Xia, Heming and Li, Yongqi and Leong, Chak Tou and Wang, Wenjie and Li, Wenjie},
  journal={arXiv preprint arXiv:2502.12067},
  year={2025}
}

@article{ma2025cot,
  title={CoT-Valve: Length-Compressible Chain-of-Thought Tuning},
  author={Ma, Xinyin and Wan, Guangnian and Yu, Runpeng and Fang, Gongfan and Wang, Xinchao},
  journal={arXiv preprint arXiv:2502.09601},
  year={2025}
}

@article{yeo2025demystifying,
  title={Demystifying Long Chain-of-Thought Reasoning in LLMs},
  author={Yeo, Edward and Tong, Yuxuan and Niu, Morry and Neubig, Graham and Yue, Xiang},
  journal={arXiv preprint arXiv:2502.03373},
  year={2025}
}

@article{besta2025reasoning,
  title={Reasoning Language Models: A Blueprint},
  author={Besta, Maciej and Barth, Julia and Schreiber, Eric and Kubicek, Ales and Catarino, Afonso and Gerstenberger, Robert and Nyczyk, Piotr and Iff, Patrick and Li, Yueling and Houliston, Sam and others},
  journal={arXiv preprint arXiv:2501.11223},
  year={2025}
}

@article{aggarwal2025l1,
  title={L1: Controlling How Long A Reasoning Model Thinks With Reinforcement Learning},
  author={Aggarwal, Pranjal and Welleck, Sean},
  journal={arXiv preprint arXiv:2503.04697},
  year={2025}
}

@article{shen2025dast,
  title={DAST: Difficulty-Adaptive Slow-Thinking for Large Reasoning Models},
  author={Shen, Yi and Zhang, Jian and Huang, Jieyun and Shi, Shuming and Zhang, Wenjing and Yan, Jiangze and Wang, Ning and Wang, Kai and Lian, Shiguo},
  journal={arXiv preprint arXiv:2503.04472},
  year={2025}
}

@article{team2025kimi,
  title={Kimi k1. 5: Scaling reinforcement learning with llms},
  author={Team, Kimi and Du, Angang and Gao, Bofei and Xing, Bowei and Jiang, Changjiu and Chen, Cheng and Li, Cheng and Xiao, Chenjun and Du, Chenzhuang and Liao, Chonghua and others},
  journal={arXiv preprint arXiv:2501.12599},
  year={2025}
}

@article{yu2025think,
  title={Think Smarter not Harder: Adaptive Reasoning with Inference Aware Optimization},
  author={Yu, Zishun and Xu, Tengyu and Jin, Di and Sankararaman, Karthik Abinav and He, Yun and Zhou, Wenxuan and Zeng, Zhouhao and Helenowski, Eryk and Zhu, Chen and Wang, Sinong and others},
  journal={arXiv preprint arXiv:2501.17974},
  year={2025}
}

@article{luo2025o1,
  title={O1-Pruner: Length-Harmonizing Fine-Tuning for O1-Like Reasoning Pruning},
  author={Luo, Haotian and Shen, Li and He, Haiying and Wang, Yibo and Liu, Shiwei and Li, Wei and Tan, Naiqiang and Cao, Xiaochun and Tao, Dacheng},
  journal={arXiv preprint arXiv:2501.12570},
  year={2025}
}


@article{arora2025training,
  title={Training Language Models to Reason Efficiently},
  author={Arora, Daman and Zanette, Andrea},
  journal={arXiv preprint arXiv:2502.04463},
  year={2025}
}

@article{pang2025bolt,
  title={BOLT: Bootstrap Long Chain-of-Thought in Language Models without Distillation},
  author={Pang, Bo and Dong, Hanze and Xu, Jiacheng and Savarese, Silvio and Zhou, Yingbo and Xiong, Caiming},
  journal={arXiv preprint arXiv:2502.03860},
  year={2025}
}

@article{wu2025more,
  title={When More is Less: Understanding Chain-of-Thought Length in LLMs},
  author={Wu, Yuyang and Wang, Yifei and Du, Tianqi and Jegelka, Stefanie and Wang, Yisen},
  journal={arXiv preprint arXiv:2502.07266},
  year={2025}
}

# latent representation

@article{pfau2024let,
  title={Let's think dot by dot: Hidden computation in transformer language models},
  author={Pfau, Jacob and Merrill, William and Bowman, Samuel R},
  journal={arXiv preprint arXiv:2404.15758},
  year={2024}
}

@article{deng2024explicit,
  title={From explicit cot to implicit cot: Learning to internalize cot step by step},
  author={Deng, Yuntian and Choi, Yejin and Shieber, Stuart},
  journal={arXiv preprint arXiv:2405.14838},
  year={2024}
}

@article{geiping2025scaling,
  title={Scaling up Test-Time Compute with Latent Reasoning: A Recurrent Depth Approach},
  author={Geiping, Jonas and McLeish, Sean and Jain, Neel and Kirchenbauer, John and Singh, Siddharth and Bartoldson, Brian R and Kailkhura, Bhavya and Bhatele, Abhinav and Goldstein, Tom},
  journal={arXiv preprint arXiv:2502.05171},
  year={2025}
}

@article{hao2024training,
  title={Training large language models to reason in a continuous latent space},
  author={Hao, Shibo and Sukhbaatar, Sainbayar and Su, DiJia and Li, Xian and Hu, Zhiting and Weston, Jason and Tian, Yuandong},
  journal={arXiv preprint arXiv:2412.06769},
  year={2024}
}

@article{cheng2024compressed,
  title={Compressed chain of thought: Efficient reasoning through dense representations},
  author={Cheng, Jeffrey and Van Durme, Benjamin},
  journal={arXiv preprint arXiv:2412.13171},
  year={2024}
}

@article{shen2025efficient,
  title={Efficient Reasoning with Hidden Thinking},
  author={Shen, Xuan and Wang, Yizhou and Shi, Xiangxi and Wang, Yanzhi and Zhao, Pu and Gu, Jiuxiang},
  journal={arXiv preprint arXiv:2501.19201},
  year={2025}
}

@article{meng2024simpo,
  title={Simpo: Simple preference optimization with a reference-free reward},
  author={Meng, Yu and Xia, Mengzhou and Chen, Danqi},
  journal={Advances in Neural Information Processing Systems},
  volume={37},
  pages={124198--124235},
  year={2024}
}

@inproceedings{coulom2006efficient,
  title={Efficient selectivity and backup operators in Monte-Carlo tree search},
  author={Coulom, R{\'e}mi},
  booktitle={International conference on computers and games},
  pages={72--83},
  year={2006},
  organization={Springer}
}

@inproceedings{kocsis2006bandit,
  title={Bandit based monte-carlo planning},
  author={Kocsis, Levente and Szepesv{\'a}ri, Csaba},
  booktitle={European conference on machine learning},
  pages={282--293},
  year={2006},
  organization={Springer}
}

@article{liu2024kivi,
  title={Kivi: A tuning-free asymmetric 2bit quantization for kv cache},
  author={Liu, Zirui and Yuan, Jiayi and Jin, Hongye and Zhong, Shaochen and Xu, Zhaozhuo and Braverman, Vladimir and Chen, Beidi and Hu, Xia},
  journal={arXiv preprint arXiv:2402.02750},
  year={2024}
}

@article{chuang2025confident,
  title={Confident or Seek Stronger: Exploring Uncertainty-Based On-device LLM Routing From Benchmarking to Generalization},
  author={Chuang, Yu-Neng and Yu, Leisheng and Wang, Guanchu and Zhang, Lizhe and Liu, Zirui and Cai, Xuanting and Sui, Yang and Braverman, Vladimir and Hu, Xia},
  journal={arXiv preprint arXiv:2502.04428},
  year={2025}
}

@article{chuang2024learning1,
  title={Learning to compress prompt in natural language formats},
  author={Chuang, Yu-Neng and Xing, Tianwei and Chang, Chia-Yuan and Liu, Zirui and Chen, Xun and Hu, Xia},
  journal={arXiv preprint arXiv:2402.18700},
  year={2024}
}


@article{ong2024routellm,
  title={Routellm: Learning to route llms with preference data},
  author={Ong, Isaac and Almahairi, Amjad and Wu, Vincent and Chiang, Wei-Lin and Wu, Tianhao and Gonzalez, Joseph E and Kadous, M Waleed and Stoica, Ion},
  journal={arXiv preprint arXiv:2406.18665},
  year={2024}
}

@article{loshchilov2016sgdr,
  title={Sgdr: Stochastic gradient descent with warm restarts},
  author={Loshchilov, Ilya and Hutter, Frank},
  journal={arXiv preprint arXiv:1608.03983},
  year={2016}
}

@article{schulman2017proximal,
  title={Proximal policy optimization algorithms},
  author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal={arXiv preprint arXiv:1707.06347},
  year={2017}
}

@article{su2025token,
  title={Token Assorted: Mixing Latent and Text Tokens for Improved Language Model Reasoning},
  author={Su, DiJia and Zhu, Hanlin and Xu, Yingchen and Jiao, Jiantao and Tian, Yuandong and Zheng, Qinqing},
  journal={arXiv preprint arXiv:2502.03275},
  year={2025}
}

@article{xu2025softcot,
  title={SoftCoT: Soft Chain-of-Thought for Efficient Reasoning with LLMs},
  author={Xu, Yige and Guo, Xu and Zeng, Zhiwei and Miao, Chunyan},
  journal={arXiv preprint arXiv:2502.12134},
  year={2025}
}

@article{saunshi2025reasoning,
  title={Reasoning with Latent Thoughts: On the Power of Looped Transformers},
  author={Saunshi, Nikunj and Dikkala, Nishanth and Li, Zhiyuan and Kumar, Sanjiv and Reddi, Sashank J},
  journal={arXiv preprint arXiv:2502.17416},
  year={2025}
}

@article{shen2025codi,
  title={CODI: Compressing Chain-of-Thought into Continuous Space via Self-Distillation},
  author={Shen, Zhenyi and Yan, Hanqi and Zhang, Linhai and Hu, Zhanghao and Du, Yali and He, Yulan},
  journal={arXiv preprint arXiv:2502.21074},
  year={2025}
}

% SLMs
%% Knowledge Distillation
@article{li2025small,
  title={Small Models Struggle to Learn from Strong Reasoners},
  author={Li, Yuetai and Yue, Xiang and Xu, Zhangchen and Jiang, Fengqing and Niu, Luyao and Lin, Bill Yuchen and Ramasubramanian, Bhaskar and Poovendran, Radha},
  journal={arXiv preprint arXiv:2502.12143},
  year={2025}
}

@article{srivastava2025towards,
  title={Towards Reasoning Ability of Small Language Models},
  author={Srivastava, Gaurav and Cao, Shuxiang and Wang, Xuan},
  journal={arXiv preprint arXiv:2502.11569},
  year={2025}
}

@article{tomar2020mirror,
  title={Mirror descent policy optimization},
  author={Tomar, Manan and Shani, Lior and Efroni, Yonathan and Ghavamzadeh, Mohammad},
  journal={arXiv preprint arXiv:2005.09814},
  year={2020}
}

@article{shao2024deepseekmath,
  title={Deepseekmath: Pushing the limits of mathematical reasoning in open language models},
  author={Shao, Zhihong and Wang, Peiyi and Zhu, Qihao and Xu, Runxin and Song, Junxiao and Bi, Xiao and Zhang, Haowei and Zhang, Mingchuan and Li, YK and Wu, Y and others},
  journal={arXiv preprint arXiv:2402.03300},
  year={2024}
}

@inproceedings{chenglin2024mixed,
  title={Mixed Distillation Helps Smaller Language Models Reason Better},
  author={Chenglin, Li and Chen, Qianglong and Li, Liangyue and Wang, Caiyu and Tao, Feng and Li, Yicheng and Chen, Zulong and Zhang, Yin},
  booktitle={Findings of the Association for Computational Linguistics: EMNLP 2024},
  pages={1673--1690},
  year={2024}
}

@article{zhang2024small,
  title={Small language models need strong verifiers to self-correct reasoning},
  author={Zhang, Yunxiang and Khalifa, Muhammad and Logeswaran, Lajanugen and Kim, Jaekyeom and Lee, Moontae and Lee, Honglak and Wang, Lu},
  journal={arXiv preprint arXiv:2404.17140},
  year={2024}
}

@inproceedings{feng2024teaching,
  title={Teaching Small Language Models Reasoning through Counterfactual Distillation},
  author={Feng, Tao and Li, Yicheng and Chenglin, Li and Chen, Hao and Yu, Fei and Zhang, Yin},
  booktitle={Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing},
  pages={5831--5842},
  year={2024}
}

@article{zhu2024improving,
  title={Improving Mathematical Reasoning Capabilities of Small Language Models via Feedback-Driven Distillation},
  author={Zhu, Xunyu and Li, Jian and Ma, Can and Wang, Weiping},
  journal={arXiv preprint arXiv:2411.14698},
  year={2024}
}

@inproceedings{zhao2024probe,
  title={Probe then retrieve and reason: Distilling probing and reasoning capabilities into smaller language models},
  author={Zhao, Yichun and Zhou, Shuheng and Zhu, Huijia},
  booktitle={Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)},
  pages={13026--13032},
  year={2024}
}

@article{chen2024distilling,
  title={Distilling Reasoning Ability from Large Language Models with Adaptive Thinking},
  author={Chen, Xiaoshu and Zhou, Sihang and Liang, Ke and Liu, Xinwang},
  journal={arXiv preprint arXiv:2404.09170},
  year={2024}
}

@inproceedings{liao2025skintern,
  title={SKIntern: Internalizing Symbolic Knowledge for Distilling Better CoT Capabilities into Small Language Models},
  author={Liao, Huanxuan and He, Shizhu and Hao, Yupu and Li, Xiang and Zhang, Yuanzhe and Zhao, Jun and Liu, Kang},
  booktitle={Proceedings of the 31st International Conference on Computational Linguistics},
  pages={3203--3221},
  year={2025}
}

@article{fu2024efficiently,
  title={Efficiently Serving LLM Reasoning Programs with Certaindex},
  author={Fu, Yichao and Chen, Junda and Zhu, Siqi and Fu, Zheyu and Dai, Zhongdongming and Qiao, Aurick and Zhang, Hao},
  journal={arXiv preprint arXiv:2412.20993},
  year={2024}
}

@article{sui2025meta,
  title={Meta-Reasoner: Dynamic Guidance for Optimized Inference-time Reasoning in Large Language Models},
  author={Sui, Yuan and He, Yufei and Cao, Tri and Han, Simeng and Hooi, Bryan},
  journal={arXiv preprint arXiv:2502.19918},
  year={2025}
}

@article{chen2025inner,
  title={Inner Thinking Transformer: Leveraging Dynamic Depth Scaling to Foster Adaptive Internal Thinking},
  author={Chen, Yilong and Shang, Junyuan and Zhang, Zhenyu and Xie, Yanxi and Sheng, Jiawei and Liu, Tingwen and Wang, Shuohuan and Sun, Yu and Wu, Hua and Wang, Haifeng},
  journal={arXiv preprint arXiv:2502.13842},
  year={2025}
}

@article{han2024token,
  title={Token-budget-aware llm reasoning},
  author={Han, Tingxu and Fang, Chunrong and Zhao, Shiyu and Ma, Shiqing and Chen, Zhenyu and Wang, Zhenting},
  journal={arXiv preprint arXiv:2412.18547},
  year={2024}
}

@article{xu2025chain,
  title={Chain of Draft: Thinking Faster by Writing Less},
  author={Xu, Silei and Xie, Wenhao and Zhao, Lingxiao and He, Pengcheng},
  journal={arXiv preprint arXiv:2502.18600},
  year={2025}
}

@article{lee2025well,
  title={How Well do LLMs Compress Their Own Chain-of-Thought? A Token Complexity Approach},
  author={Lee, Ayeong and Che, Ethan and Peng, Tianyi},
  journal={arXiv preprint arXiv:2503.01141},
  year={2025}
}

@inproceedings{renze2024benefits,
  title={The benefits of a concise chain of thought on problem-solving in large language models},
  author={Renze, Matthew and Guven, Erhan},
  booktitle={2024 2nd International Conference on Foundation and Large Language Models (FLLM)},
  pages={476--483},
  year={2024},
  organization={IEEE}
}


@misc{ye2025limoreasoning,
      title={LIMO: Less is More for Reasoning}, 
      author={Yixin Ye and Zhen Huang and Yang Xiao and Ethan Chern and Shijie Xia and Pengfei Liu},
      year={2025},
      eprint={2502.03387},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2502.03387}, 
}

@misc{muennighoff2025s1simpletesttimescaling,
      title={s1: Simple test-time scaling}, 
      author={Niklas Muennighoff and Zitong Yang and Weijia Shi and Xiang Lisa Li and Li Fei-Fei and Hannaneh Hajishirzi and Luke Zettlemoyer and Percy Liang and Emmanuel Cand√®s and Tatsunori Hashimoto},
      year={2025},
      eprint={2501.19393},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2501.19393}, 
}

@misc{ma2025s2rteachingllmsselfverify,
      title={S$^2$R: Teaching LLMs to Self-verify and Self-correct via Reinforcement Learning}, 
      author={Ruotian Ma and Peisong Wang and Cheng Liu and Xingyan Liu and Jiaqi Chen and Bang Zhang and Xin Zhou and Nan Du and Jia Li},
      year={2025},
      eprint={2502.12853},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2502.12853}, 
}

@article{aytes2025sketch,
  title={Sketch-of-Thought: Efficient LLM Reasoning with Adaptive Cognitive-Inspired Sketching},
  author={Aytes, Simon A and Baek, Jinheon and Hwang, Sung Ju},
  journal={arXiv preprint arXiv:2503.05179},
  year={2025}
}

@article{liao2025reward,
  title={Reward-Guided Speculative Decoding for Efficient LLM Reasoning},
  author={Liao, Baohao and Xu, Yuhui and Dong, Hanze and Li, Junnan and Monz, Christof and Savarese, Silvio and Sahoo, Doyen and Xiong, Caiming},
  journal={arXiv preprint arXiv:2501.19324},
  year={2025}
}

@misc{parashar2025inferencetimecomputationsllmreasoning,
      title={Inference-Time Computations for LLM Reasoning and Planning: A Benchmark and Insights}, 
      author={Shubham Parashar and Blake Olson and Sambhav Khurana and Eric Li and Hongyi Ling and James Caverlee and Shuiwang Ji},
      year={2025},
      eprint={2502.12521},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2502.12521}, 
}

@misc{cuadron2025dangeroverthinkingexaminingreasoningaction,
      title={The Danger of Overthinking: Examining the Reasoning-Action Dilemma in Agentic Tasks}, 
      author={Alejandro Cuadron and Dacheng Li and Wenjie Ma and Xingyao Wang and Yichuan Wang and Siyuan Zhuang and Shu Liu and Luis Gaspar Schroeder and Tian Xia and Huanzhi Mao and Nicholas Thumiger and Aditya Desai and Ion Stoica and Ana Klimovic and Graham Neubig and Joseph E. Gonzalez},
      year={2025},
      eprint={2502.08235},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2502.08235}, 
}


@misc{liu20251bllmsurpass405b,
      title={Can 1B LLM Surpass 405B LLM? Rethinking Compute-Optimal Test-Time Scaling}, 
      author={Runze Liu and Junqi Gao and Jian Zhao and Kaiyan Zhang and Xiu Li and Biqing Qi and Wanli Ouyang and Bowen Zhou},
      year={2025},
      eprint={2502.06703},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2502.06703}, 
}

@article{li2025output,
  title={Output Length Effect on DeepSeek-R1's Safety in Forced Thinking},
  author={Li, Xuying and Li, Zhuo and Kosuga, Yuji and Bian, Victor},
  journal={arXiv preprint arXiv:2503.01923},
  year={2025}
}

@article{chen2024not,
  title={Do not think that much for 2+ 3=? on the overthinking of o1-like llms},
  author={Chen, Xingyu and Xu, Jiahao and Liang, Tian and He, Zhiwei and Pang, Jianhui and Yu, Dian and Song, Linfeng and Liu, Qiuzhi and Zhou, Mengfei and Zhang, Zhuosheng and others},
  journal={arXiv preprint arXiv:2412.21187},
  year={2024}
}

@article{wei2022chain,
  title={Chain-of-thought prompting elicits reasoning in large language models},
  author={Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Xia, Fei and Chi, Ed and Le, Quoc V and Zhou, Denny and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={24824--24837},
  year={2022}
}

@article{guo2025deepseek,
  title={Deepseek-r1: Incentivizing reasoning capability in llms via reinforcement learning},
  author={Guo, Daya and Yang, Dejian and Zhang, Haowei and Song, Junxiao and Zhang, Ruoyu and Xu, Runxin and Zhu, Qihao and Ma, Shirong and Wang, Peiyi and Bi, Xiao and others},
  journal={arXiv preprint arXiv:2501.12948},
  year={2025}
}

@misc{openai_learning_to_reason,
  author       = {OpenAI},
  title        = {Learning to Reason with LLMs},
  howpublished = {\\url{https://openai.com/index/learning-to-reason-with-llms/}},
  note         = {Accessed: 15 March 2025}
}

@article{li2025system,
  title={From System 1 to System 2: A Survey of Reasoning Large Language Models},
  author={Li, Zhong-Zhi and Zhang, Duzhen and Zhang, Ming-Liang and Zhang, Jiaxin and Liu, Zengyan and Yao, Yuxuan and Xu, Haotian and Zheng, Junhao and Wang, Pei-Jie and Chen, Xiuyi and others},
  journal={arXiv preprint arXiv:2502.17419},
  year={2025}
}

@misc{qwen_qwq_32b_preview,
  author       = {Qwen Team},
  title        = {QwQ-32B-Preview},
  howpublished = {\\url{https://qwenlm.github.io/blog/qwq-32b-preview/}},
  note         = {Accessed: 15 March 2025}
}

@inproceedings{wang2023self,
  title={Self-Consistency Improves Chain of Thought Reasoning in Language Models},
  author={Wang, Xuezhi and Wei, Jason and Schuurmans, Dale and Le, Quoc V and Chi, Ed H and Narang, Sharan and Chowdhery, Aakanksha and Zhou, Denny},
  booktitle={The Eleventh International Conference on Learning Representations}, 
  year={2023}
}

@article{yao2023tree,
  title={Tree of thoughts: Deliberate problem solving with large language models},
  author={Yao, Shunyu and Yu, Dian and Zhao, Jeffrey and Shafran, Izhak and Griffiths, Tom and Cao, Yuan and Narasimhan, Karthik},
  journal={Advances in neural information processing systems},
  volume={36},
  pages={11809--11822},
  year={2023}
}

@article{xu2025towards,
  title={Towards Large Reasoning Models: A Survey of Reinforced Reasoning with Large Language Models},
  author={Xu, Fengli and Hao, Qianyue and Zong, Zefang and Wang, Jingwei and Zhang, Yunke and Wang, Jingyi and Lan, Xiaochong and Gong, Jiahui and Ouyang, Tianjian and Meng, Fanjin and others},
  journal={arXiv preprint arXiv:2501.09686},
  year={2025}
}

@inproceedings{besta2024graph,
  title={Graph of thoughts: Solving elaborate problems with large language models},
  author={Besta, Maciej and Blach, Nils and Kubicek, Ales and Gerstenberger, Robert and Podstawski, Michal and Gianinazzi, Lukas and Gajda, Joanna and Lehmann, Tomasz and Niewiadomski, Hubert and Nyczyk, Piotr and others},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={38},
  number={16},
  pages={17682--17690},
  year={2024}
}

@article{uesato2022solving,
  title={Solving math word problems with process-and outcome-based feedback},
  author={Uesato, Jonathan and Kushman, Nate and Kumar, Ramana and Song, Francis and Siegel, Noah and Wang, Lisa and Creswell, Antonia and Irving, Geoffrey and Higgins, Irina},
  journal={arXiv preprint arXiv:2211.14275},
  year={2022}
}

@article{snell2024scaling,
  title={Scaling llm test-time compute optimally can be more effective than scaling model parameters},
  author={Snell, Charlie and Lee, Jaehoon and Xu, Kelvin and Kumar, Aviral},
  journal={arXiv preprint arXiv:2408.03314},
  year={2024}
}

@article{wu2024tokenselect,
  title={TokenSelect: Efficient Long-Context Inference and Length Extrapolation for LLMs via Dynamic Token-Level KV Cache Selection},
  author={Wu, Wei and Pan, Zhuoshi and Wang, Chao and Chen, Liyi and Bai, Yunchu and Fu, Kun and Wang, Zheng and Xiong, Hui},
  journal={arXiv preprint arXiv:2411.02886},
  year={2024}
}

@misc{beeching2024scalingtesttimecompute,
      title={Scaling test-time compute with open models},
      author={Edward Beeching and Lewis Tunstall and Sasha Rush},
      url={https://huggingface.co/spaces/HuggingFaceH4/blogpost-scaling-test-time-compute},
}

@article{ding2025dynamic,
  title={Dynamic Parallel Tree Search for Efficient LLM Reasoning},
  author={Ding, Yifu and Jiang, Wentao and Liu, Shunyu and Jing, Yongcheng and Guo, Jinyang and Wang, Yingjie and Zhang, Jing and Wang, Zengmao and Liu, Ziwei and Du, Bo and others},
  journal={arXiv preprint arXiv:2502.16235},
  year={2025}
}

@article{wang2025sampling,
  title={Sampling-Efficient Test-Time Scaling: Self-Estimating the Best-of-N Sampling in Early Decoding},
  author={Wang, Yiming and Zhang, Pei and Huang, Siyuan and Yang, Baosong and Zhang, Zhuosheng and Huang, Fei and Wang, Rui},
  journal={arXiv preprint arXiv:2503.01422},
  year={2025}
}

@article{sun2024fast,
  title={Fast best-of-n decoding via speculative rejection},
  author={Sun, Hanshi and Haider, Momin and Zhang, Ruiqi and Yang, Huitao and Qiu, Jiahao and Yin, Ming and Wang, Mengdi and Bartlett, Peter and Zanette, Andrea},
  journal={arXiv preprint arXiv:2410.20290},
  year={2024}
}

@article{li2025fastmcts,
  title={FastMCTS: A Simple Sampling Strategy for Data Synthesis},
  author={Li, Peiji and Lv, Kai and Shao, Yunfan and Ma, Yichuan and Li, Linyang and Zheng, Xiaoqing and Qiu, Xipeng and Guo, Qipeng},
  journal={arXiv preprint arXiv:2502.11476},
  year={2025}
}

@article{zhang2025lightthinker,
  title={LightThinker: Thinking Step-by-Step Compression},
  author={Zhang, Jintian and Zhu, Yuqi and Sun, Mengshu and Luo, Yujie and Qiao, Shuofei and Du, Lun and Zheng, Da and Chen, Huajun and Zhang, Ningyu},
  journal={arXiv preprint arXiv:2502.15589},
  year={2025}
}

@article{yan2025inftythink,
  title={InftyThink: Breaking the Length Limits of Long-Context Reasoning in Large Language Models},
  author={Yan, Yuchen and Shen, Yongliang and Liu, Yang and Jiang, Jin and Zhang, Mengdi and Shao, Jian and Zhuang, Yueting},
  journal={arXiv preprint arXiv:2503.06692},
  year={2025}
}

@article{van2017neural,
  title={Neural discrete representation learning},
  author={Van Den Oord, Aaron and Vinyals, Oriol and others},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@online{anthropic_claude_sonnet,
  author       = {Anthropic},
  title        = {Claude 3.7 Sonnet},
  year         = {2023},
  url          = {https://www.anthropic.com/news/claude-3-7-sonnet},
  note         = {Accessed: March 10, 2025}
}

@article{duan2022survey,
  title={A survey of embodied ai: From simulators to research tasks},
  author={Duan, Jiafei and Yu, Samson and Tan, Hui Li and Zhu, Hongyuan and Tan, Cheston},
  journal={IEEE Transactions on Emerging Topics in Computational Intelligence},
  volume={6},
  number={2},
  pages={230--244},
  year={2022},
  publisher={IEEE}
}

@article{grattafiori2024llama,
  title={The llama 3 herd of models},
  author={Grattafiori, Aaron and Dubey, Abhimanyu and Jauhri, Abhinav and Pandey, Abhinav and Kadian, Abhishek and Al-Dahle, Ahmad and Letman, Aiesha and Mathur, Akhil and Schelten, Alan and Vaughan, Alex and others},
  journal={arXiv preprint arXiv:2407.21783},
  year={2024}
}

@article{yang2024qwen2,
  title={Qwen2. 5 technical report},
  author={Yang, An and Yang, Baosong and Zhang, Beichen and Hui, Binyuan and Zheng, Bo and Yu, Bowen and Li, Chengyuan and Liu, Dayiheng and Huang, Fei and Wei, Haoran and others},
  journal={arXiv preprint arXiv:2412.15115},
  year={2024}
}

@article{touvron2023llama,
  title={Llama: Open and efficient foundation language models},
  author={Touvron, Hugo and Lavril, Thibaut and Izacard, Gautier and Martinet, Xavier and Lachaux, Marie-Anne and Lacroix, Timoth{\'e}e and Rozi{\`e}re, Baptiste and Goyal, Naman and Hambro, Eric and Azhar, Faisal and others},
  journal={arXiv preprint arXiv:2302.13971},
  year={2023}
}

@inproceedings{devlin2019bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  booktitle={Proceedings of the 2019 conference of the North American chapter of the association for computational linguistics: human language technologies, volume 1 (long and short papers)},
  pages={4171--4186},
  year={2019}
}

@article{cobbe2021training,
  title={Training verifiers to solve math word problems},
  author={Cobbe, Karl and Kosaraju, Vineet and Bavarian, Mohammad and Chen, Mark and Jun, Heewoo and Kaiser, Lukasz and Plappert, Matthias and Tworek, Jerry and Hilton, Jacob and Nakano, Reiichiro and others},
  journal={arXiv preprint arXiv:2110.14168},
  year={2021}
}

@article{chen2021evaluating,
  title={Evaluating large language models trained on code},
  author={Chen, Mark and Tworek, Jerry and Jun, Heewoo and Yuan, Qiming and Pinto, Henrique Ponde De Oliveira and Kaplan, Jared and Edwards, Harri and Burda, Yuri and Joseph, Nicholas and Brockman, Greg and others},
  journal={arXiv preprint arXiv:2107.03374},
  year={2021}
}

@inproceedings{hendrycks2measuring,
  title={Measuring Mathematical Problem Solving With the MATH Dataset},
  author={Hendrycks, Dan and Burns, Collin and Kadavath, Saurav and Arora, Akul and Basart, Steven and Tang, Eric and Song, Dawn and Steinhardt, Jacob},
  booktitle={Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track},
  year={2021}
}

@misc{codeforces,
  author       = {Codeforces},
  title        = {Codeforces - Competitive Programming Platform},
  year         = {2025},
  url          = {https://codeforces.com/},
  note         = {Accessed: 2025-03-18}
}

@inproceedings{lightman2023let,
  title={Let's verify step by step},
  author={Lightman, Hunter and Kosaraju, Vineet and Burda, Yuri and Edwards, Harrison and Baker, Bowen and Lee, Teddy and Leike, Jan and Schulman, John and Sutskever, Ilya and Cobbe, Karl},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2023}
}

@article{silver2017mastering,
  title={Mastering the game of go without human knowledge},
  author={Silver, David and Schrittwieser, Julian and Simonyan, Karen and Antonoglou, Ioannis and Huang, Aja and Guez, Arthur and Hubert, Thomas and Baker, Lucas and Lai, Matthew and Bolton, Adrian and others},
  journal={nature},
  volume={550},
  number={7676},
  pages={354--359},
  year={2017},
  publisher={Nature Publishing Group UK London}
}

@inproceedings{frantar2023gptq,
  title={GPTQ: Accurate Post-Training Quantization for Generative Pre-trained Transformers},
  author={Frantar, Elias and Ashkboos, Saleh and Hoefler, Torsten and Alistarh, Dan},
  booktitle={The Eleventh International Conference on Learning Representations},
  year={2023},
  organization={OpenReview}
}

@article{lin2024awq,
  title={Awq: Activation-aware weight quantization for on-device llm compression and acceleration},
  author={Lin, Ji and Tang, Jiaming and Tang, Haotian and Yang, Shang and Chen, Wei-Ming and Wang, Wei-Chen and Xiao, Guangxuan and Dang, Xingyu and Gan, Chuang and Han, Song},
  journal={Proceedings of Machine Learning and Systems},
  volume={6},
  pages={87--100},
  year={2024}
}

@article{zhang2023h2o,
  title={H2o: Heavy-hitter oracle for efficient generative inference of large language models},
  author={Zhang, Zhenyu and Sheng, Ying and Zhou, Tianyi and Chen, Tianlong and Zheng, Lianmin and Cai, Ruisi and Song, Zhao and Tian, Yuandong and R{\'e}, Christopher and Barrett, Clark and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={34661--34710},
  year={2023}
}

@inproceedings{cui2024survey,
  title={A survey on multimodal large language models for autonomous driving},
  author={Cui, Can and Ma, Yunsheng and Cao, Xu and Ye, Wenqian and Zhou, Yang and Liang, Kaizhao and Chen, Jintai and Lu, Juanwu and Yang, Zichong and Liao, Kuei-Da and others},
  booktitle={Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision},
  pages={958--979},
  year={2024}
}

@article{he2023survey,
  title={A Survey of Large Language Models for Healthcare: from Data, Technology, and Applications to Accountability and Ethics},
  author={He, Kai and Mao, Rui and Lin, Qika and Ruan, Yucheng and Lan, Xiang and Feng, Mengling and Cambria, Erik},
  journal={arXiv preprint arXiv:2310.05694},
  year={2023}
}



@article{liu2025adaptivestep,
  title={AdaptiveStep: Automatically Dividing Reasoning Step through Model Confidence},
  author={Liu, Yuliang and Lu, Junjie and Chen, Zhaoling and Qu, Chaofeng and Liu, Jason Klein and Liu, Chonghan and Cai, Zefan and Xia, Yunhui and Zhao, Li and Bian, Jiang and others},
  journal={arXiv preprint arXiv:2502.13943},
  year={2025}
}

@article{kuo2025h,
  title={H-cot: Hijacking the chain-of-thought safety reasoning mechanism to jailbreak large reasoning models, including openai o1/o3, deepseek-r1, and gemini 2.0 flash thinking},
  author={Kuo, Martin and Zhang, Jianyi and Ding, Aolin and Wang, Qinsi and DiValentin, Louis and Bao, Yujia and Wei, Wei and Juan, Da-Cheng and Li, Hai and Chen, Yiran},
  journal={arXiv preprint arXiv:2502.12893},
  year={2025}
}

@article{qu2025optimizing,
  title={Optimizing Test-Time Compute via Meta Reinforcement Fine-Tuning},
  author={Qu, Yuxiao and Yang, Matthew YR and Setlur, Amrith and Tunstall, Lewis and Beeching, Edward Emanuel and Salakhutdinov, Ruslan and Kumar, Aviral},
  journal={arXiv preprint arXiv:2503.07572},
  year={2025}
}

@article{cui2025stepwise,
  title={Stepwise Perplexity-Guided Refinement for Efficient Chain-of-Thought Reasoning in Large Language Models},
  author={Cui, Yingqian and He, Pengfei and Zeng, Jingying and Liu, Hui and Tang, Xianfeng and Dai, Zhenwei and Han, Yan and Luo, Chen and Huang, Jing and Li, Zhen and others},
  journal={arXiv preprint arXiv:2502.13260},
  year={2025}
}

@article{wen2025light,
  title={Light-R1: Curriculum SFT, DPO and RL for Long COT from Scratch and Beyond},
  author={Wen, Liang and Cai, Yunke and Xiao, Fenrui and He, Xin and An, Qi and Duan, Zhenyu and Du, Yimin and Liu, Junchen and Tang, Lifu and Lv, Xiaowei and others},
  journal={arXiv preprint arXiv:2503.10460},
  year={2025}
}

@article{xiang2025can,
  title={Can Atomic Step Decomposition Enhance the Self-structured Reasoning of Multimodal Large Models?},
  author={Xiang, Kun and Liu, Zhili and Jiang, Zihao and Nie, Yunshuang and Cai, Kaixin and Yin, Yiyang and Huang, Runhui and Fan, Haoxiang and Li, Hanhui and Huang, Weiran and others},
  journal={arXiv preprint arXiv:2503.06252},
  year={2025}
}

@article{sun2025tinyr1,
  title={TinyR1-32B-Preview: Boosting Accuracy with Branch-Merge Distillation},
  author={Sun, Lin and Zhao, Guangxiang and Jian, Xiaoqi and Wu, Yuhan and Lin, Weihong and Zhu, Yongfu and Zhang, Linglin and Wu, Jinzhu and Ran, Junfeng and Hu, Sai-er and others},
  journal={arXiv preprint arXiv:2503.04872},
  year={2025}
}

@article{xing2024autotrust,
  title={AutoTrust: Benchmarking Trustworthiness in Large Vision Language Models for Autonomous Driving},
  author={Xing, Shuo and Hua, Hongyuan and Gao, Xiangbo and Zhu, Shenzhe and Li, Renjie and Tian, Kexin and Li, Xiaopeng and Huang, Heng and Yang, Tianbao and Wang, Zhangyang and others},
  journal={arXiv preprint arXiv:2412.15206},
  year={2024}
}

@inproceedings{xing2025openemma,
  title={Openemma: Open-source multimodal model for end-to-end autonomous driving},
  author={Xing, Shuo and Qian, Chengyuan and Wang, Yuping and Hua, Hongyuan and Tian, Kexin and Zhou, Yang and Tu, Zhengzhong},
  booktitle={Proceedings of the Winter Conference on Applications of Computer Vision},
  pages={1001--1009},
  year={2025}
}

@article{xing2025can,
  title={Can Large Vision Language Models Read Maps Like a Human?},
  author={Xing, Shuo and Sun, Zezhou and Xie, Shuangyu and Chen, Kaiyuan and Huang, Yanjia and Wang, Yuping and Li, Jiachen and Song, Dezhen and Tu, Zhengzhong},
  journal={arXiv preprint arXiv:2503.14607},
  year={2025}
}

@article{chen2025towards,
  title={Towards Reasoning Era: A Survey of Long Chain-of-Thought for Reasoning Large Language Models},
  author={Chen, Qiguang and Qin, Libo and Liu, Jinhao and Peng, Dengyun and Guan, Jiannan and Wang, Peng and Hu, Mengkang and Zhou, Yuhang and Gao, Te and Che, Wangxiang},
  journal={arXiv preprint arXiv:2503.09567},
  year={2025}
}

@article{wan2024dynamic,
  title={Dynamic self-consistency: Leveraging reasoning paths for efficient llm sampling},
  author={Wan, Guangya and Wu, Yuqi and Chen, Jie and Li, Sheng},
  journal={arXiv preprint arXiv:2408.17017},
  year={2024}
}

@inproceedings{yuan2024lcbench,
    title = "{KV} Cache Compression, But What Must We Give in Return? A Comprehensive Benchmark of Long Context Capable Approaches",
    author = "Yuan, Jiayi  and
      Liu, Hongyi  and
      Zhong, Shaochen  and
      Chuang, Yu-Neng  and
      Li, Songchen  and
      Wang, Guanchu  and
      Le, Duy  and
      Jin, Hongye  and
      Chaudhary, Vipin  and
      Xu, Zhaozhuo  and
      Liu, Zirui  and
      Hu, Xia",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2024",
    month = nov,
    year = "2024",
    publisher = "Association for Computational Linguistics",
}



@article{shi2024keepcost,
  title={Keep the cost down: A review on methods to optimize llm's kv-cache consumption},
  author={Shi, Luohe and Zhang, Hongyi and Yao, Yao and Li, Zuchao and Zhao, Hai},
  journal={arXiv preprint arXiv:2407.18003},
  year={2024}
}

@inproceedings{xiao2023smoothquant,
  title={Smoothquant: Accurate and efficient post-training quantization for large language models},
  author={Xiao, Guangxuan and Lin, Ji and Seznec, Mickael and Wu, Hao and Demouth, Julien and Han, Song},
  booktitle={International Conference on Machine Learning},
  pages={38087--38099},
  year={2023},
  organization={PMLR}
}

% Routing by Question Attributes

@misc{chuang2025learningroutellmsconfidence,
      title={Learning to Route LLMs with Confidence Tokens}, 
      author={Yu-Neng Chuang and Helen Zhou and Prathusha Kameswara Sarma and Parikshit Gopalan and John Boccio and Sara Bolouki and Xia Hu},
      year={2025},
      eprint={2410.13284},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2410.13284}, 
}

@misc{chuang2025confidentseekstrongerexploring,
      title={Confident or Seek Stronger: Exploring Uncertainty-Based On-device LLM Routing From Benchmarking to Generalization}, 
      author={Yu-Neng Chuang and Leisheng Yu and Guanchu Wang and Lizhe Zhang and Zirui Liu and Xuanting Cai and Yang Sui and Vladimir Braverman and Xia Hu},
      year={2025},
      eprint={2502.04428},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2502.04428}, 
}

@misc{ong2025routellmlearningroutellms,
      title={RouteLLM: Learning to Route LLMs with Preference Data}, 
      author={Isaac Ong and Amjad Almahairi and Vincent Wu and Wei-Lin Chiang and Tianhao Wu and Joseph E. Gonzalez and M Waleed Kadous and Ion Stoica},
      year={2025},
      eprint={2406.18665},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2406.18665}, 
}

@article{liu2025bag,
  title={Bag of Tricks for Inference-time Computation of LLM Reasoning},
  author={Liu, Fan and Chao, Wenshuo and Tan, Naiqiang and Liu, Hao},
  journal={arXiv preprint arXiv:2502.07191},
  year={2025}
}

@article{jin2024impact,
  title={The impact of reasoning step length on large language models},
  author={Jin, Mingyu and Yu, Qinkai and Shu, Dong and Zhao, Haiyan and Hua, Wenyue and Meng, Yanda and Zhang, Yongfeng and Du, Mengnan},
  journal={arXiv preprint arXiv:2401.04925},
  year={2024}
}

@article{chen2024unlocking,
  title={Unlocking the capabilities of thought: A reasoning boundary framework to quantify and optimize chain-of-thought},
  author={Chen, Qiguang and Qin, Libo and Wang, Jiaqi and Zhou, Jingxuan and Che, Wanxiang},
  journal={Advances in Neural Information Processing Systems},
  volume={37},
  pages={54872--54904},
  year={2024}
}

@article{liu2025advances,
  title={Advances and Challenges in Foundation Agents: From Brain-Inspired Intelligence to Evolutionary, Collaborative, and Safe Systems},
  author={Liu, Bang and Li, Xinfeng and Zhang, Jiayi and Wang, Jinlin and He, Tanjin and Hong, Sirui and Liu, Hongzhang and Zhang, Shaokun and Song, Kaitao and Zhu, Kunlun and others},
  journal={arXiv preprint arXiv:2504.01990},
  year={2025}
}

@article{hu2023tree,
  title={Tree-planner: Efficient close-loop task planning with large language models},
  author={Hu, Mengkang and Mu, Yao and Yu, Xinmiao and Ding, Mingyu and Wu, Shiguang and Shao, Wenqi and Chen, Qiguang and Wang, Bin and Qiao, Yu and Luo, Ping},
  journal={arXiv preprint arXiv:2310.08582},
  year={2023}
}

@article{hu2024hiagent,
  title={Hiagent: Hierarchical working memory management for solving long-horizon agent tasks with large language model},
  author={Hu, Mengkang and Chen, Tianxing and Chen, Qiguang and Mu, Yao and Shao, Wenqi and Luo, Ping},
  journal={arXiv preprint arXiv:2408.09559},
  year={2024}
}

@article{huang2025efficient,
  title={Efficient test-time scaling via self-calibration},
  author={Huang, Chengsong and Huang, Langlin and Leng, Jixuan and Liu, Jiacheng and Huang, Jiaxin},
  journal={arXiv preprint arXiv:2503.00031},
  year={2025}
}

@article{taubenfeld2025confidence,
  title={Confidence Improves Self-Consistency in LLMs},
  author={Taubenfeld, Amir and Sheffer, Tom and Ofek, Eran and Feder, Amir and Goldstein, Ariel and Gekhman, Zorik and Yona, Gal},
  journal={arXiv preprint arXiv:2502.06233},
  year={2025}
}

@inproceedings{li2024escape,
  title={Escape Sky-high Cost: Early-stopping Self-Consistency for Multi-step Reasoning},
  author={Li, Yiwei and Yuan, Peiwen and Feng, Shaoxiong and Pan, Boyuan and Wang, Xinglin and Sun, Bin and Wang, Heda and Li, Kan},
  booktitle={ICLR},
  year={2024}
}

@article{wang2024make,
  title={Make every penny count: Difficulty-adaptive self-consistency for cost-efficient reasoning},
  author={Wang, Xinglin and Feng, Shaoxiong and Li, Yiwei and Yuan, Peiwen and Zhang, Yueqi and Tan, Chuyi and Pan, Boyuan and Hu, Yao and Li, Kan},
  journal={arXiv preprint arXiv:2408.13457},
  year={2024}
}

@article{zhu2024path,
  title={Path-Consistency: Prefix Enhancement for Efficient Inference in LLM},
  author={Zhu, Jiace and Shen, Yingtao and Zhao, Jie and Zou, An},
  journal={arXiv preprint arXiv:2409.01281},
  year={2024}
}

@article{wan2024reasoning,
  title={Reasoning Aware Self-Consistency: Leveraging Reasoning Paths for Efficient LLM Sampling},
  author={Wan, Guangya and Wu, Yuqi and Chen, Jie and Li, Sheng},
  journal={arXiv preprint arXiv:2408.17017},
  year={2024}
}

@article{zhou2025bridging,
  title={Bridging Internal Probability and Self-Consistency for Effective and Efficient LLM Reasoning},
  author={Zhou, Zhi and Yuhao, Tan and Li, Zenan and Yao, Yuan and Guo, Lan-Zhe and Ma, Xiaoxing and Li, Yu-Feng},
  journal={arXiv preprint arXiv:2502.00511},
  year={2025}
}

@article{liu2025bagoftrick,
  title={Bag of Tricks for Inference-time Computation of LLM Reasoning},
  author={Liu, Fan and Chao, Wenshuo and Tan, Naiqiang and Liu, Hao},
  journal={arXiv preprint arXiv:2502.07191},
  year={2025}
}

@article{pan2024chain,
  title={Chain-of-action: Faithful and multimodal question answering through large language models},
  author={Pan, Zhenyu and Luo, Haozheng and Li, Manling and Liu, Han},
  journal={arXiv preprint arXiv:2403.17359},
  year={2024}
}

@inproceedings{hao2025omnikv,
  title={OmniKV: Dynamic context selection for efficient long-context LLMs},
  author={Hao, Jitai and Zhu, Yuke and Wang, Tian and Yu, Jun and Xin, Xin and Zheng, Bo and Ren, Zhaochun and Guo, Sheng},
  booktitle={The Thirteenth International Conference on Learning Representations},
  year={2025}
}

@article{kumar2025overthink,
  title={OverThink: Slowdown Attacks on Reasoning LLMs},
  author={Kumar, Abhinav and Roh, Jaechul and Naseh, Ali and Karpinska, Marzena and Iyyer, Mohit and Houmansadr, Amir and Bagdasarian, Eugene},
  journal={arXiv e-prints},
  pages={arXiv--2502},
  year={2025}
}

@article{tang2025think,
  title={Think Before Recommend: Unleashing the Latent Reasoning Power for Sequential Recommendation},
  author={Tang, Jiakai and Dai, Sunhao and Shi, Teng and Xu, Jun and Chen, Xu and Chen, Wen and Jian, Wu and Jiang, Yuning},
  journal={arXiv preprint arXiv:2503.22675},
  year={2025}
}

@article{liu2024mind,
  title={Mind your step (by step): Chain-of-thought can reduce performance on tasks where thinking makes humans worse},
  author={Liu, Ryan and Geng, Jiayi and Wu, Addison J and Sucholutsky, Ilia and Lombrozo, Tania and Griffiths, Thomas L},
  journal={arXiv preprint arXiv:2410.21333},
  year={2024}
}

@article{li2025syzygy,
  title={Syzygy of Thoughts: Improving LLM CoT with the Minimal Free Resolution},
  author={Li, Chenghao and Zhang, Chaoning and Lu, Yi and Zhang, Jiaquan and Sun, Qigan and Wang, Xudong and Wei, Jiwei and Wang, Guoqing and Yang, Yang and Shen, Heng Tao},
  journal={arXiv preprint arXiv:2504.09566},
  year={2025}
}

@misc{liu2025thoughtmanipulationexternalthought,
      title={Thought Manipulation: External Thought Can Be Efficient for Large Reasoning Models}, 
      author={Yule Liu and Jingyi Zheng and Zhen Sun and Zifan Peng and Wenhan Dong and Zeyang Sha and Shiwen Cui and Weiqiang Wang and Xinlei He},
      year={2025},
      eprint={2504.13626},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2504.13626}, 
}

@misc{pu2025thoughtterminatorbenchmarkingcalibratingmitigating,
      title={THOUGHTTERMINATOR: Benchmarking, Calibrating, and Mitigating Overthinking in Reasoning Models}, 
      author={Xiao Pu and Michael Saxon and Wenyue Hua and William Yang Wang},
      year={2025},
      eprint={2504.13367},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2504.13367}, 
}

@article{zhang2025s1,
  title={S1-Bench: A Simple Benchmark for Evaluating System 1 Thinking Capability of Large Reasoning Models},
  author={Zhang, Wenyuan and Nie, Shuaiyi and Zhang, Xinghua and Zhang, Zefeng and Liu, Tingwen},
  journal={arXiv preprint arXiv:2504.10368},
  year={2025}
}

@article{yang2025speculative,
  title={Speculative Thinking: Enhancing Small-Model Reasoning with Large Model Guidance at Inference Time},
  author={Yang, Wang and Yue, Xiang and Chaudhary, Vipin and Han, Xiaotian},
  journal={arXiv preprint arXiv:2504.12329},
  year={2025}
}

@article{lin2025sleep,
  title={Sleep-time Compute: Beyond Inference Scaling at Test-time},
  author={Lin, Kevin and Snell, Charlie and Wang, Yu and Packer, Charles and Wooders, Sarah and Stoica, Ion and Gonzalez, Joseph E},
  journal={arXiv preprint arXiv:2504.13171},
  year={2025}
}

@article{pan2025specreason,
  title={SpecReason: Fast and Accurate Inference-Time Compute via Speculative Reasoning},
  author={Pan, Rui and Dai, Yinwei and Zhang, Zhihao and Oliaro, Gabriele and Jia, Zhihao and Netravali, Ravi},
  journal={arXiv preprint arXiv:2504.07891},
  year={2025}
}

@article{ma2025reasoning,
  title={Reasoning Models Can Be Effective Without Thinking},
  author={Ma, Wenjie and He, Jingxuan and Snell, Charlie and Griggs, Tyler and Min, Sewon and Zaharia, Matei},
  journal={arXiv preprint arXiv:2504.09858},
  year={2025}
}

@article{fang2025safemlrm,
  title={SafeMLRM: Demystifying Safety in Multi-modal Large Reasoning Models},
  author={Fang, Junfeng and Wang, Yukai and Wang, Ruipeng and Yao, Zijun and Wang, Kun and Zhang, An and Wang, Xiang and Chua, Tat-Seng},
  journal={arXiv preprint arXiv:2504.08813},
  year={2025}
}

@article{zhang2025reasoning,
  title={When Reasoning Meets Compression: Benchmarking Compressed Large Reasoning Models on Complex Reasoning Tasks},
  author={Zhang, Nan and Zhang, Yusen and Mitra, Prasenjit and Zhang, Rui},
  journal={arXiv preprint arXiv:2504.02010},
  year={2025}
}

@article{fan2025missing,
  title={Missing Premise exacerbates Overthinking: Are Reasoning Models losing Critical Thinking Skill?},
  author={Fan, Chenrui and Li, Ming and Sun, Lichao and Zhou, Tianyi},
  journal={arXiv preprint arXiv:2504.06514},
  year={2025}
}

@misc{yang2025thinkingoptimalscalingtesttimecompute,
      title={Towards Thinking-Optimal Scaling of Test-Time Compute for LLM Reasoning}, 
      author={Wenkai Yang and Shuming Ma and Yankai Lin and Furu Wei},
      year={2025},
      eprint={2502.18080},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2502.18080}, 
}

@misc{xu2025twtthinkingtokenshabitual,
      title={TwT: Thinking without Tokens by Habitual Reasoning Distillation with Multi-Teachers' Guidance}, 
      author={Jingxian Xu and Mengyu Zhou and Weichang Liu and Hanbing Liu and Shi Han and Dongmei Zhang},
      year={2025},
      eprint={2503.24198},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2503.24198}, 
}

@misc{liu2025quantizationhurtsreasoningempirical,
      title={Quantization Hurts Reasoning? An Empirical Study on Quantized Reasoning Models}, 
      author={Ruikang Liu and Yuxuan Sun and Manyi Zhang and Haoli Bai and Xianzhi Yu and Tiezheng Yu and Chun Yuan and Lu Hou},
      year={2025},
      eprint={2504.04823},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2504.04823}, 
}

@misc{lu2025retrosearchexploringuntakenpaths,
      title={Retro-Search: Exploring Untaken Paths for Deeper and Efficient Reasoning}, 
      author={Ximing Lu and Seungju Han and David Acuna and Hyunwoo Kim and Jaehun Jung and Shrimai Prabhumoye and Niklas Muennighoff and Mostofa Patwary and Mohammad Shoeybi and Bryan Catanzaro and Yejin Choi},
      year={2025},
      eprint={2504.04383},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2504.04383}, 
}

@misc{eo2025debatenecessaryadaptivemultiagent,
      title={Debate Only When Necessary: Adaptive Multiagent Collaboration for Efficient LLM Reasoning}, 
      author={Sugyeong Eo and Hyeonseok Moon and Evelyn Hayoon Zi and Chanjun Park and Heuiseok Lim},
      year={2025},
      eprint={2504.05047},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2504.05047}, 
}

@misc{yang2025thinkneedselfadaptivechainofthought,
      title={Think When You Need: Self-Adaptive Chain-of-Thought Learning}, 
      author={Junjie Yang and Ke Lin and Xing Yu},
      year={2025},
      eprint={2504.03234},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2504.03234}, 
}

@misc{she2025hawkeyeefficientreasoningmodelcollaboration,
      title={Hawkeye:Efficient Reasoning with Model Collaboration}, 
      author={Jianshu She and Zhuohao Li and Zhemin Huang and Qi Li and Peiran Xu and Haonan Li and Qirong Ho},
      year={2025},
      eprint={2504.00424},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2504.00424}, 
}

@misc{yu2025z1efficienttesttimescaling,
      title={Z1: Efficient Test-time Scaling with Code}, 
      author={Zhaojian Yu and Yinghao Wu and Yilun Zhao and Arman Cohan and Xiao-Ping Zhang},
      year={2025},
      eprint={2504.00810},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2504.00810}, 
}

@misc{lee2025criticalthinkingkindscomplexity,
      title={Critical Thinking: Which Kinds of Complexity Govern Optimal Reasoning Length?}, 
      author={Celine Lee and Alexander M. Rush and Keyon Vafa},
      year={2025},
      eprint={2504.01935},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2504.01935}, 
}

@misc{wu2025unlockingefficientlongtoshortllm,
      title={Unlocking Efficient Long-to-Short LLM Reasoning with Model Merging}, 
      author={Han Wu and Yuxuan Yao and Shuqi Liu and Zehua Liu and Xiaojin Fu and Xiongwei Han and Xing Li and Hui-Ling Zhen and Tao Zhong and Mingxuan Yuan},
      year={2025},
      eprint={2503.20641},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2503.20641}, 
}

@misc{yang2024modelmergingllmsmllms,
      title={Model Merging in LLMs, MLLMs, and Beyond: Methods, Theories, Applications and Opportunities}, 
      author={Enneng Yang and Li Shen and Guibing Guo and Xingwei Wang and Xiaochun Cao and Jie Zhang and Dacheng Tao},
      year={2024},
      eprint={2408.07666},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2408.07666}, 
}

@inproceedings{
fu2025reasoning,
title={Reasoning Without Self-Doubt: More Efficient Chain-of-Thought Through Certainty Probing},
author={Yichao Fu and Junda Chen and Yonghao Zhuang and Zheyu Fu and Ion Stoica and Hao Zhang},
booktitle={ICLR 2025 Workshop on Foundation Models in the Wild},
year={2025},
url={https://openreview.net/forum?id=wpK4IMJfdX}
}

@article{hou2025thinkprune,
  title={ThinkPrune: Pruning Long Chain-of-Thought of LLMs via Reinforcement Learning},
  author={Hou, Bairu and Zhang, Yang and Ji, Jiabao and Liu, Yujian and Qian, Kaizhi and Andreas, Jacob and Chang, Shiyu},
  journal={arXiv preprint arXiv:2504.01296},
  year={2025}
}

@misc{wang2025thinkdeepthinkfast,
      title={Think Deep, Think Fast: Investigating Efficiency of Verifier-free Inference-time-scaling Methods}, 
      author={Junlin Wang and Shang Zhu and Jon Saad-Falcon and Ben Athiwaratkun and Qingyang Wu and Jue Wang and Shuaiwen Leon Song and Ce Zhang and Bhuwan Dhingra and James Zou},
      year={2025},
      eprint={2504.14047},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2504.14047}, 
}

