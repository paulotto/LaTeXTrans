
% Use this file for citations not found in the ACL Anthology (contained in "anthology.bib").

@book{Aho:72,
    author  = {Alfred V. Aho and Jeffrey D. Ullman},
    title   = {The Theory of Parsing, Translation and Compiling},
    year    = "1972",
    volume  = "1",
    publisher = {Prentice-Hall},
    address = {Englewood Cliffs, NJ}
}

@book{APA:83,
    author  = {{American Psychological Association}},
    title   = {Publications Manual},
    year    = "1983",
    publisher = {American Psychological Association},
    address = {Washington, DC}
}

@article{Chandra:81,
	author = {Ashok K. Chandra and Dexter C. Kozen and Larry J. Stockmeyer},
	year = "1981",
	title = {Alternation},
	journal = {Journal of the Association for Computing Machinery},
	volume = "28",
	number = "1",
	pages = "114--133",
	doi = "10.1145/322234.322243",
}

@inproceedings{andrew2007scalable,
  title={Scalable training of {L1}-regularized log-linear models},
  author={Andrew, Galen and Gao, Jianfeng},
  booktitle={Proceedings of the 24th International Conference on Machine Learning},
  pages={33--40},
  year={2007},
}

@book{Gusfield:97,
    author  = {Dan Gusfield},
    title   = {Algorithms on Strings, Trees and Sequences},
    year    = "1997",
    publisher = {Cambridge University Press},
    address = {Cambridge, UK}
}

@article{rasooli-tetrault-2015,
    author    = {Mohammad Sadegh Rasooli and Joel R. Tetreault},
    title     = {Yara Parser: {A} Fast and Accurate Dependency Parser},
    journal   = {Computing Research Repository},
    volume    = {arXiv:1503.06733},
    year      = {2015},
    url       = {http://arxiv.org/abs/1503.06733},
    note    = {version 2}
}

@article{Ando2005,
	Acmid = {1194905},
	Author = {Ando, Rie Kubota and Zhang, Tong},
	Issn = {1532-4435},
	Issue_Date = {12/1/2005},
	Journal = {Journal of Machine Learning Research},
	Month = dec,
	Numpages = {37},
	Pages = {1817--1853},
	Publisher = {JMLR.org},
	Title = {A Framework for Learning Predictive Structures from Multiple Tasks and Unlabeled Data},
	Volume = {6},
	Year = {2005}
}



@inproceedings{tiong2022plug,
    title = "Plug-and-Play {VQA}: Zero-shot {VQA} by Conjoining Large Pretrained Models with Zero Training",
    author = "Tiong, Anthony Meng Huat  and
      Li, Junnan  and
      Li, Boyang  and
      Savarese, Silvio  and
      Hoi, Steven C.H.",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2022",
    month = dec,
    year = "2022",
    address = "Abu Dhabi, United Arab Emirates",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.findings-emnlp.67",
    pages = "951--967",
}


@inproceedings{chen2022align,
  title={Align, Reason and Learn: Enhancing Medical Vision-and-Language Pre-training with Knowledge},
  author={Chen, Zhihong and Li, Guanbin and Wan, Xiang},
  booktitle={Proceedings of the 30th ACM International Conference on Multimedia},
  pages={5152--5161},
  year={2022}
}


@inproceedings{svladapterbmvc2022,
    author    = {Pantazis, Omiros and Brostow, Gabriel and Jones, Kate and Mac Aodha, Oisin},
    title     = {SVL-Adapter: Self-Supervised Adapter for Vision-Language Pretrained Models},
    booktitle = {British Machine Vision Conference (BMVC)},
    year      = {2022}
}



@inproceedings{li2022blip,
  title={Blip: Bootstrapping language-image pre-training for unified vision-language understanding and generation},
  author={Li, Junnan and Li, Dongxu and Xiong, Caiming and Hoi, Steven},
  booktitle={International Conference on Machine Learning},
  pages={12888--12900},
  year={2022},
  organization={PMLR}
}

@article{eslami2021does,
  title={Does CLIP Benefit Visual Question Answering in the Medical Domain as Much as it Does in the General Domain?},
  author={Eslami, Sedigheh and de Melo, Gerard and Meinel, Christoph},
  journal={arXiv preprint arXiv:2112.13906},
  year={2021}
}

@inproceedings{zhan2020medical,
  title={Medical visual question answering via conditional reasoning},
  author={Zhan, Li-Ming and Liu, Bo and Fan, Lu and Chen, Jiaxin and Wu, Xiao-Ming},
  booktitle={Proceedings of the 28th ACM International Conference on Multimedia},
  pages={2345--2354},
  year={2020}
}

@inproceedings{sung2022vl,
  title={Vl-adapter: Parameter-efficient transfer learning for vision-and-language tasks},
  author={Sung, Yi-Lin and Cho, Jaemin and Bansal, Mohit},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={5227--5237},
  year={2022}
}

@inproceedings{nguyen2019overcoming,
  title={Overcoming data limitation in medical visual question answering},
  author={Nguyen, Binh D and Do, Thanh-Toan and Nguyen, Binh X and Do, Tuong and Tjiputra, Erman and Tran, Quang D},
  booktitle={International Conference on Medical Image Computing and Computer-Assisted Intervention},
  pages={522--530},
  year={2019},
  organization={Springer}
}

@article{gao2021clip,
  title={Clip-adapter: Better vision-language models with feature adapters},
  author={Gao, Peng and Geng, Shijie and Zhang, Renrui and Ma, Teli and Fang, Rongyao and Zhang, Yongfeng and Li, Hongsheng and Qiao, Yu},
  journal={arXiv preprint arXiv:2110.04544},
  year={2021}
}

@article{muller2019does,
  title={When does label smoothing help?},
  author={M{\"u}ller, Rafael and Kornblith, Simon and Hinton, Geoffrey E},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@inproceedings{gong2021cross,
  title={Cross-modal self-attention with multi-task pre-training for medical visual question answering},
  author={Gong, Haifan and Chen, Guanqi and Liu, Sishuo and Yu, Yizhou and Li, Guanbin},
  booktitle={Proceedings of the 2021 International Conference on Multimedia Retrieval},
  pages={456--460},
  year={2021}
}

@article{ren2020cgmvqa,
  title={Cgmvqa: A new classification and generative model for medical visual question answering},
  author={Ren, Fuji and Zhou, Yangyang},
  journal={IEEE Access},
  volume={8},
  pages={50626--50636},
  year={2020},
  publisher={IEEE}
}

@inproceedings{khare2021mmbert,
  title={MMBERT: multimodal BERT pretraining for improved medical VQA},
  author={Khare, Yash and Bagal, Viraj and Mathew, Minesh and Devi, Adithi and Priyakumar, U Deva and Jawahar, CV},
  booktitle={2021 IEEE 18th International Symposium on Biomedical Imaging (ISBI)},
  pages={1033--1036},
  year={2021},
  organization={IEEE}
}


@article{kim2018bilinear,
  title={Bilinear attention networks},
  author={Kim, Jin-Hwa and Jun, Jaehyun and Zhang, Byoung-Tak},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}

@inproceedings{finn2017model,
  title={Model-agnostic meta-learning for fast adaptation of deep networks},
  author={Finn, Chelsea and Abbeel, Pieter and Levine, Sergey},
  booktitle={International conference on machine learning},
  pages={1126--1135},
  year={2017},
  organization={PMLR}
}

@inproceedings{masci2011stacked,
  title={Stacked convolutional auto-encoders for hierarchical feature extraction},
  author={Masci, Jonathan and Meier, Ueli and Cire{\c{s}}an, Dan and Schmidhuber, J{\"u}rgen},
  booktitle={International conference on artificial neural networks},
  pages={52--59},
  year={2011},
  organization={Springer}
}

@inproceedings{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International Conference on Machine Learning},
  pages={8748--8763},
  year={2021},
  organization={PMLR}
}

@inproceedings{hu2022pushing,
  title={Pushing the Limits of Simple Pipelines for Few-Shot Learning: External Data and Fine-Tuning Make a Difference},
  author={Hu, Shell Xu and Li, Da and St{\"u}hmer, Jan and Kim, Minyoung and Hospedales, Timothy M},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={9068--9077},
  year={2022}
}

@inproceedings{houlsby2019parameter,
  title={Parameter-efficient transfer learning for NLP},
  author={Houlsby, Neil and Giurgiu, Andrei and Jastrzebski, Stanislaw and Morrone, Bruna and De Laroussilhe, Quentin and Gesmundo, Andrea and Attariyan, Mona and Gelly, Sylvain},
  booktitle={International Conference on Machine Learning},
  pages={2790--2799},
  year={2019},
  organization={PMLR}
}

@inproceedings{antol2015vqa,
  title={Vqa: Visual question answering},
  author={Antol, Stanislaw and Agrawal, Aishwarya and Lu, Jiasen and Mitchell, Margaret and Batra, Dhruv and Zitnick, C Lawrence and Parikh, Devi},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={2425--2433},
  year={2015}
}

@inproceedings{anderson2018bottom,
  title={Bottom-up and top-down attention for image captioning and visual question answering},
  author={Anderson, Peter and He, Xiaodong and Buehler, Chris and Teney, Damien and Johnson, Mark and Gould, Stephen and Zhang, Lei},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={6077--6086},
  year={2018}
}

@inproceedings{liu2019erasing,
  title={Erasing-based attention learning for visual question answering},
  author={Liu, Fei and Liu, Jing and Hong, Richang and Lu, Hanqing},
  booktitle={Proceedings of the 27th ACM International Conference on Multimedia},
  pages={1175--1183},
  year={2019}
}

@inproceedings{abacha2018nlm,
  title={NLM at ImageCLEF 2018 Visual Question Answering in the Medical Domain.},
  author={Abacha, Asma Ben and Gayen, Soumya and Lau, Jason J and Rajaraman, Sivaramakrishnan and Demner-Fushman, Dina},
  booktitle={CLEF (Working Notes)},
  year={2018}
}


@inproceedings{fukui2016multimodal,
  title={Multimodal Compact Bilinear Pooling for Visual Question Answering and Visual Grounding},
  author={Fukui, Akira and Park, Dong Huk and Yang, Daylen and Rohrbach, Anna and Darrell, Trevor and Rohrbach, Marcus},
  booktitle={Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing},
  pages={457--468},
  year={2016}
}

@inproceedings{shi2019deep,
  title={Deep multimodal learning for medical visual question answering},
  author={Shi, Lei and Liu, Feifan and Rosen, Max P},
  booktitle={CLEF (Working Notes)},
  year={2019}
}

@inproceedings{yu2017multi,
  title={Multi-modal factorized bilinear pooling with co-attention learning for visual question answering},
  author={Yu, Zhou and Yu, Jun and Fan, Jianping and Tao, Dacheng},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={1821--1830},
  year={2017}
}

@inproceedings{chen2020uniter,
  title={Uniter: Universal image-text representation learning},
  author={Chen, Yen-Chun and Li, Linjie and Yu, Licheng and El Kholy, Ahmed and Ahmed, Faisal and Gan, Zhe and Cheng, Yu and Liu, Jingjing},
  booktitle={European conference on computer vision},
  pages={104--120},
  year={2020},
  organization={Springer}
}

@inproceedings{li2020oscar,
  title={Oscar: Object-semantics aligned pre-training for vision-language tasks},
  author={Li, Xiujun and Yin, Xi and Li, Chunyuan and Zhang, Pengchuan and Hu, Xiaowei and Zhang, Lei and Wang, Lijuan and Hu, Houdong and Dong, Li and Wei, Furu and others},
  booktitle={European Conference on Computer Vision},
  pages={121--137},
  year={2020},
  organization={Springer}
}



@inproceedings{sharma2018conceptual,
  title={Conceptual captions: A cleaned, hypernymed, image alt-text dataset for automatic image captioning},
  author={Sharma, Piyush and Ding, Nan and Goodman, Sebastian and Soricut, Radu},
  booktitle={Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={2556--2565},
  year={2018}
}

@inproceedings{jia2021scaling,
  title={Scaling up visual and vision-language representation learning with noisy text supervision},
  author={Jia, Chao and Yang, Yinfei and Xia, Ye and Chen, Yi-Ting and Parekh, Zarana and Pham, Hieu and Le, Quoc and Sung, Yun-Hsuan and Li, Zhen and Duerig, Tom},
  booktitle={International Conference on Machine Learning},
  pages={4904--4916},
  year={2021},
  organization={PMLR}
}


@inproceedings{gao2019dynamic,
  title={Dynamic fusion with intra-and inter-modality attention flow for visual question answering},
  author={Gao, Peng and Jiang, Zhengkai and You, Haoxuan and Lu, Pan and Hoi, Steven CH and Wang, Xiaogang and Li, Hongsheng},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={6639--6648},
  year={2019}
}

@article{devlin2018bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}

@inproceedings{kenton2019bert,
  title={BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
  author={Kenton, Jacob Devlin Ming-Wei Chang and Toutanova, Lee Kristina},
  booktitle={Proceedings of NAACL-HLT},
  pages={4171--4186},
  year={2019}
}


@inproceedings{do2021multiple,
  title={Multiple meta-model quantifying for medical visual question answering},
  author={Do, Tuong and Nguyen, Binh X and Tjiputra, Erman and Tran, Minh and Tran, Quang D and Nguyen, Anh},
  booktitle={International Conference on Medical Image Computing and Computer-Assisted Intervention},
  pages={64--74},
  year={2021},
  organization={Springer}
}



@inproceedings{shen2021much,
  title={How Much Can CLIP Benefit Vision-and-Language Tasks?},
  author={Shen, Sheng and Li, Liunian Harold and Tan, Hao and Bansal, Mohit and Rohrbach, Anna and Chang, Kai-Wei and Yao, Zhewei and Keutzer, Kurt},
  booktitle={International Conference on Learning Representations},
  year={2022},
}



@article{dosovitskiy2020vit,
  title={An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale},
  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and  Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and Uszkoreit, Jakob and Houlsby, Neil},
  journal={ICLR},
  year={2021}
}

@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}

@article{radford2019language,
  title={Language models are unsupervised multitask learners},
  author={Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya and others},
  journal={OpenAI blog},
  volume={1},
  number={8},
  pages={9},
  year={2019}
}



@inproceedings{hu2021lora,
  title={LoRA: Low-Rank Adaptation of Large Language Models},
  author={Hu, Edward J and Shen, Yelong and Wallis, Phillip and Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang, Lu and Chen, Weizhu},
  booktitle={International Conference on Learning Representations},
  year={2022},
}

@inproceedings{stickland2019bert,
  title={Bert and pals: Projected attention layers for efficient adaptation in multi-task learning},
  author={Stickland, Asa Cooper and Murray, Iain},
  booktitle={International Conference on Machine Learning},
  pages={5986--5995},
  year={2019},
  organization={PMLR}
}

@inproceedings{zhao2021calibrate,
  title={Calibrate before use: Improving few-shot performance of language models},
  author={Zhao, Zihao and Wallace, Eric and Feng, Shi and Klein, Dan and Singh, Sameer},
  booktitle={International Conference on Machine Learning},
  pages={12697--12706},
  year={2021},
  organization={PMLR}
}

@article{zhou2022learning,
  title={Learning to prompt for vision-language models},
  author={Zhou, Kaiyang and Yang, Jingkang and Loy, Chen Change and Liu, Ziwei},
  journal={International Journal of Computer Vision},
  volume={130},
  number={9},
  pages={2337--2348},
  year={2022},
  publisher={Springer}
}


@inproceedings{lester2021power,
  title={The Power of Scale for Parameter-Efficient Prompt Tuning},
  author={Lester, Brian and Al-Rfou, Rami and Constant, Noah},
  booktitle={Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing},
  pages={3045--3059},
  year={2021}
}

@article{karimi2021compacter,
  title={Compacter: Efficient low-rank hypercomplex adapter layers},
  author={Karimi Mahabadi, Rabeeh and Henderson, James and Ruder, Sebastian},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={1022--1035},
  year={2021}
}


@inproceedings{guo2020parameter,
  title={Parameter-Efficient Transfer Learning with Diff Pruning},
  author={Guo, Demi and Rush, Alexander M and Kim, Yoon},
  booktitle={Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)},
  pages={4884--4896},
  year={2021}
}

@article{rebuffi2017learning,
  title={Learning multiple visual domains with residual adapters},
  author={Rebuffi, Sylvestre-Alvise and Bilen, Hakan and Vedaldi, Andrea},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@inproceedings{rebuffi2018efficient,
  title={Efficient parametrization of multi-domain deep neural networks},
  author={Rebuffi, Sylvestre-Alvise and Bilen, Hakan and Vedaldi, Andrea},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={8119--8127},
  year={2018}
}



@inproceedings{karimi2021parameterefficient,
  title={Parameter-efficient Multi-task Fine-tuning for Transformers via Shared Hypernetworks},
  author={Karimi Mahabadi, Rabeeh and Ruder, Sebastian and Dehghani, Mostafa and Henderson, James},
  booktitle={Annual Meeting of the Association for Computational Linguistics},
  year={2021}
}

@inproceedings{teney2018tips,
  title={Tips and tricks for visual question answering: Learnings from the 2017 challenge},
  author={Teney, Damien and Anderson, Peter and He, Xiaodong and Van Den Hengel, Anton},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={4223--4232},
  year={2018}
}


@inproceedings{pennington2014glove,
  title={Glove: Global vectors for word representation},
  author={Pennington, Jeffrey and Socher, Richard and Manning, Christopher D},
  booktitle={Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP)},
  pages={1532--1543},
  year={2014}
}


@article{pereyra2017regularizing,
  title={Regularizing neural networks by penalizing confident output distributions},
  author={Pereyra, Gabriel and Tucker, George and Chorowski, Jan and Kaiser, {\L}ukasz and Hinton, Geoffrey},
  journal={arXiv preprint arXiv:1701.06548},
  year={2017}
}

@inproceedings{xie2016disturblabel,
  title={Disturblabel: Regularizing cnn on the loss layer},
  author={Xie, Lingxi and Wang, Jingdong and Wei, Zhen and Wang, Meng and Tian, Qi},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={4753--4762},
  year={2016}
}

@inproceedings{yang2016stacked,
  title={Stacked attention networks for image question answering},
  author={Yang, Zichao and He, Xiaodong and Gao, Jianfeng and Deng, Li and Smola, Alex},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={21--29},
  year={2016}
}

@inproceedings{selvaraju2017grad,
  title={Grad-cam: Visual explanations from deep networks via gradient-based localization},
  author={Selvaraju, Ramprasaath R and Cogswell, Michael and Das, Abhishek and Vedantam, Ramakrishna and Parikh, Devi and Batra, Dhruv},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={618--626},
  year={2017}
}

@article{luo2022clip4clip,
  title={CLIP4Clip: An empirical study of CLIP for end to end video clip retrieval and captioning},
  author={Luo, Huaishao and Ji, Lei and Zhong, Ming and Chen, Yang and Lei, Wen and Duan, Nan and Li, Tianrui},
  journal={Neurocomputing},
  volume={508},
  pages={293--304},
  year={2022},
  publisher={Elsevier}
}

@inproceedings{zhang2022pointclip,
  title={Pointclip: Point cloud understanding by clip},
  author={Zhang, Renrui and Guo, Ziyu and Zhang, Wei and Li, Kunchang and Miao, Xupeng and Cui, Bin and Qiao, Yu and Gao, Peng and Li, Hongsheng},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={8552--8562},
  year={2022}
}

@inproceedings{chefer2021generic,
  title={Generic attention-model explainability for interpreting bi-modal and encoder-decoder transformers},
  author={Chefer, Hila and Gur, Shir and Wolf, Lior},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={397--406},
  year={2021}
}

@inproceedings{pelka2018radiology,
  title={Radiology Objects in COntext (ROCO): a multimodal image dataset},
  author={Pelka, Obioma and Koitka, Sven and R{\"u}ckert, Johannes and Nensa, Felix and Friedrich, Christoph M},
  booktitle={Intravascular Imaging and Computer Assisted Stenting and Large-Scale Annotation of Biomedical Data and Expert Label Synthesis: 7th Joint International Workshop, CVII-STENT 2018 and Third International Workshop, LABELS 2018, Held in Conjunction with MICCAI 2018, Granada, Spain, September 16, 2018, Proceedings 3},
  pages={180--189},
  year={2018},
  organization={Springer}
}








@article{banerjee2020weaqa,
  title={WeaQA: Weak Supervision via Captions for Visual Question Answering},
  author={Banerjee, Pratyay and Gokhale, Tejas and Yang, Yezhou and Baral, Chitta},
  journal={Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021},
  year={2021}
}


@inproceedings{changpinyo2022all,
  title={All You May Need for VQA are Image Captions},
  author={Changpinyo, Soravit and Kukliansy, Doron and Szpektor, Idan and Chen, Xi and Ding, Nan and Soricut, Radu},
  booktitle={Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies},
  pages={1947--1963},
  year={2022}
}





@inproceedings{song2022clip,
  title={CLIP Models are Few-Shot Learners: Empirical Studies on VQA and Visual Entailment},
  author={Song, Haoyu and Dong, Li and Zhang, Weinan and Liu, Ting and Wei, Furu},
  booktitle={Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={6088--6100},
  year={2022}
}


@inproceedings{wang2022clip,
  title={CLIP-TD: CLIP Targeted Distillation for Vision-Language Tasks},
  author={Wang, Zhecan and Xiao, Bin and Codella, Noel and Yang, Jianwei and Chen, Yen-Chun and Zhou, Luowei and Chang, Shih-Fu and Dai, Xiyang and You, Haoxuan and Yuan, Lu},
  booktitle={International Conference on Learning Representations},
  year={2022},
}

@article{ramesh2022hierarchical,
  title={Hierarchical text-conditional image generation with clip latents},
  author={Ramesh, Aditya and Dhariwal, Prafulla and Nichol, Alex and Chu, Casey and Chen, Mark},
  journal={arXiv preprint arXiv:2204.06125},
  year={2022}
}



@inproceedings{wang2022cris,
  title={Cris: Clip-driven referring image segmentation},
  author={Wang, Zhaoqing and Lu, Yu and Li, Qiang and Tao, Xunqiang and Guo, Yandong and Gong, Mingming and Liu, Tongliang},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={11686--11695},
  year={2022}
}

@inproceedings{liu2021contrastive,
  title={Contrastive pre-training and representation distillation for medical visual question answering based on radiology images},
  author={Liu, Bo and Zhan, Li-Ming and Wu, Xiao-Ming},
  booktitle={Medical Image Computing and Computer Assisted Intervention--MICCAI 2021: 24th International Conference, Strasbourg, France, September 27--October 1, 2021, Proceedings, Part II 24},
  pages={210--220},
  year={2021},
  organization={Springer}
}


@article{li2024llava,
  title={Llava-med: Training a large language-and-vision assistant for biomedicine in one day},
  author={Li, Chunyuan and Wong, Cliff and Zhang, Sheng and Usuyama, Naoto and Liu, Haotian and Yang, Jianwei and Naumann, Tristan and Poon, Hoifung and Gao, Jianfeng},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@misc{shinn2023reflexion,
      title={Reflexion: Language Agents with Verbal Reinforcement Learning}, 
      author={Noah Shinn and Federico Cassano and Edward Berman and Ashwin Gopinath and Karthik Narasimhan and Shunyu Yao},
      year={2023},
      eprint={2303.11366},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
}

@misc{xu2024preemptive,
      title={Preemptive Answer "Attacks" on Chain-of-Thought Reasoning}, 
      author={Rongwu Xu and Zehan Qi and Wei Xu},
      year={2024},
      eprint={2405.20902},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@inproceedings{langley00,
 author    = {P. Langley},
 title     = {Crafting Papers on Machine Learning},
 year      = {2000},
 pages     = {1207--1216},
 editor    = {Pat Langley},
 booktitle     = {Proceedings of the 17th International Conference
              on Machine Learning (ICML 2000)},
 address   = {Stanford, CA},
 publisher = {Morgan Kaufmann}
}

@TechReport{mitchell80,
  author = 	 "T. M. Mitchell",
  title = 	 "The Need for Biases in Learning Generalizations",
  institution =  "Computer Science Department, Rutgers University",
  year = 	 "1980",
  address =	 "New Brunswick, MA",
}

@phdthesis{kearns89,
  author = {M. J. Kearns},
  title =  {Computational Complexity of Machine Learning},
  school = {Department of Computer Science, Harvard University},
  year =   {1989}
}

@Book{MachineLearningI,
  editor = 	 "R. S. Michalski and J. G. Carbonell and T.
		  M. Mitchell",
  title = 	 "Machine Learning: An Artificial Intelligence
		  Approach, Vol. I",
  publisher = 	 "Tioga",
  year = 	 "1983",
  address =	 "Palo Alto, CA"
}

@Book{DudaHart2nd,
  author =       "R. O. Duda and P. E. Hart and D. G. Stork",
  title =        "Pattern Classification",
  publisher =    "John Wiley and Sons",
  edition =      "2nd",
  year =         "2000"
}

@misc{anonymous,
  title= {Suppressed for Anonymity},
  author= {Author, N. N.},
  year= {2021}
}

@InCollection{Newell81,
  author =       "A. Newell and P. S. Rosenbloom",
  title =        "Mechanisms of Skill Acquisition and the Law of
                  Practice", 
  booktitle =    "Cognitive Skills and Their Acquisition",
  pages =        "1--51",
  publisher =    "Lawrence Erlbaum Associates, Inc.",
  year =         "1981",
  editor =       "J. R. Anderson",
  chapter =      "1",
  address =      "Hillsdale, NJ"
}


@Article{Samuel59,
  author = 	 "A. L. Samuel",
  title = 	 "Some Studies in Machine Learning Using the Game of
		  Checkers",
  journal =	 "IBM Journal of Research and Development",
  year =	 "1959",
  volume =	 "3",
  number =	 "3",
  pages =	 "211--229"
}

@article{lu2022learn,
  title={Learn to explain: Multimodal reasoning via thought chains for science question answering},
  author={Lu, Pan and Mishra, Swaroop and Xia, Tanglin and Qiu, Liang and Chang, Kai-Wei and Zhu, Song-Chun and Tafjord, Oyvind and Clark, Peter and Kalyan, Ashwin},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={2507--2521},
  year={2022}
}

@inproceedings{shi2022spatial,
  title={Spatial and Visual Perspective-Taking via View Rotation and Relation Reasoning for Embodied Reference Understanding},
  author={Shi, Cheng and Yang, Sibei},
  booktitle={European Conference on Computer Vision},
  pages={201--218},
  year={2022},
  organization={Springer}
}

@article{wang2022code4struct,
  title={Code4Struct: Code Generation for Few-Shot Event Structure Prediction},
  author={Wang, Xingyao and Li, Sha and Ji, Heng},
  journal={arXiv preprint arXiv:2210.12810},
  year={2022}
}

@article{chen2022program,
  title={Program of thoughts prompting: Disentangling computation from reasoning for numerical reasoning tasks},
  author={Chen, Wenhu and Ma, Xueguang and Wang, Xinyi and Cohen, William W},
  journal={arXiv preprint arXiv:2211.12588},
  year={2022}
}

@inproceedings{tang2023contrastive,
  title={Contrastive Grouping with Transformer for Referring Image Segmentation},
  author={Tang, Jiajin and Zheng, Ge and Shi, Cheng and Yang, Sibei},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={23570--23580},
  year={2023}
}

@article{liu2023deep,
  title={Deep learning-enabled 3D multimodal fusion of cone-beam CT and intraoral mesh scans for clinically applicable tooth-bone reconstruction},
  author={Liu, Jiaxiang and Hao, Jin and Lin, Hangzheng and Pan, Wei and Yang, Jianfei and Feng, Yang and Wang, Gaoang and Li, Jin and Jin, Zuolin and Zhao, Zhihe and others},
  journal={Patterns},
  volume={4},
  number={9},
  year={2023},
  publisher={Elsevier}
}

@article{zhang2023multimodal,
  title={Multimodal chain-of-thought reasoning in language models},
  author={Zhang, Zhuosheng and Zhang, Aston and Li, Mu and Zhao, Hai and Karypis, George and Smola, Alex},
  journal={arXiv preprint arXiv:2302.00923},
  year={2023}
}

@article{zhang2023scalable,
  title={Scalable Geometric Fracture Assembly via Co-creation Space among Assemblers},
  author={Zhang, Ruiyuan and Liu, Jiaxiang and Li, Zexi and Dong, Hao and Fu, Jie and Wu, Chao},
  journal={arXiv preprint arXiv:2312.12340},
  year={2023}
}

@inproceedings{lin2021stm,
  title={STM-multifrontal QR: streaming task mapping multifrontal QR factorization empowered by GCN},
  author={Lin, Shengle and Yang, Wangdong and Wang, Haotian and Tsai, Qinyun and Li, Kenli},
  booktitle={Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis},
  pages={1--14},
  year={2021}
}

@inproceedings{zheng2023ddcot,
  title={DDCoT: Duty-Distinct Chain-of-Thought Prompting for Multimodal Reasoning in Language Models},
  author={Zheng, Ge and Yang, Bin and Tang, Jiajin and Zhou, Hong-Yu and Yang, Sibei},
  booktitle={Thirty-seventh Conference on Neural Information Processing Systems},
  year={2023}
}

@inproceedings{wang2020revisiting,
  title={Revisiting Locally Supervised Learning: an Alternative to End-to-end Training},
  author={Wang, Yulin and Ni, Zanlin and Song, Shiji and Yang, Le and Huang, Gao},
  booktitle={International Conference on Learning Representations},
  year={2020}
}

@article{liu2023parameter,
  title={Parameter-efficient transfer learning for medical visual question answering},
  author={Liu, Jiaxiang and Hu, Tianxiang and Zhang, Yan and Feng, Yang and Hao, Jin and Lv, Junhui and Liu, Zuozhu},
  journal={IEEE Transactions on Emerging Topics in Computational Intelligence},
  year={2023},
  publisher={IEEE}
}

@article{kojima2022large,
  title={Large language models are zero-shot reasoners},
  author={Kojima, Takeshi and Gu, Shixiang Shane and Reid, Machel and Matsuo, Yutaka and Iwasawa, Yusuke},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={22199--22213},
  year={2022}
}

@inproceedings{rubin2022learning,
  title={Learning To Retrieve Prompts for In-Context Learning},
  author={Rubin, Ohad and Herzig, Jonathan and Berant, Jonathan},
  booktitle={Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies},
  pages={2655--2671},
  year={2022}
}


@article{zhang2023llama,
  title={Llama-adapter: Efficient fine-tuning of language models with zero-init attention},
  author={Zhang, Renrui and Han, Jiaming and Zhou, Aojun and Hu, Xiangfei and Yan, Shilin and Lu, Pan and Li, Hongsheng and Gao, Peng and Qiao, Yu},
  journal={arXiv preprint arXiv:2303.16199},
  year={2023}
}

@inproceedings{howard2018universal,
  title={Universal Language Model Fine-tuning for Text Classification},
  author={Howard, Jeremy and Ruder, Sebastian},
  booktitle={Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={328--339},
  year={2018}
}

@inproceedings{chen2020recall,
  title={Recall and Learn: Fine-tuning Deep Pretrained Language Models with Less Forgetting},
  author={Chen, Sanyuan and Hou, Yutai and Cui, Yiming and Che, Wanxiang and Liu, Ting and Yu, Xiangzhan},
  booktitle={Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  pages={7870--7881},
  year={2020}
}

@inproceedings{yang2020towards,
  title={Towards making the most of bert in neural machine translation},
  author={Yang, Jiacheng and Wang, Mingxuan and Zhou, Hao and Zhao, Chengqi and Zhang, Weinan and Yu, Yong and Li, Lei},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={34},
  number={05},
  pages={9378--9385},
  year={2020}
}

@article{ouyang2022training,
  title={Training language models to follow instructions with human feedback},
  author={Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={27730--27744},
  year={2022}
}

@inproceedings{khashabi2020unifiedqa,
  title={UNIFIEDQA: Crossing Format Boundaries with a Single QA System},
  author={Khashabi, Daniel and Min, Sewon and Khot, Tushar and Sabharwal, Ashish and Tafjord, Oyvind and Clark, Peter and Hajishirzi, Hannaneh},
  booktitle={Findings of the Association for Computational Linguistics: EMNLP 2020},
  pages={1896--1907},
  year={2020}
}

@article{dai2305instructblip,
  title={InstructBLIP: Towards General-purpose Vision-Language Models with Instruction Tuning. arXiv 2023},
  author={Dai, W and Li, J and Li, D and Tiong, AMH and Zhao, J and Wang, W and Li, B and Fung, P and Hoi, S},
  journal={arXiv preprint arXiv:2305.06500}
}

@inproceedings{carion2020end,
  title={End-to-end object detection with transformers},
  author={Carion, Nicolas and Massa, Francisco and Synnaeve, Gabriel and Usunier, Nicolas and Kirillov, Alexander and Zagoruyko, Sergey},
  booktitle={European conference on computer vision},
  pages={213--229},
  year={2020},
  organization={Springer}
}

@article{paszke2019pytorch,
  title={Pytorch: An imperative style, high-performance deep learning library},
  author={Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and others},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@inproceedings{wolf2020transformers,
  title={Transformers: State-of-the-art natural language processing},
  author={Wolf, Thomas and Debut, Lysandre and Sanh, Victor and Chaumond, Julien and Delangue, Clement and Moi, Anthony and Cistac, Pierric and Rault, Tim and Louf, R{\'e}mi and Funtowicz, Morgan and others},
  booktitle={Proceedings of the 2020 conference on empirical methods in natural language processing: system demonstrations},
  pages={38--45},
  year={2020}
}

@inproceedings{yu2019deep,
  title={Deep modular co-attention networks for visual question answering},
  author={Yu, Zhou and Yu, Jun and Cui, Yuhao and Tao, Dacheng and Tian, Qi},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={6281--6290},
  year={2019}
}

@inproceedings{anderson2018bottom,
  title={Bottom-up and top-down attention for image captioning and visual question answering},
  author={Anderson, Peter and He, Xiaodong and Buehler, Chris and Teney, Damien and Johnson, Mark and Gould, Stephen and Zhang, Lei},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={6077--6086},
  year={2018}
}


@inproceedings{gao2019dynamic,
  title={Dynamic fusion with intra-and inter-modality attention flow for visual question answering},
  author={Gao, Peng and Jiang, Zhengkai and You, Haoxuan and Lu, Pan and Hoi, Steven CH and Wang, Xiaogang and Li, Hongsheng},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={6639--6648},
  year={2019}
}

@inproceedings{kim2021vilt,
  title={Vilt: Vision-and-language transformer without convolution or region supervision},
  author={Kim, Wonjae and Son, Bokyung and Kim, Ildoo},
  booktitle={International Conference on Machine Learning},
  pages={5583--5594},
  year={2021},
  organization={PMLR}
}

@inproceedings{lu2021iconqa,
  title={IconQA: A New Benchmark for Abstract Diagram Understanding and Visual Language Reasoning},
  author={Lu, Pan and Qiu, Liang and Chen, Jiaqi and Xia, Tony and Zhao, Yizhou and Zhang, Wei and Yu, Zhou and Liang, Xiaodan and Zhu, Song-Chun},
  booktitle={Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track (Round 2)},
  year={2021}
}

@article{li2019visualbert,
  title={Visualbert: A simple and performant baseline for vision and language},
  author={Li, Liunian Harold and Yatskar, Mark and Yin, Da and Hsieh, Cho-Jui and Chang, Kai-Wei},
  journal={arXiv preprint arXiv:1908.03557},
  year={2019}
}

@article{chen2020big,
  title={Big self-supervised models are strong semi-supervised learners},
  author={Chen, Ting and Kornblith, Simon and Swersky, Kevin and Norouzi, Mohammad and Hinton, Geoffrey E},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={22243--22255},
  year={2020}
}


@book{daniel2017thinking,
  title={Thinking, fast and slow},
  author={Daniel, Kahneman},
  year={2017}
}

@inproceedings{booch2021thinking,
  title={Thinking fast and slow in AI},
  author={Booch, Grady and Fabiano, Francesco and Horesh, Lior and Kate, Kiran and Lenchner, Jonathan and Linck, Nick and Loreggia, Andreas and Murgesan, Keerthiram and Mattei, Nicholas and Rossi, Francesca and others},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={35},
  number={17},
  pages={15042--15046},
  year={2021}
}

@article{lu2023chameleon,
  title={Chameleon: Plug-and-play compositional reasoning with large language models},
  author={Lu, Pan and Peng, Baolin and Cheng, Hao and Galley, Michel and Chang, Kai-Wei and Wu, Ying Nian and Zhu, Song-Chun and Gao, Jianfeng},
  journal={arXiv preprint arXiv:2304.09842},
  year={2023}
}

@inproceedings{ritter2017cognitive,
  title={Cognitive psychology for deep neural networks: A shape bias case study},
  author={Ritter, Samuel and Barrett, David GT and Santoro, Adam and Botvinick, Matt M},
  booktitle={International conference on machine learning},
  pages={2940--2949},
  year={2017},
  organization={PMLR}
}

@article{zhao2022cognitive,
  title={Cognitive psychology-based artificial intelligence review},
  author={Zhao, Jian and Wu, Mengqing and Zhou, Liyun and Wang, Xuezhu and Jia, Jian},
  journal={Frontiers in Neuroscience},
  volume={16},
  pages={1024316},
  year={2022},
  publisher={Frontiers Media SA}
}

@article{rosenfeld2012combining,
  title={Combining psychological models with machine learning to better predict people’s decisions},
  author={Rosenfeld, Avi and Zuckerman, Inon and Azaria, Amos and Kraus, Sarit},
  journal={Synthese},
  volume={189},
  pages={81--93},
  year={2012},
  publisher={Springer}
}

@article{taylor2021artificial,
  title={Artificial cognition: How experimental psychology can help generate explainable artificial intelligence},
  author={Taylor, J Eric T and Taylor, Graham W},
  journal={Psychonomic Bulletin \& Review},
  volume={28},
  number={2},
  pages={454--475},
  year={2021},
  publisher={Springer}
}

@article{breit2023combining,
  title={Combining machine learning and semantic web: A systematic mapping study},
  author={Breit, Anna and Waltersdorfer, Laura and Ekaputra, Fajar J and Sabou, Marta and Ekelhart, Andreas and Iana, Andreea and Paulheim, Heiko and Portisch, Jan and Revenko, Artem and Teije, Annette ten and others},
  journal={ACM Computing Surveys},
  year={2023},
  publisher={ACM New York, NY}
}

@inproceedings{
wang2023selfconsistency,
title={Self-Consistency Improves Chain of Thought Reasoning in Language Models},
author={Xuezhi Wang and Jason Wei and Dale Schuurmans and Quoc V Le and Ed H. Chi and Sharan Narang and Aakanksha Chowdhery and Denny Zhou},
booktitle={The Eleventh International Conference on Learning Representations },
year={2023},
url={https://openreview.net/forum?id=1PL1NIMMrw}
}


@inproceedings{zhang2022automatic,
  title={Automatic Chain of Thought Prompting in Large Language Models},
  author={Zhang, Zhuosheng and Zhang, Aston and Li, Mu and Smola, Alex},
  booktitle={The Eleventh International Conference on Learning Representations},
  year={2022}
}

@inproceedings{wang2022self,
  title={Self-Consistency Improves Chain of Thought Reasoning in Language Models},
  author={Wang, Xuezhi and Wei, Jason and Schuurmans, Dale and Le, Quoc V and Chi, Ed H and Narang, Sharan and Chowdhery, Aakanksha and Zhou, Denny},
  booktitle={The Eleventh International Conference on Learning Representations},
  year={2022}
}

@article{tang2023towards,
  title={Towards causalgpt: A multi-agent approach for faithful knowledge reasoning via promoting causal consistency in llms},
  author={Tang, Ziyi and Wang, Ruilin and Chen, Weixing and Wang, Keze and Liu, Yang and Chen, Tianshui and Lin, Liang},
  journal={arXiv preprint arXiv:2308.11914},
  year={2023}
}

@inproceedings{hirashima2011learning,
  title={Learning by problem-posing for reverse-thinking problems},
  author={Hirashima, Tsukasa and Kurayama, Megumi},
  booktitle={Artificial Intelligence in Education: 15th International Conference, AIED 2011, Auckland, New Zealand, June 28--July 2011 15},
  pages={123--130},
  year={2011},
  organization={Springer}
}

@article{li2020modeling,
  title={Modeling reverse thinking for machine learning},
  author={Li, Huihui and Wen, Guihua},
  journal={Soft Computing},
  volume={24},
  pages={1483--1496},
  year={2020},
  publisher={Springer}
}

@inproceedings{sakaguchi1967interaction,
  title={Interaction information in multivariate probability distributions},
  author={Sakaguchi, Minoru},
  booktitle={Kodai Mathematical Seminar Reports},
  volume={19},
  number={2},
  pages={147--155},
  year={1967},
  organization={Department of Mathematics, Tokyo Institute of Technology}
}

@article{zhang2024cocot,
  title={CoCoT: Contrastive Chain-of-Thought Prompting for Large Multimodal Models with Multiple Image Inputs},
  author={Zhang, Daoan and Yang, Junming and Lyu, Hanjia and Jin, Zijian and Yao, Yuan and Chen, Mingkai and Luo, Jiebo},
  journal={arXiv preprint arXiv:2401.02582},
  year={2024}
}


@article{chu2023survey,
  title={A survey of chain of thought reasoning: Advances, frontiers and future},
  author={Chu, Zheng and Chen, Jingchang and Chen, Qianglong and Yu, Weijiang and He, Tao and Wang, Haotian and Peng, Weihua and Liu, Ming and Qin, Bing and Liu, Ting},
  journal={arXiv preprint arXiv:2309.15402},
  year={2023}
}

@inproceedings{mahabadi2020end,
  title={End-to-End Bias Mitigation by Modelling Biases in Corpora},
  author={Mahabadi, Rabeeh Karimi and Belinkov, Yonatan and Henderson, James},
  booktitle={Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},
  pages={8706--8716},
  year={2020}
}

@inproceedings{liang2023prompting,
  title={Prompting Large Language Models with Chain-of-Thought for Few-Shot Knowledge Base Question Generation},
  author={Liang, Yuanyuan and Wang, Jianing and Zhu, Hanlun and Wang, Lei and Qian, Weining and Lan, Yunshi},
  booktitle={Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing},
  pages={4329--4343},
  year={2023}
}

@inproceedings{fu2021automatic,
  title={Automatic Classification of Human Translation and Machine Translation: A Study from the Perspective of Lexical Diversity},
  author={Fu, Yingxue and Nederhof, Mark-Jan},
  booktitle={Proceedings for the First Workshop on Modelling Translation: Translatology in the Digital Age},
  pages={91--99},
  year={2021}
}

@inproceedings{nam2017dual,
  title={Dual attention networks for multimodal reasoning and matching},
  author={Nam, Hyeonseob and Ha, Jung-Woo and Kim, Jeonghee},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={299--307},
  year={2017}
}

@article{yang2023mm,
  title={Mm-react: Prompting chatgpt for multimodal reasoning and action},
  author={Yang, Zhengyuan and Li, Linjie and Wang, Jianfeng and Lin, Kevin and Azarnasab, Ehsan and Ahmed, Faisal and Liu, Zicheng and Liu, Ce and Zeng, Michael and Wang, Lijuan},
  journal={arXiv preprint arXiv:2303.11381},
  year={2023}
}

@article{wang2024exploring,
  title={Exploring the Reasoning Abilities of Multimodal Large Language Models (MLLMs): A Comprehensive Survey on Emerging Trends in Multimodal Reasoning},
  author={Wang, Yiqi and Chen, Wentao and Han, Xiaotian and Lin, Xudong and Zhao, Haiteng and Liu, Yongfei and Zhai, Bohan and Yuan, Jianbo and You, Quanzeng and Yang, Hongxia},
  journal={arXiv preprint arXiv:2401.06805},
  year={2024}
}

@article{zhang2021dmrfnet,
  title={DMRFNet: deep multimodal reasoning and fusion for visual question answering and explanation generation},
  author={Zhang, Weifeng and Yu, Jing and Zhao, Wenhong and Ran, Chuan},
  journal={Information Fusion},
  volume={72},
  pages={70--79},
  year={2021},
  publisher={Elsevier}
}

% hallucinations
@article{hallucinations1,
  title={Hallucinations in large multilingual translation models},
  author={Guerreiro, Nuno M and Alves, Duarte M and Waldendorf, Jonas and Haddow, Barry and Birch, Alexandra and Colombo, Pierre and Martins, Andr{\'e} FT},
  journal={Transactions of the Association for Computational Linguistics},
  volume={11},
  pages={1500--1517},
  year={2023},
  publisher={MIT Press One Broadway, 12th Floor, Cambridge, Massachusetts 02142, USA~…}
}

@article{hallucinations2,
  title={A survey on hallucination in large language models: Principles, taxonomy, challenges, and open questions},
  author={Huang, Lei and Yu, Weijiang and Ma, Weitao and Zhong, Weihong and Feng, Zhangyin and Wang, Haotian and Chen, Qianglong and Peng, Weihua and Feng, Xiaocheng and Qin, Bing and others},
  journal={arXiv preprint arXiv:2311.05232},
  year={2023}
}

@article{dubois2000knowledge,
  title={Knowledge-driven versus data-driven logics},
  author={Dubois, Didier and H{\'a}jek, Petr and Prade, Henri},
  journal={Journal of logic, Language and information},
  volume={9},
  pages={65--89},
  year={2000},
  publisher={Springer}
}

@inproceedings{peng2020bi,
  title={Bi-directional CognitiveThinking Network for Machine Reading Comprehension},
  author={Peng, Wei and Hu, Yue and Xing, Luxi and Xie, Yuqiang and Yu, Jing and Sun, Yajing and Wei, Xiangpeng},
  booktitle={Proceedings of the 28th International Conference on Computational Linguistics},
  pages={2613--2623},
  year={2020}
}


@article{liu2024visual,
  title={Visual instruction tuning},
  author={Liu, Haotian and Li, Chunyuan and Wu, Qingyang and Lee, Yong Jae},
  journal={Advances in neural information processing systems},
  volume={36},
  year={2024}
}

@article{gupta2021hierarchical,
  title={Hierarchical deep multi-modal network for medical visual question answering},
  author={Gupta, Deepak and Suman, Swati and Ekbal, Asif},
  journal={Expert Systems with Applications},
  volume={164},
  pages={113993},
  year={2021},
  publisher={Elsevier}
}
@ARTICLE{Liujiaxiang2023Adapter,
  author={Liu, Jiaxiang and Hu, Tianxiang and Zhang, Yan and Feng, Yang and Hao, Jin and Lv, Junhui and Liu, Zuozhu},
  journal={IEEE Transactions on Emerging Topics in Computational Intelligence}, 
  title={Parameter-Efficient Transfer Learning for Medical Visual Question Answering}, 
  year={2023},
  volume={},
  number={},
  pages={1-11},
  doi={10.1109/TETCI.2023.3311333}}

@article{litjens2017survey,
  title={A survey on deep learning in medical image analysis},
  author={Litjens, Geert and Kooi, Thijs and Bejnordi, Babak Ehteshami and Setio, Arnaud Arindra Adiyoso and Ciompi, Francesco and Ghafoorian, Mohsen and Van Der Laak, Jeroen Awm and Van Ginneken, Bram and S{\'a}nchez, Clara I},
  journal={Medical image analysis},
  volume={42},
  pages={60--88},
  year={2017},
  publisher={Elsevier}
}

@article{kermany2018identifying,
  title={Identifying medical diagnoses and treatable diseases by image-based deep learning},
  author={Kermany, Daniel S and Goldbaum, Michael and Cai, Wenjia and Valentim, Carolina CS and Liang, Huiying and Baxter, Sally L and McKeown, Alex and Yang, Ge and Wu, Xiaokang and Yan, Fangbing and others},
  journal={cell},
  volume={172},
  number={5},
  pages={1122--1131},
  year={2018},
  publisher={Elsevier}
}
@article{jaeger2014two,
  title={Two public chest X-ray datasets for computer-aided screening of pulmonary diseases},
  author={Jaeger, Stefan and Candemir, Sema and Antani, Sameer and W{\'a}ng, Y{\`\i}-Xi{\'a}ng J and Lu, Pu-Xuan and Thoma, George},
  journal={Quantitative imaging in medicine and surgery},
  volume={4},
  number={6},
  pages={475},
  year={2014},
  publisher={AME Publications}
}
@article{porwal2018indian,
  title={Indian diabetic retinopathy image dataset (IDRiD): a database for diabetic retinopathy screening research},
  author={Porwal, Prasanna and Pachade, Samiksha and Kamble, Ravi and Kokare, Manesh and Deshmukh, Girish and Sahasrabuddhe, Vivek and Meriaudeau, Fabrice},
  journal={Data},
  volume={3},
  number={3},
  pages={25},
  year={2018},
  publisher={MDPI}
}


@InProceedings{Chefer_2021_ICCV,
    author    = {Chefer, Hila and Gur, Shir and Wolf, Lior},
    title     = {Generic Attention-Model Explainability for Interpreting Bi-Modal and Encoder-Decoder Transformers},
    booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
    month     = {October},
    year      = {2021},
    pages     = {397-406}
}

@article{lin2023medical,
  title={Medical visual question answering: A survey},
  author={Lin, Zhihong and Zhang, Donghao and Tao, Qingyi and Shi, Danli and Haffari, Gholamreza and Wu, Qi and He, Mingguang and Ge, Zongyuan},
  journal={Artificial Intelligence in Medicine},
  pages={102611},
  year={2023},
  publisher={Elsevier}
}

@article{hasan2018overview,
  title={Overview of imageclef 2018 medical domain visual question answering task},
  author={Hasan, Sadid A and Ling, Yuan and Farri, Oladimeji and Liu, Joey and M{\"u}ller, Henning and Lungren, Matthew},
  journal={Proceedings of CLEF 2018 Working Notes},
  year={2018},
  publisher={10-14 September 2018}
}
@article{openai2023gpt4,
  title={GPT-4 Technical Report},
  author={Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others},
  journal={arXiv preprint arXiv:2303.08774},
  year={2023}
}

@article{zhu2023minigpt,
  title={Minigpt-4: Enhancing vision-language understanding with advanced large language models},
  author={Zhu, Deyao and Chen, Jun and Shen, Xiaoqian and Li, Xiang and Elhoseiny, Mohamed},
  journal={arXiv preprint arXiv:2304.10592},
  year={2023}
}
@article{liu2023improved,
  title={Improved baselines with visual instruction tuning},
  author={Liu, Haotian and Li, Chunyuan and Li, Yuheng and Lee, Yong Jae},
  journal={arXiv preprint arXiv:2310.03744},
  year={2023}
}
@article{bai2023qwen,
  title={Qwen-vl: A frontier large vision-language model with versatile abilities},
  author={Bai, Jinze and Bai, Shuai and Yang, Shusheng and Wang, Shijie and Tan, Sinan and Wang, Peng and Lin, Junyang and Zhou, Chang and Zhou, Jingren},
  journal={arXiv preprint arXiv:2308.12966},
  year={2023}
}
@article{team2023gemini,
  title={Gemini: a family of highly capable multimodal models},
  author={Team, Gemini and Anil, Rohan and Borgeaud, Sebastian and Wu, Yonghui and Alayrac, Jean-Baptiste and Yu, Jiahui and Soricut, Radu and Schalkwyk, Johan and Dai, Andrew M and Hauth, Anja and others},
  journal={arXiv preprint arXiv:2312.11805},
  year={2023}
}
@article{kavur2021chaos,
  title={CHAOS challenge-combined (CT-MR) healthy abdominal organ segmentation},
  author={Kavur, A Emre and Gezer, N Sinem and Bar{\i}{\c{s}}, Mustafa and Aslan, Sinem and Conze, Pierre-Henri and Groza, Vladimir and Pham, Duc Duy and Chatterjee, Soumick and Ernst, Philipp and {\"O}zkan, Sava{\c{s}} and others},
  journal={Medical Image Analysis},
  volume={69},
  pages={101950},
  year={2021},
  publisher={Elsevier}
}
@inproceedings{wang2017chestx,
  title={Chestx-ray8: Hospital-scale chest x-ray database and benchmarks on weakly-supervised classification and localization of common thorax diseases},
  author={Wang, Xiaosong and Peng, Yifan and Lu, Le and Lu, Zhiyong and Bagheri, Mohammadhadi and Summers, Ronald M},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={2097--2106},
  year={2017}
}
@article{simpson2019large,
  title={A large annotated medical image dataset for the development and evaluation of segmentation algorithms},
  author={Simpson, Amber L and Antonelli, Michela and Bakas, Spyridon and Bilello, Michel and Farahani, Keyvan and Van Ginneken, Bram and Kopp-Schneider, Annette and Landman, Bennett A and Litjens, Geert and Menze, Bjoern and others},
  journal={arXiv preprint arXiv:1902.09063},
  year={2019}
}
@article{DBLP:journals/corr/abs-1901-07042,
  author       = {Alistair E. W. Johnson and
                  Tom J. Pollard and
                  Seth J. Berkowitz and
                  Nathaniel R. Greenbaum and
                  Matthew P. Lungren and
                  Chih{-}ying Deng and
                  Roger G. Mark and
                  Steven Horng},
  title        = {{MIMIC-CXR:} {A} large publicly available database of labeled chest
                  radiographs},
  journal      = {CoRR},
  volume       = {abs/1901.07042},
  year         = {2019},
  url          = {http://arxiv.org/abs/1901.07042},
  eprinttype    = {arXiv},
  eprint       = {1901.07042},
  timestamp    = {Thu, 14 Oct 2021 09:14:23 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1901-07042.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{ben2021overview,
  title={Overview of the vqa-med task at imageclef 2021: Visual question answering and generation in the medical domain},
  author={Ben Abacha, Asma and Sarrouti, Mourad and Demner-Fushman, Dina and Hasan, Sadid A and M{\"u}ller, Henning},
  booktitle={Proceedings of the CLEF 2021 Conference and Labs of the Evaluation Forum-working notes},
  year={2021},
  organization={21-24 September 2021}
}
@ARTICLE{Lau2018,
	author = {Lau, Denys T. and Strashny, Alex and Phan, Kellina and Blum, Amy L. and Burke-Bebee, Suzie},
	title = {Evaluation of transition from ICD-9-CM to ICD-10-CM diagnosis coding system in the national ambulatory medical care survey},
	year = {2018},
	journal = {National Health Statistics Reports},
	volume = {2018},
	number = {120},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060914386&partnerID=40&md5=644a66a65f6d08348ff7fb4ee0f9130f},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6}
}
@inproceedings{ben2019vqa,
  title={Vqa-med: Overview of the medical visual question answering task at imageclef 2019},
  author={Ben Abacha, Asma and Hasan, Sadid A and Datla, Vivek V and Demner-Fushman, Dina and M{\"u}ller, Henning},
  booktitle={Proceedings of CLEF (Conference and Labs of the Evaluation Forum) 2019 Working Notes},
  year={2019},
  organization={9-12 September 2019}
}
@INPROCEEDINGS{7410636,
  author={Antol, Stanislaw and Agrawal, Aishwarya and Lu, Jiasen and Mitchell, Margaret and Batra, Dhruv and Zitnick, C. Lawrence and Parikh, Devi},
  booktitle={2015 IEEE International Conference on Computer Vision (ICCV)}, 
  title={VQA: Visual Question Answering}, 
  year={2015},
  volume={},
  number={},
  pages={2425-2433},
  doi={10.1109/ICCV.2015.279}}
@inproceedings{Hasan2018OverviewOI,
  title={Overview of ImageCLEF 2018 Medical Domain Visual Question Answering Task},
  author={Sadid A. Hasan and Yuan Ling and Oladimeji Farri and Joey Liu and Henning M{\"u}ller and Matthew P. Lungren},
  booktitle={Conference and Labs of the Evaluation Forum},
  year={2018},
  url={https://api.semanticscholar.org/CorpusID:51943124}
}
@inproceedings{kovaleva-etal-2020-towards,
    title = "Towards Visual Dialog for Radiology",
    author = "Kovaleva, Olga  and
      Shivade, Chaitanya  and
      Kashyap, Satyananda  and
      Kanjaria, Karina  and
      Wu, Joy  and
      Ballah, Deddeh  and
      Coy, Adam  and
      Karargyris, Alexandros  and
      Guo, Yufan  and
      Beymer, David Beymer  and
      Rumshisky, Anna  and
      Mukherjee, Vandana Mukherjee",
    editor = "Demner-Fushman, Dina  and
      Cohen, Kevin Bretonnel  and
      Ananiadou, Sophia  and
      Tsujii, Junichi",
    booktitle = "Proceedings of the 19th SIGBioMed Workshop on Biomedical Language Processing",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.bionlp-1.6",
    doi = "10.18653/v1/2020.bionlp-1.6",
    pages = "60--69",
    abstract = "Current research in machine learning for radiology is focused mostly on images. There exists limited work in investigating intelligent interactive systems for radiology. To address this limitation, we introduce a realistic and information-rich task of Visual Dialog in radiology, specific to chest X-ray images. Using MIMIC-CXR, an openly available database of chest X-ray images, we construct both a synthetic and a real-world dataset and provide baseline scores achieved by state-of-the-art models. We show that incorporating medical history of the patient leads to better performance in answering questions as opposed to conventional visual question answering model which looks only at the image. While our experiments show promising results, they indicate that the task is extremely challenging with significant scope for improvement. We make both the datasets (synthetic and gold standard) and the associated code publicly available to the research community.",
}
@misc{he2020pathvqa,
      title={PathVQA: 30000+ Questions for Medical Visual Question Answering}, 
      author={Xuehai He and Yichen Zhang and Luntian Mou and Eric Xing and Pengtao Xie},
      year={2020},
      eprint={2003.10286},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@article{tschandl2020human,
  title={Human--computer collaboration for skin cancer recognition},
  author={Tschandl, Philipp and Rinner, Christoph and Apalla, Zoe and Argenziano, Giuseppe and Codella, Noel and Halpern, Allan and Janda, Monika and Lallas, Aimilios and Longo, Caterina and Malvehy, Josep and others},
  journal={Nature Medicine},
  volume={26},
  number={8},
  pages={1229--1234},
  year={2020},
  publisher={Nature Publishing Group US New York}
}


@inproceedings{khot2020qasc,
  title={Qasc: A dataset for question answering via sentence composition},
  author={Khot, Tushar and Clark, Peter and Guerquin, Michal and Jansen, Peter and Sabharwal, Ashish},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={34},
  number={05},
  pages={8082--8090},
  year={2020}
}

@article{jhamtani2020learning,
  title={Learning to explain: Datasets and models for identifying valid reasoning chains in multihop question-answering},
  author={Jhamtani, Harsh and Clark, Peter},
  journal={arXiv preprint arXiv:2010.03274},
  year={2020}
}

@inproceedings{kembhavi2017you,
  title={Are you smarter than a sixth grader? textbook question answering for multimodal machine comprehension},
  author={Kembhavi, Aniruddha and Seo, Minjoon and Schwenk, Dustin and Choi, Jonghyun and Farhadi, Ali and Hajishirzi, Hannaneh},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern recognition},
  pages={4999--5007},
  year={2017}
}


@misc{openai2023gpt4vision,
  title        = {{GPT-4V(ision) System Card}},
  author       = {{OpenAI}},
  year         = 2023,
  howpublished = {\url{https://cdn.openai.com/papers/GPTV_System_Card.pdf}},
  note         = {Accessed: 2023-12-29}
}

@article{zhang2023pmc,
  title={Pmc-vqa: Visual instruction tuning for medical visual question answering},
  author={Zhang, Xiaoman and Wu, Chaoyi and Zhao, Ziheng and Lin, Weixiong and Zhang, Ya and Wang, Yanfeng and Xie, Weidi},
  journal={arXiv preprint arXiv:2305.10415},
  year={2023}
}




@inproceedings{eslami-etal-2023-pubmedclip,
    title = "{P}ub{M}ed{CLIP}: How Much Does {CLIP} Benefit Visual Question Answering in the Medical Domain?",
    author = "Eslami, Sedigheh  and
      Meinel, Christoph  and
      de Melo, Gerard",
    editor = "Vlachos, Andreas  and
      Augenstein, Isabelle",
    booktitle = "Findings of the Association for Computational Linguistics: EACL 2023",
    month = may,
    year = "2023",
    address = "Dubrovnik, Croatia",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.findings-eacl.88",
    doi = "10.18653/v1/2023.findings-eacl.88",
    pages = "1181--1193",
    abstract = "Contrastive Language{--}Image Pre-training (CLIP) has shown remarkable success in learning with cross-modal supervision from extensive amounts of image{--}text pairs collected online. Thus far, the effectiveness of CLIP has been investigated primarily in general-domain multimodal problems. In this work, we evaluate the effectiveness of CLIP for the task of Medical Visual Question Answering (MedVQA). We present PubMedCLIP, a fine-tuned version of CLIP for the medical domain based on PubMed articles. Our experiments conducted on two MedVQA benchmark datasets illustrate that PubMedCLIP achieves superior results improving the overall accuracy up to 3{\%} in comparison to the state-of-the-art Model-Agnostic Meta-Learning (MAML) networks pre-trained only on visual data. The PubMedCLIP model with different back-ends, the source code for pre-training them and reproducing our MedVQA pipeline is publicly available at \url{https://github.com/sarahESL/PubMedCLIP}.",
}

@inproceedings{tiong-etal-2022-plug,
    title = "Plug-and-Play {VQA}: Zero-shot {VQA} by Conjoining Large Pretrained Models with Zero Training",
    author = "Tiong, Anthony Meng Huat  and
      Li, Junnan  and
      Li, Boyang  and
      Savarese, Silvio  and
      Hoi, Steven C.H.",
    editor = "Goldberg, Yoav  and
      Kozareva, Zornitsa  and
      Zhang, Yue",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2022",
    month = dec,
    year = "2022",
    address = "Abu Dhabi, United Arab Emirates",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.findings-emnlp.67",
    doi = "10.18653/v1/2022.findings-emnlp.67",
    pages = "951--967",
    abstract = "Visual question answering (VQA) is a hallmark of vision and language reasoningand a challenging task under the zero-shot setting. We propose Plug-and-Play VQA (PNP-VQA),a modular framework for zero-shot VQA.In contrast to most existing works, which require substantial adaptation of pretrained language models (PLMs) for the vision modality,PNP-VQA requires no additional training of the PLMs.Instead, we propose to use natural language and network interpretation as an intermediate representation that glues pretrained models together. We first generate question-guided informative image captions,and pass the captions to a PLM as context for question answering. Surpassing end-to-end trained baselines, PNP-VQA achieves state-of-the-art results on zero-shot VQAv2 and GQA. With 11B parameters, it outperforms the 80B-parameter Flamingo model by 8.5{\%} on VQAv2. With 738M PLM parameters, PNP-VQA achieves an improvement of 9.1{\%} on GQA over FewVLM with 740M PLM parameters.",
}




@inproceedings{liu2023chatgpt,
  title={A ChatGPT Aided Explainable Framework for Zero-Shot Medical Image Diagnosis},
  author={Liu, Jiaxiang and Hu, Tianxiang and Zhang, Yan and Gai, Xiaotang and FENG, YANG and Liu, Zuozhu},
  booktitle={ICML 3rd Workshop on Interpretable Machine Learning in Healthcare (IMLH)},
  year={2023}
}

@inproceedings{do2021multiple,
  title={Multiple meta-model quantifying for medical visual question answering},
  author={Do, Tuong and Nguyen, Binh X and Tjiputra, Erman and Tran, Minh and Tran, Quang D and Nguyen, Anh},
  booktitle={Medical Image Computing and Computer Assisted Intervention--MICCAI 2021: 24th International Conference, Strasbourg, France, September 27--October 1, 2021, Proceedings, Part V 24},
  pages={64--74},
  year={2021},
  organization={Springer}
}

@inproceedings{al2019just,
  title={JUST at ImageCLEF 2019 Visual Question Answering in the Medical Domain.},
  author={Al-Sadi, Aisha and Talafha, Bashar and Al-Ayyoub, Mahmoud and Jararweh, Yaser and Costen, Fumie},
  booktitle={CLEF (working notes)},
  year={2019}
}

@inproceedings{jung2020bumjun_jung,
  title={bumjun\_jung at VQA-Med 2020: VQA Model Based on Feature Extraction and Multi-modal Feature Fusion.},
  author={Jung, Bumjun and Gu, Lin and Harada, Tatsuya},
  booktitle={CLEF (Working Notes)},
  year={2020}
}


@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}

@article{chowdhery2023palm,
  title={Palm: Scaling language modeling with pathways},
  author={Chowdhery, Aakanksha and Narang, Sharan and Devlin, Jacob and Bosma, Maarten and Mishra, Gaurav and Roberts, Adam and Barham, Paul and Chung, Hyung Won and Sutton, Charles and Gehrmann, Sebastian and others},
  journal={Journal of Machine Learning Research},
  volume={24},
  number={240},
  pages={1--113},
  year={2023}
}

@article{raffel2020exploring,
  title={Exploring the limits of transfer learning with a unified text-to-text transformer},
  author={Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J},
  journal={The Journal of Machine Learning Research},
  volume={21},
  number={1},
  pages={5485--5551},
  year={2020},
  publisher={JMLRORG}
}

@article{rae2021scaling,
  title={Scaling language models: Methods, analysis \& insights from training gopher},
  author={Rae, Jack W and Borgeaud, Sebastian and Cai, Trevor and Millican, Katie and Hoffmann, Jordan and Song, Francis and Aslanides, John and Henderson, Sarah and Ring, Roman and Young, Susannah and others},
  journal={arXiv preprint arXiv:2112.11446},
  year={2021}
}

@article{ling2017program,
  title={Program induction by rationale generation: Learning to solve and explain algebraic word problems},
  author={Ling, Wang and Yogatama, Dani and Dyer, Chris and Blunsom, Phil},
  journal={arXiv preprint arXiv:1705.04146},
  year={2017}
}

@inproceedings{peters-etal-2018-deep,
    title = "Deep Contextualized Word Representations",
    author = "Peters, Matthew E.  and
      Neumann, Mark  and
      Iyyer, Mohit  and
      Gardner, Matt  and
      Clark, Christopher  and
      Lee, Kenton  and
      Zettlemoyer, Luke",
    editor = "Walker, Marilyn  and
      Ji, Heng  and
      Stent, Amanda",
    booktitle = "Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)",
    month = jun,
    year = "2018",
    address = "New Orleans, Louisiana",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N18-1202",
    doi = "10.18653/v1/N18-1202",
    pages = "2227--2237",
    abstract = "We introduce a new type of deep contextualized word representation that models both (1) complex characteristics of word use (e.g., syntax and semantics), and (2) how these uses vary across linguistic contexts (i.e., to model polysemy). Our word vectors are learned functions of the internal states of a deep bidirectional language model (biLM), which is pre-trained on a large text corpus. We show that these representations can be easily added to existing models and significantly improve the state of the art across six challenging NLP problems, including question answering, textual entailment and sentiment analysis. We also present an analysis showing that exposing the deep internals of the pre-trained network is crucial, allowing downstream models to mix different types of semi-supervision signals.",
}

@article{cobbe2021training,
  title={Training verifiers to solve math word problems},
  author={Cobbe, Karl and Kosaraju, Vineet and Bavarian, Mohammad and Chen, Mark and Jun, Heewoo and Kaiser, Lukasz and Plappert, Matthias and Tworek, Jerry and Hilton, Jacob and Nakano, Reiichiro and others},
  journal={arXiv preprint arXiv:2110.14168},
  year={2021}
}

@inproceedings{chen2019neural,
  title={Neural symbolic reader: Scalable integration of distributed and symbolic representations for reading comprehension},
  author={Chen, Xinyun and Liang, Chen and Yu, Adams Wei and Zhou, Denny and Song, Dawn and Le, Quoc V},
  booktitle={International Conference on Learning Representations},
  year={2019}
}

@article{wei2022chain,
  title={Chain-of-thought prompting elicits reasoning in large language models},
  author={Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Xia, Fei and Chi, Ed and Le, Quoc V and Zhou, Denny and others},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={24824--24837},
  year={2022}
}

@article{qi2023gemini,
  title={Gemini vs GPT-4V: A Preliminary Comparison and Combination of Vision-Language Models Through Qualitative Cases},
  author={Qi, Zhangyang and Fang, Ye and Zhang, Mengchen and Sun, Zeyi and Wu, Tong and Liu, Ziwei and Lin, Dahua and Wang, Jiaqi and Zhao, Hengshuang},
  journal={arXiv preprint arXiv:2312.15011},
  year={2023}
}

@article{fu2023challenger,
  title={A challenger to gpt-4v? early explorations of gemini in visual expertise},
  author={Fu, Chaoyou and Zhang, Renrui and Lin, Haojia and Wang, Zihan and Gao, Timin and Luo, Yongdong and Huang, Yubo and Zhang, Zhengye and Qiu, Longtian and Ye, Gaoxiang and others},
  journal={arXiv preprint arXiv:2312.12436},
  year={2023}
}

@inproceedings{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International conference on machine learning},
  pages={8748--8763},
  year={2021},
  organization={PMLR}
}

@article{nori2023capabilities,
  title={Capabilities of gpt-4 on medical challenge problems},
  author={Nori, Harsha and King, Nicholas and McKinney, Scott Mayer and Carignan, Dean and Horvitz, Eric},
  journal={arXiv preprint arXiv:2303.13375},
  year={2023}
}

@inproceedings{liu2021contrastive,
  title={Contrastive pre-training and representation distillation for medical visual question answering based on radiology images},
  author={Liu, Bo and Zhan, Li-Ming and Wu, Xiao-Ming},
  booktitle={Medical Image Computing and Computer Assisted Intervention--MICCAI 2021: 24th International Conference, Strasbourg, France, September 27--October 1, 2021, Proceedings, Part II 24},
  pages={210--220},
  year={2021},
  organization={Springer}
}

@inproceedings{zhang2022contrastive,
  title={Contrastive learning of medical visual representations from paired images and text},
  author={Zhang, Yuhao and Jiang, Hang and Miura, Yasuhide and Manning, Christopher D and Langlotz, Curtis P},
  booktitle={Machine Learning for Healthcare Conference},
  pages={2--25},
  year={2022},
  organization={PMLR}
}

@article{sharma2021medfusenet,
  title={MedFuseNet: An attention-based multimodal deep learning model for visual question answering in the medical domain},
  author={Sharma, Dhruv and Purushotham, Sanjay and Reddy, Chandan K},
  journal={Scientific Reports},
  volume={11},
  number={1},
  pages={19826},
  year={2021},
  publisher={Nature Publishing Group UK London}
}

@article{lai2024language,
  title={Language models are free boosters for biomedical imaging tasks},
  author={Lai, Zhixin and Wu, Jing and Chen, Suiyao and Zhou, Yucheng and Hovakimyan, Anna and Hovakimyan, Naira},
  journal={arXiv preprint arXiv:2403.17343},
  year={2024}
}

@article{lai2024adaptive,
  title={Adaptive ensembles of fine-tuned transformers for llm-generated text detection},
  author={Lai, Zhixin and Zhang, Xuesheng and Chen, Suiyao},
  journal={arXiv preprint arXiv:2403.13335},
  year={2024}
}

@inproceedings{zhang2024scalable,
  title={Scalable Geometric Fracture Assembly via Co-creation Space among Assemblers},
  author={Zhang, Ruiyuan and Liu, Jiaxiang and Li, Zexi and Dong, Hao and Fu, Jie and Wu, Chao},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={38},
  number={7},
  pages={7269--7277},
  year={2024}
}

@article{gai2024medthink,
  title={MedThink: Explaining Medical Visual Question Answering via Multimodal Decision-Making Rationale},
  author={Gai, Xiaotang and Zhou, Chenyi and Liu, Jiaxiang and Feng, Yang and Wu, Jian and Liu, Zuozhu},
  journal={arXiv preprint arXiv:2404.12372},
  year={2024}
}

@article{jacobs1991adaptive,
  title={Adaptive mixtures of local experts},
  author={Jacobs, Robert A and Jordan, Michael I and Nowlan, Steven J and Hinton, Geoffrey E},
  journal={Neural computation},
  volume={3},
  number={1},
  pages={79--87},
  year={1991},
  publisher={MIT Press}
}

@article{fedus2022review,
  title={A review of sparse expert models in deep learning},
  author={Fedus, William and Dean, Jeff and Zoph, Barret},
  journal={arXiv preprint arXiv:2209.01667},
  year={2022}
}

@inproceedings{shazeer2016outrageously,
  title={Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer},
  author={Shazeer, Noam and Mirhoseini, Azalia and Maziarz, Krzysztof and Davis, Andy and Le, Quoc and Hinton, Geoffrey and Dean, Jeff},
  booktitle={International Conference on Learning Representations},
  year={2016}
}


@inproceedings{lepikhin2020gshard,
  title={GShard: Scaling Giant Models with Conditional Computation and Automatic Sharding},
  author={Lepikhin, Dmitry and Lee, HyoukJoong and Xu, Yuanzhong and Chen, Dehao and Firat, Orhan and Huang, Yanping and Krikun, Maxim and Shazeer, Noam and Chen, Zhifeng},
  booktitle={International Conference on Learning Representations},
  year={2020}
}

@article{fedus2022switch,
  title={Switch transformers: Scaling to trillion parameter models with simple and efficient sparsity},
  author={Fedus, William and Zoph, Barret and Shazeer, Noam},
  journal={Journal of Machine Learning Research},
  volume={23},
  number={120},
  pages={1--39},
  year={2022}
}

@article{huang2023dual,
  title={A Dual-Attention Learning Network with Word and Sentence Embedding for Medical Visual Question Answering},
  author={Huang, Xiaofei and Gong, Hongfang},
  journal={IEEE Transactions on Medical Imaging},
  year={2023},
  publisher={IEEE}
}

@article{bazi2023vision,
  title={Vision--language model for visual question answering in medical imagery},
  author={Bazi, Yakoub and Rahhal, Mohamad Mahmoud Al and Bashmal, Laila and Zuair, Mansour},
  journal={Bioengineering},
  volume={10},
  number={3},
  pages={380},
  year={2023},
  publisher={MDPI}
}

@inproceedings{liu2023q2atransformer,
  title={Q2atransformer: Improving medical vqa via an answer querying decoder},
  author={Liu, Yunyi and Wang, Zhanyu and Xu, Dong and Zhou, Luping},
  booktitle={International Conference on Information Processing in Medical Imaging},
  pages={445--456},
  year={2023},
  organization={Springer}
}

@inproceedings{van2023open,
  title={Open-ended medical visual question answering through prefix tuning of language models},
  author={Van Sonsbeek, Tom and Derakhshani, Mohammad Mahdi and Najdenkoska, Ivona and Snoek, Cees GM and Worring, Marcel},
  booktitle={International Conference on Medical Image Computing and Computer-Assisted Intervention},
  pages={726--736},
  year={2023},
  organization={Springer}
}

@article{lau2018dataset,
  title={A dataset of clinically generated visual questions and answers about radiology images},
  author={Lau, Jason J and Gayen, Soumya and Ben Abacha, Asma and Demner-Fushman, Dina},
  journal={Scientific data},
  volume={5},
  number={1},
  pages={1--10},
  year={2018},
  publisher={Nature Publishing Group}
}


@inproceedings{liu2021slake,
  title={Slake: A semantically-labeled knowledge-enhanced dataset for medical visual question answering},
  author={Liu, Bo and Zhan, Li-Ming and Xu, Li and Ma, Lin and Yang, Yan and Wu, Xiao-Ming},
  booktitle={2021 IEEE 18th International Symposium on Biomedical Imaging (ISBI)},
  pages={1650--1654},
  year={2021},
  organization={IEEE}
}

@article{abacha2019vqa,
  title={VQA-Med: Overview of the medical visual question answering task at ImageCLEF 2019.},
  author={Abacha, Asma Ben and Hasan, Sadid A and Datla, Vivek V and Liu, Joey and Demner-Fushman, Dina and M{\"u}ller, Henning},
  journal={CLEF (working notes)},
  volume={2},
  number={6},
  year={2019}
}

@article{huang2023survey,
  title={A survey on hallucination in large language models: Principles, taxonomy, challenges, and open questions},
  author={Huang, Lei and Yu, Weijiang and Ma, Weitao and Zhong, Weihong and Feng, Zhangyin and Wang, Haotian and Chen, Qianglong and Peng, Weihua and Feng, Xiaocheng and Qin, Bing and others},
  journal={arXiv preprint arXiv:2311.05232},
  year={2023}
}

@inproceedings{Abacha2019VQAMedOO,
  title={VQA-Med: Overview of the Medical Visual Question Answering Task at ImageCLEF 2019},
  author={Asma Ben Abacha and Sadid A. Hasan and Vivek Datla and Joey Liu and Dina Demner-Fushman and Henning M{\"u}ller},
  booktitle={Conference and Labs of the Evaluation Forum},
  year={2019},
  url={https://api.semanticscholar.org/CorpusID:198489641}
}