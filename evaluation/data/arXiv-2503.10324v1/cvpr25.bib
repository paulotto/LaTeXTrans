
@article{smith2022simplified,
  title={Simplified state space layers for sequence modeling},
  author={Smith, Jimmy TH and Warrington, Andrew and Linderman, Scott W},
  journal={arXiv preprint arXiv:2208.04933},
  year={2022}
}
@article{gu2021combining,
  title={Combining recurrent, convolutional, and continuous-time models with linear state space layers},
  author={Gu, Albert and Johnson, Isys and Goel, Karan and Saab, Khaled and Dao, Tri and Rudra, Atri and R{\'e}, Christopher},
  journal={NeurIPS},
  volume={34},
  pages={572--585},
  year={2021}
}

@article{wang2024large,
  title={When Large Vision-Language Models Meet Person Re-Identification},
  author={Wang, Qizao and Li, Bin and Xue, Xiangyang},
  journal={arXiv preprint arXiv:2411.18111},
  year={2024}
}
@article{niu2025chatreid,
  title={ChatReID: Open-ended Interactive Person Retrieval via Hierarchical Progressive Tuning for Vision Language Models},
  author={Niu, Ke and Yu, Haiyang and Zhao, Mengyang and Fu, Teng and Yi, Siyang and Lu, Wei and Li, Bin and Qian, Xuelin and Xue, Xiangyang},
  journal={arXiv preprint arXiv:2502.19958},
  year={2025}
}
@article{yu2024llms,
  title={Llms can evolve continually on modality for x-modal reasoning},
  author={Yu, Jiazuo and Xiong, Haomiao and Zhang, Lu and Diao, Haiwen and Zhuge, Yunzhi and Hong, Lanqing and Wang, Dong and Lu, Huchuan and He, You and Chen, Long},
  journal={arXiv preprint arXiv:2410.20178},
  year={2024}
}
@inproceedings{yu2024boosting,
  title={Boosting continual learning of vision-language models via mixture-of-experts adapters},
  author={Yu, Jiazuo and Zhuge, Yunzhi and Zhang, Lu and Hu, Ping and Wang, Dong and Lu, Huchuan and He, You},
  booktitle={CVPR},
  pages={23219--23230},
  year={2024}
}

@article{diao2024unveiling,
  title={Unveiling encoder-free vision-language models},
  author={Diao, Haiwen and Cui, Yufeng and Li, Xiaotong and Wang, Yueze and Lu, Huchuan and Wang, Xinlong},
  journal={arXiv preprint arXiv:2406.11832},
  year={2024}
}

@inproceedings{xia2022vision,
  title={Vision transformer with deformable attention},
  author={Xia, Zhuofan and Pan, Xuran and Song, Shiji and Li, Li Erran and Huang, Gao},
  booktitle={CVPR},
  pages={4794--4803},
  year={2022}
}
@inproceedings{wang2021pyramid,
  title={Pyramid spatial-temporal aggregation for video-based person re-identification},
  author={Wang, Yingquan and Zhang, Pingping and Gao, Shang and Geng, Xia and Lu, Hu and Wang, Dong},
  booktitle={ICCV},
  pages={12026--12035},
  year={2021}
}

@inproceedings{wang2024top,
  title={Top-reid: Multi-spectral object re-identification with token permutation},
  author={Wang, Yuhao and Liu, Xuehu and Zhang, Pingping and Lu, Hu and Tu, Zhengzheng and Lu, Huchuan},
  booktitle={AAAI},
  volume={38},
  number={6},
  pages={5758--5766},
  year={2024}
}

@inproceedings{yu2025hierarchical,
  title={Hierarchical Proxy Learning for Cloth-Changing Person Re-Identification},
  author={Yu, Chenyang and Liu, Xuehu and Dai, Ju and Zhang, Pingping and Lu, Huchuan},
  booktitle={ICASSP},
  pages={1--5},
  year={2025},
  organization={IEEE}
}

@article{wang2024mambapro,
  title={MambaPro: Multi-Modal Object Re-Identification with Mamba Aggregation and Synergistic Prompt},
  author={Wang, Yuhao and Liu, Xuehu and Yan, Tianyu and Liu, Yang and Zheng, Aihua and Zhang, Pingping and Lu, Huchuan},
  journal={arXiv preprint arXiv:2412.10707},
  year={2024}
}
@article{wang2024decoupled,
  title={Decoupled Feature-Based Mixture of Experts for Multi-Modal Object Re-Identification},
  author={Wang, Yuhao and Liu, Yang and Zheng, Aihua and Zhang, Pingping},
  journal={arXiv preprint arXiv:2412.10650},
  year={2024}
}
@article{yu2024representation,
  title={Representation Selective Coupling via Token Sparsification for Multi-Spectral Object Re-Identification},
  author={Yu, Zhi and Huang, Zhiyong and Hou, Mingyang and Pei, Jiaming and Yan, Yan and Liu, Yushi and Sun, Daming},
  journal={TCSVT},
  year={2024},
  publisher={IEEE}
}

@article{shi2024learning,
  title={Learning commonality, divergence and variety for unsupervised visible-infrared person re-identification},
  author={Shi, Jiangming and Yin, Xiangbo and Zhang, Yachao and Xie, Yuan and Qu, Yanyun and others},
  journal={NeurIPS},
  volume={37},
  pages={99715--99734},
  year={2024}
}

@article{wu2025lrmm,
  title={LRMM: Low rank multi-scale multi-modal fusion for person re-identification based on RGB-NI-TI},
  author={Wu, Di and Liu, Zhihui and Chen, Zihan and Gan, Shenglong and Tan, Kaiwen and Wan, Qin and Wang, Yaonan},
  journal={ESWA},
  volume={263},
  pages={125716},
  year={2025},
  publisher={Elsevier}
}

@inproceedings{yang2024shallow,
  title={Shallow-Deep Collaborative Learning for Unsupervised Visible-Infrared Person Re-Identification},
  author={Yang, Bin and Chen, Jun and Ye, Mang},
  booktitle={CVPR},
  pages={16870--16879},
  year={2024}
}
@article{yu2025wtsf,
  title={WTSF-ReID: Depth-driven Window-oriented Token Selection and Fusion for multi-modality vehicle re-identification with knowledge consistency constraint},
  author={Yu, Zhi and Huang, Zhiyong and Hou, Mingyang and Yan, Yan and Liu, Yushi},
  journal={ESWA},
  pages={126921},
  year={2025},
  publisher={Elsevier}
}

@article{zheng2025flare,
  title={Flare-aware cross-modal enhancement network for multi-spectral vehicle Re-identification},
  author={Zheng, Aihua and Ma, Zhiqi and Sun, Yongqi and Wang, Zi and Li, Chenglong and Tang, Jin},
  journal={Information Fusion},
  volume={116},
  pages={102800},
  year={2025},
  publisher={Elsevier}
}
@inproceedings{chowdhury2023patch,
  title={Patch-level routing in mixture-of-experts is provably sample-efficient for convolutional neural networks},
  author={Chowdhury, Mohammed Nowaz Rabbani and Zhang, Shuai and Wang, Meng and Liu, Sijia and Chen, Pin-Yu},
  booktitle={ICML},
  pages={6074--6114},
  year={2023}
}

@inproceedings{zheng2021robust,
  title={Robust multi-modality person re-identification},
  author={Zheng, Aihua and Wang, Zi and Chen, Zihan and Li, Chenglong and Tang, Jin},
  booktitle={AAAI},
  volume={35},
  pages={3529--3537},
  year={2021}
}

@inproceedings{wu2017rgb,
  title={RGB-infrared cross-modality person re-identification},
  author={Wu, Ancong and Zheng, Wei-Shi and Yu, Hong-Xing and Gong, Shaogang and Lai, Jianhuang},
  booktitle={ICCV},
  pages={5380--5389},
  year={2017}
}

@inproceedings{dai2018cross,
  title={Cross-modality person re-identification with generative adversarial training.},
  author={Dai, Pingyang and Ji, Rongrong and Wang, Haibin and Wu, Qiong and Huang, Yuyu},
  booktitle={IJCAI},
  volume={1},
  number={3},
  pages={6},
  year={2018}
}

@inproceedings{hao2019dual,
  title={Dual-alignment feature embedding for cross-modality person re-identification},
  author={Hao, Yi and Wang, Nannan and Gao, Xinbo and Li, Jie and Wang, Xiaoyu},
  booktitle={ACM MM},
  pages={57--65},
  year={2019}
}

@inproceedings{chen2019abd,
  title={Abd-net: Attentive but diverse person re-identification},
  author={Chen, Tianlong and Ding, Shaojin and Xie, Jingyi and Yuan, Ye and Chen, Wuyang and Yang, Yang and Ren, Zhou and Wang, Zhangyang},
  booktitle={ICCV},
  pages={8351--8361},
  year={2019}
}

@inproceedings{ye2018visible,
  title={Visible thermal person re-identification via dual-constrained top-ranking.},
  author={Ye, Mang and Wang, Zheng and Lan, Xiangyuan and Yuen, Pong C},
  booktitle={IJCAI},
  volume={1},
  pages={2},
  year={2018}
}


@inproceedings{selvaraju2017grad,
  title={Grad-cam: Visual explanations from deep networks via gradient-based localization},
  author={Selvaraju, Ramprasaath R and Cogswell, Michael and Das, Abhishek and Vedantam, Ramakrishna and Parikh, Devi and Batra, Dhruv},
  booktitle={ICCV},
  pages={618--626},
  year={2017}
}

@inproceedings{li2020infrared,
  title={Infrared-visible cross-modal person re-identification with an x modality},
  author={Li, Diangang and Wei, Xing and Hong, Xiaopeng and Gong, Yihong},
  booktitle={AAAI},
  volume={34},
  number={04},
  pages={4610--4617},
  year={2020}
}

@inproceedings{wang2022interact,
  title={Interact, embed, and enlarge: Boosting modality-specific representations for multi-modal person re-identification},
  author={Wang, Zi and Li, Chenglong and Zheng, Aihua and He, Ran and Tang, Jin},
  booktitle={AAAI},
  volume={36},
  pages={2633--2641},
  year={2022}
}

@inproceedings{zhang2023diverse,
  title={Diverse Embedding Expansion Network and Low-Light Cross-Modality Benchmark for Visible-Infrared Person Re-identification},
  author={Zhang, Yukang and Wang, Hanzi},
  booktitle={CVPR},
  pages={2153--2162},
  year={2023}
}

@article{liu2020parameter,
  title={Parameter sharing exploration and hetero-center triplet loss for visible-thermal person re-identification},
  author={Liu, Haijun and Tan, Xiaoheng and Zhou, Xichuan},
  journal={TMM},
  volume={23},
  pages={4414--4425},
  year={2020},
  publisher={IEEE}
}

@article{liu2021strong,
  title={Strong but simple baseline with dual-granularity triplet loss for visible-thermal person re-identification},
  author={Liu, Haijun and Chai, Yanxia and Tan, Xiaoheng and Li, Dong and Zhou, Xichuan},
  journal={SPL},
  volume={28},
  pages={653--657},
  year={2021},
  publisher={IEEE}
}

@article{zheng2023dynamic,
  title={Dynamic Enhancement Network for Partial Multi-modality Person Re-identification},
  author={Zheng, Aihua and He, Ziling and Wang, Zi and Li, Chenglong and Tang, Jin},
  journal={arXiv preprint arXiv:2305.15762},
  year={2023}
}

@inproceedings{he2021transreid,
  title={Transreid: Transformer-based object re-identification},
  author={He, Shuting and Luo, Hao and Wang, Pichao and Wang, Fan and Li, Hao and Jiang, Wei},
  booktitle={ICCV},
  pages={15013--15022},
  year={2021}
}

@inproceedings{yuan2021tokens,
  title={Tokens-to-token vit: Training vision transformers from scratch on imagenet},
  author={Yuan, Li and Chen, Yunpeng and Wang, Tao and Yu, Weihao and Shi, Yujun and Jiang, Zi-Hang and Tay, Francis EH and Feng, Jiashi and Yan, Shuicheng},
  booktitle={ICCV},
  pages={558--567},
  year={2021}
}

@inproceedings{wang2018learning,
  title={Learning discriminative features with multiple granularities for person re-identification},
  author={Wang, Guanshuo and Yuan, Yufeng and Chen, Xiong and Li, Jiwei and Zhou, Xi},
  booktitle={ACM MM},
  pages={274--282},
  year={2018}
}

@inproceedings{miao2019pose,
  title={Pose-guided feature alignment for occluded person re-identification},
  author={Miao, Jiaxu and Wu, Yu and Liu, Ping and Ding, Yuhang and Yang, Yi},
  booktitle={ICCV},
  pages={542--551},
  year={2019}
}

@inproceedings{dai2019batch,
  title={Batch dropblock network for person re-identification and beyond},
  author={Dai, Zuozhuo and Chen, Mingqiang and Gu, Xiaodong and Zhu, Siyu and Tan, Ping},
  booktitle={ICCV},
  pages={3691--3701},
  year={2019}
}


@inproceedings{zhou2019omni,
  title={Omni-scale feature learning for person re-identification},
  author={Zhou, Kaiyang and Yang, Yongxin and Cavallaro, Andrea and Xiang, Tao},
  booktitle={ICCV},
  pages={3702--3712},
  year={2019}
}


@inproceedings{wang2020high,
  title={High-order information matters: Learning relation and topology for occluded person re-identification},
  author={Wang, Guan'an and Yang, Shuo and Liu, Huanyu and Wang, Zhicheng and Yang, Yang and Wang, Shuliang and Yu, Gang and Zhou, Erjin and Sun, Jian},
  booktitle={CVPR},
  pages={6449--6458},
  year={2020}
}


@inproceedings{jin2020style,
  title={Style normalization and restitution for generalizable person re-identification},
  author={Jin, Xin and Lan, Cuiling and Zeng, Wenjun and Chen, Zhibo and Zhang, Li},
  booktitle={CVPR},
  pages={3143--3152},
  year={2020}
}


@inproceedings{zhang2020relation,
  title={Relation-aware global attention for person re-identification},
  author={Zhang, Zhizheng and Lan, Cuiling and Zeng, Wenjun and Jin, Xin and Chen, Zhibo},
  booktitle={CVPR},
  pages={3186--3195},
  year={2020}
}

@article{shi2024multi,
  title={Multi-Memory Matching for Unsupervised Visible-Infrared Person Re-Identification},
  author={Shi, Jiangming and Yin, Xiangbo and Chen, Yeyun and Zhang, Yachao and Zhang, Zhizhong and Xie, Yuan and Qu, Yanyun},
  journal={arXiv preprint arXiv:2401.06825},
  year={2024}
}
@inproceedings{zhu2020identity,
  title={Identity-guided human semantic parsing for person re-identification},
  author={Zhu, Kuan and Guo, Haiyun and Liu, Zhiwei and Tang, Ming and Wang, Jinqiao},
  booktitle={ECCV},
  pages={346--363},
  year={2020},
  organization={Springer}
}

@InProceedings{Yang_2023_ICCV,
    author    = {Yang, Bin and Chen, Jun and Ye, Mang},
    title     = {Towards Grand Unified Representation Learning for Unsupervised Visible-Infrared Person Re-Identification},
    booktitle = {ICCV},
    month     = {October},
    year      = {2023},
    pages     = {11069-11079}
}

@inproceedings{li2021combined,
  title={Combined depth space based architecture search for person re-identification},
  author={Li, Hanjun and Wu, Gaojie and Zheng, Wei-Shi},
  booktitle={CVPR},
  pages={6729--6738},
  year={2021}
}


@inproceedings{zhang2021hat,
  title={Hat: Hierarchical aggregation transformers for person re-identification},
  author={Zhang, Guowen and Zhang, Pingping and Qi, Jinqing and Lu, Huchuan},
  booktitle={ACM MM},
  pages={516--525},
  year={2021}
}

@article{zhao2021incremental,
  title={Incremental generative occlusion adversarial suppression network for person reid},
  author={Zhao, Cairong and Lv, Xinbi and Dou, Shuguang and Zhang, Shanshan and Wu, Jun and Wang, Liang},
  journal={TIP},
  volume={30},
  pages={4212--4224},
  year={2021},
  publisher={IEEE}
}


@inproceedings{wang2022pose,
  title={Pose-guided feature disentangling for occluded person re-identification based on transformer},
  author={Wang, Tao and Liu, Hong and Song, Pinhao and Guo, Tianyu and Shi, Wei},
  booktitle={AAAI},
  volume={36},
  number={3},
  pages={2540--2549},
  year={2022}
}

@inproceedings{wang2022feature,
  title={Feature erasing and diffusion network for occluded person re-identification},
  author={Wang, Zhikang and Zhu, Feng and Tang, Shixiang and Zhao, Rui and He, Lihuo and Song, Jiangning},
  booktitle={CVPR},
  pages={4754--4763},
  year={2022}
}


@inproceedings{nguyen2021graph,
  title={Graph-based person signature for person re-identifications},
  author={Nguyen, Binh X and Nguyen, Binh D and Do, Tuong and Tjiputra, Erman and Tran, Quang D and Nguyen, Anh},
  booktitle={CVPR},
  pages={3492--3501},
  year={2021}
}


@inproceedings{sun2018beyond,
  title={Beyond part models: Person retrieval with refined part pooling (and a strong convolutional baseline)},
  author={Sun, Yifan and Zheng, Liang and Yang, Yi and Tian, Qi and Wang, Shengjin},
  booktitle={ECCV},
  pages={480--496},
  year={2018}
}


@inproceedings{wei2018person,
  title={Person transfer gan to bridge domain gap for person re-identification},
  author={Wei, Longhui and Zhang, Shiliang and Gao, Wen and Tian, Qi},
  booktitle={CVPR},
  pages={79--88},
  year={2018}
}

@inproceedings{zheng2015scalable,
  title={Scalable person re-identification: A benchmark},
  author={Zheng, Liang and Shen, Liyue and Tian, Lu and Wang, Shengjin and Wang, Jingdong and Tian, Qi},
  booktitle={ICCV},
  pages={1116--1124},
  year={2015}
}

@inproceedings{zheng2017unlabeled,
  title={Unlabeled samples generated by gan improve the person re-identification baseline in vitro},
  author={Zheng, Zhedong and Zheng, Liang and Yang, Yi},
  booktitle={ICCV},
  pages={3754--3762},
  year={2017}
}

@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={CVPR},
  pages={770--778},
  year={2016}
}


@article{dosovitskiy2020image,
  title={An image is worth 16x16 words: Transformers for image recognition at scale},
  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others},
  journal={arXiv preprint arXiv:2010.11929},
  year={2020}
}

@inproceedings{selvaraju2017grad,
  title={Grad-cam: Visual explanations from deep networks via gradient-based localization},
  author={Selvaraju, Ramprasaath R and Cogswell, Michael and Das, Abhishek and Vedantam, Ramakrishna and Parikh, Devi and Batra, Dhruv},
  booktitle={ICCV},
  pages={618--626},
  year={2017}
}

@inproceedings{szegedy2016rethinking,
  title={Rethinking the inception architecture for computer vision},
  author={Szegedy, Christian and Vanhoucke, Vincent and Ioffe, Sergey and Shlens, Jon and Wojna, Zbigniew},
  booktitle={CVPR},
  pages={2818--2826},
  year={2016}
}

@article{hermans2017defense,
  title={In defense of the triplet loss for person re-identification},
  author={Hermans, Alexander and Beyer, Lucas and Leibe, Bastian},
  journal={arXiv preprint arXiv:1703.07737},
  year={2017}
}

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={NeurIPS},
  volume={30},
  year={2017}
}

@article{zhu2021aaformer,
  title={Aaformer: Auto-aligned transformer for person re-identification},
  author={Zhu, Kuan and Guo, Haiyun and Zhang, Shiliang and Wang, Yaowei and Huang, Gaopan and Qiao, Honglin and Liu, Jing and Wang, Jinqiao and Tang, Ming},
  journal={arXiv preprint arXiv:2104.00921},
  year={2021}
}


@article{li2022heterogeneous,
  title={Heterogeneous feature-aware Transformer-CNN coupling network for person re-identification},
  author={Li, Yanchao and Lian, Guoyun and Zhang, Wenyu and Ma, Guanglin and Ren, Jin and Yang, Jinfeng},
  journal={PeerJ Computer Science},
  volume={8},
  pages={e1098},
  year={2022},
  publisher={PeerJ Inc.}
}


@article{zhang2021seeing,
  title={Seeing like a human: Asynchronous learning with dynamic progressive refinement for person re-identification},
  author={Zhang, Quan and Lai, Jianhuang and Feng, Zhanxiang and Xie, Xiaohua},
  journal={TIP},
  volume={31},
  pages={352--365},
  year={2021},
  publisher={IEEE}
}



@article{bai2020deep,
  title={Deep-person: Learning discriminative deep features for person re-identification},
  author={Bai, Xiang and Yang, Mingkun and Huang, Tengteng and Dou, Zhiyong and Yu, Rui and Xu, Yongchao},
  journal={PR},
  volume={98},
  pages={107036},
  year={2020},
  publisher={Elsevier}
}


@inproceedings{yang2021learning,
  title={Learning to know where to see: A visibility-aware approach for occluded person re-identification},
  author={Yang, Jinrui and Zhang, Jiawei and Yu, Fufu and Jiang, Xinyang and Zhang, Mengdan and Sun, Xing and Chen, Ying-Cong and Zheng, Wei-Shi},
  booktitle={ICCV},
  pages={11885--11894},
  year={2021}
}

@inproceedings{luo2019bag,
  title={Bag of tricks and a strong baseline for deep person re-identification},
  author={Luo, Hao and Gu, Youzhi and Liao, Xingyu and Lai, Shenqi and Jiang, Wei},
  booktitle={CVPRW},
  pages={1487-1495},
  year={2019}
}


@inproceedings{touvron2021training,
  title={Training data-efficient image transformers \& distillation through attention},
  author={Touvron, Hugo and Cord, Matthieu and Douze, Matthijs and Massa, Francisco and Sablayrolles, Alexandre and J{\'e}gou, Herv{\'e}},
  booktitle={ICML},
  pages={10347--10357},
  year={2021},
}



@inproceedings{karpathy2014large,
  title={Large-scale video classification with convolutional neural networks},
  author={Karpathy, Andrej and Toderici, George and Shetty, Sanketh and Leung, Thomas and Sukthankar, Rahul and Fei-Fei, Li},
  booktitle={CVPR},
  pages={1725--1732},
  year={2014}
}

@inproceedings{zhong2020random,
  title={Random erasing data augmentation},
  author={Zhong, Zhun and Zheng, Liang and Kang, Guoliang and Li, Shaozi and Yang, Yi},
  booktitle={AAAI},
  volume={34},
  pages={13001--13008},
  year={2020}
}

@article{radenovic2018fine,
  title={Fine-tuning CNN image retrieval with no human annotation},
  author={Radenovi{\'c}, Filip and Tolias, Giorgos and Chum, Ond{\v{r}}ej},
  journal={TPAMI},
  volume={41},
  number={7},
  pages={1655--1668},
  year={2018},
  publisher={IEEE}
}

@inproceedings{wang2022nformer,
  title={Nformer: Robust person re-identification with neighbor transformer},
  author={Wang, Haochen and Shen, Jiayi and Liu, Yongtuo and Gao, Yan and Gavves, Efstratios},
  booktitle={CVPR},
  pages={7297--7307},
  year={2022}
}

@article{gulati2020conformer,
  title={Conformer: Convolution-augmented transformer for speech recognition},
  author={Gulati, Anmol and Qin, James and Chiu, Chung-Cheng and Parmar, Niki and Zhang, Yu and Yu, Jiahui and Han, Wei and Wang, Shibo and Zhang, Zhengdong and Wu, Yonghui and others},
  journal={arXiv preprint arXiv:2005.08100},
  year={2020}
}

@inproceedings{chen2022mobile,
  title={Mobile-former: Bridging mobilenet and transformer},
  author={Chen, Yinpeng and Dai, Xiyang and Chen, Dongdong and Liu, Mengchen and Dong, Xiaoyi and Yuan, Lu and Liu, Zicheng},
  booktitle={CVPR},
  pages={5270--5279},
  year={2022}
}

@article{dai2021coatnet,
  title={Coatnet: Marrying convolution and attention for all data sizes},
  author={Dai, Zihang and Liu, Hanxiao and Le, Quoc V and Tan, Mingxing},
  journal={NeurIPS},
  volume={34},
  pages={3965--3977},
  year={2021}
}

@inproceedings{li2018harmonious,
  title={Harmonious attention network for person re-identification},
  author={Li, Wei and Zhu, Xiatian and Gong, Shaogang},
  booktitle={CVPR},
  pages={2285--2294},
  year={2018}
}

@inproceedings{song2018mask,
  title={Mask-guided contrastive attention model for person re-identification},
  author={Song, Chunfeng and Huang, Yan and Ouyang, Wanli and Wang, Liang},
  booktitle={CVPR},
  pages={1179--1188},
  year={2018}
}

@inproceedings{li2021diverse,
  title={Diverse part discovery: Occluded person re-identification with part-aware transformer},
  author={Li, Yulin and He, Jianfeng and Zhang, Tianzhu and Liu, Xiang and Zhang, Yongdong and Wu, Feng},
  booktitle={CVPR},
  pages={2898--2907},
  year={2021}
}

@article{yao2019deep,
  title={Deep representation learning with part loss for person re-identification},
  author={Yao, Hantao and Zhang, Shiliang and Hong, Richang and Zhang, Yongdong and Xu, Changsheng and Tian, Qi},
  journal={TIP},
  volume={28},
  number={6},
  pages={2860--2871},
  year={2019},
  publisher={IEEE}
}

@article{zheng2019pose,
  title={Pose-invariant embedding for deep person re-identification},
  author={Zheng, Liang and Huang, Yujia and Lu, Huchuan and Yang, Yi},
  journal={TIP},
  volume={28},
  number={9},
  pages={4500--4509},
  year={2019},
  publisher={IEEE}
}

@inproceedings{he2019foreground,
  title={Foreground-aware pyramid reconstruction for alignment-free occluded person re-identification},
  author={He, Lingxiao and Wang, Yinggang and Liu, Wu and Zhao, He and Sun, Zhenan and Feng, Jiashi},
  booktitle={ICCV},
  pages={8450--8459},
  year={2019}
}

@inproceedings{sarfraz2018pose,
  title={A pose-sensitive embedding for person re-identification with expanded cross neighborhood re-ranking},
  author={Sarfraz, M Saquib and Schumann, Arne and Eberle, Andreas and Stiefelhagen, Rainer},
  booktitle={CVPR},
  pages={420--429},
  year={2018}
}

@inproceedings{wu2021cvt,
  title={Cvt: Introducing convolutions to vision transformers},
  author={Wu, Haiping and Xiao, Bin and Codella, Noel and Liu, Mengchen and Dai, Xiyang and Yuan, Lu and Zhang, Lei},
  booktitle={ICCV},
  pages={22--31},
  year={2021}
}

@inproceedings{li2014deepreid,
  title={Deepreid: Deep filter pairing neural network for person re-identification},
  author={Li, Wei and Zhao, Rui and Xiao, Tong and Wang, Xiaogang},
  booktitle={CVPR},
  pages={152--159},
  year={2014}
}

@inproceedings{xiao2016learning,
  title={Learning deep feature representations with domain guided dropout for person re-identification},
  author={Xiao, Tong and Li, Hongsheng and Ouyang, Wanli and Wang, Xiaogang},
  booktitle={CVPR},
  pages={1249--1258},
  year={2016}
}

@article{wang2020receptive,
  title={Receptive multi-granularity representation for person re-identification},
  author={Wang, Guanshuo and Yuan, Yufeng and Li, Jiwei and Ge, Shiming and Zhou, Xi},
  journal={TIP},
  volume={29},
  pages={6096--6109},
  year={2020},
  publisher={IEEE}
}

@inproceedings{su2017pose,
  title={Pose-driven deep convolutional model for person re-identification},
  author={Su, Chi and Li, Jianing and Zhang, Shiliang and Xing, Junliang and Gao, Wen and Tian, Qi},
  booktitle={ICCV},
  pages={3960--3969},
  year={2017}
}


@inproceedings{zhao2017spindle,
  title={Spindle net: Person re-identification with human body region guided feature decomposition and fusion},
  author={Zhao, Haiyu and Tian, Maoqing and Sun, Shuyang and Shao, Jing and Yan, Junjie and Yi, Shuai and Wang, Xiaogang and Tang, Xiaoou},
  booktitle={CVPR},
  pages={1077--1085},
  year={2017}
}


@article{huang2018eanet,
  title={Eanet: Enhancing alignment for cross-domain person re-identification},
  author={Huang, Houjing and Yang, Wenjie and Chen, Xiaotang and Zhao, Xin and Huang, Kaiqi and Lin, Jinbin and Huang, Guan and Du, Dalong},
  journal={arXiv preprint arXiv:1812.11369},
  year={2018}
}

@inproceedings{suh2018part,
  title={Part-aligned bilinear representations for person re-identification},
  author={Suh, Yumin and Wang, Jingdong and Tang, Siyu and Mei, Tao and Lee, Kyoung Mu},
  booktitle={ECCV},
  pages={402--419},
  year={2018}
}

@inproceedings{zhang2019densely,
  title={Densely semantically aligned person re-identification},
  author={Zhang, Zhizheng and Lan, Cuiling and Zeng, Wenjun and Chen, Zhibo},
  booktitle={CVPR},
  pages={667--676},
  year={2019}
}

@inproceedings{yi2014deep,
  title={Deep metric learning for person re-identification},
  author={Yi, Dong and Lei, Zhen and Liao, Shengcai and Li, Stan Z},
  booktitle={ICPR},
  pages={34--39},
  year={2014},
  organization={IEEE}
}

@inproceedings{he2015delving,
  title={Delving deep into rectifiers: Surpassing human-level performance on imagenet classification},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={ICCV},
  pages={1026--1034},
  year={2015}
}

@article{ba2016layer,
  title={Layer normalization},
  author={Ba, Jimmy Lei and Kiros, Jamie Ryan and Hinton, Geoffrey E},
  journal={arXiv preprint arXiv:1607.06450},

  year={2016}
}

@inproceedings{ioffe2015batch,
  title={Batch normalization: Accelerating deep network training by reducing internal covariate shift},
  author={Ioffe, Sergey and Szegedy, Christian},
  booktitle={ICML},
  pages={448--456},
  year={2015},
  organization={pmlr}
}

@article{hendrycks2016gaussian,
  title={Gaussian error linear units (gelus)},
  author={Hendrycks, Dan and Gimpel, Kevin},
  journal={arXiv preprint arXiv:1606.08415},
  year={2016}
}

@article{wang2021mutualformer,
  title={MutualFormer: Multi-modality representation learning via mutual transformer},
  author={Wang, Xixi and Jiang, Bo and Wang, Xiao and Luo, Bin},
  journal={arXiv e-prints},
  pages={arXiv--2112},
  year={2021}
}

@inproceedings{li2020multi,
  title={Multi-spectral vehicle re-identification: A challenge},
  author={Li, Hongchao and Li, Chenglong and Zhu, Xianpeng and Zheng, Aihua and Luo, Bin},
  booktitle={AAAI},
  volume={34},
  pages={11345--11353},
  year={2020}
}


@article{zheng2023cross,
  title={Cross-directional consistency network with adaptive layer normalization for multi-spectral vehicle re-identification and a high-quality benchmark},
  author={Zheng, Aihua and Zhu, Xianpeng and Ma, Zhiqi and Li, Chenglong and Tang, Jin and Ma, Jixin},
  journal={Information Fusion},
  volume={100},
  pages={101901},
  year={2023},
  publisher={Elsevier}
}

@inproceedings{chen2019deep,
  title={Deep meta metric learning},
  author={Chen, Guangyi and Zhang, Tianren and Lu, Jiwen and Zhou, Jie},
  booktitle={ICCV},
  pages={9547--9556},
  year={2019}
}

@inproceedings{zhao2021heterogeneous,
  title={Heterogeneous relational complement for vehicle re-identification},
  author={Zhao, Jiajian and Zhao, Yifan and Li, Jia and Yan, Ke and Tian, Yonghong},
  booktitle={ICCV},
  pages={205--214},
  year={2021}
}

@inproceedings{sun2020circle,
  title={Circle loss: A unified perspective of pair similarity optimization},
  author={Sun, Yifan and Cheng, Changmao and Zhang, Yuhan and Zhang, Chi and Zheng, Liang and Wang, Zhongdao and Wei, Yichen},
  booktitle={CVPR},
  pages={6398--6407},
  year={2020}
}

@article{zhang2018generalized,
  title={Generalized cross entropy loss for training deep neural networks with noisy labels},
  author={Zhang, Zhilu and Sabuncu, Mert},
  journal={NeurIPS},
  volume={31},
  year={2018}
}

@article{ye2021deep,
  title={Deep learning for person re-identification: A survey and outlook},
  author={Ye, Mang and Shen, Jianbing and Lin, Gaojie and Xiang, Tao and Shao, Ling and Hoi, Steven CH},
  journal={TPAMI},
  volume={44},
  number={6},
  pages={2872--2893},
  year={2021},
  publisher={IEEE}
}

@inproceedings{barbosa2012re,
  title={Re-identification with rgb-d sensors},
  author={Barbosa, Igor Barros and Cristani, Marco and Del Bue, Alessio and Bazzani, Loris and Murino, Vittorio},
  booktitle={ECCV},
  pages={433--442},
  year={2012},
  organization={Springer}
}

@inproceedings{guo2022generative,
  title={Generative and attentive fusion for multi-spectral vehicle re-identification},
  author={Guo, Jinbo and Zhang, Xiaojing and Liu, Zhengyi and Wang, Yuan},
  booktitle={ICSP},
  pages={1565--1572},
  year={2022},
}

@article{pan2023progressively,
  title={Progressively Hybrid Transformer for Multi-Modal Vehicle Re-Identification},
  author={Pan, Wenjie and Huang, Linhan and Liang, Jianbao and Hong, Lan and Zhu, Jianqing},
  journal={Sensors},
  volume={23},
  number={9},
  pages={4206},
  year={2023},
  publisher={MDPI}
}

@inproceedings{qian2017multi,
  title={Multi-scale deep learning architectures for person re-identification},
  author={Qian, Xuelin and Fu, Yanwei and Jiang, Yu-Gang and Xiang, Tao and Xue, Xiangyang},
  booktitle={ICCV},
  pages={5399--5408},
  year={2017}
}

@inproceedings{chang2018multi,
  title={Multi-level factorisation net for person re-identification},
  author={Chang, Xiaobin and Hospedales, Timothy M and Xiang, Tao},
  booktitle={CVPR},
  pages={2109--2118},
  year={2018}
}

@inproceedings{rao2021counterfactual,
  title={Counterfactual attention learning for fine-grained visual categorization and re-identification},
  author={Rao, Yongming and Chen, Guangyi and Lu, Jiwen and Zhou, Jie},
  booktitle={ICCV},
  pages={1025--1034},
  year={2021}
}

@article{chen2022rest,
  title={ResT-ReID: Transformer block-based residual learning for person re-identification},
  author={Chen, Ying and Xia, Shixiong and Zhao, Jiaqi and Zhou, Yong and Niu, Qiang and Yao, Rui and Zhu, Dongjun and Liu, Dongjingdian},
  journal={PRL},
  volume={157},
  pages={90--96},
  year={2022},
  publisher={Elsevier}
}

@inproceedings{deng2009imagenet,
  title={Imagenet: A large-scale hierarchical image database},
  author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
  booktitle={CVPR},
  pages={248--255},
  year={2009},
}

@inproceedings{pan2022h,
  title={H-vit: Hybrid vision transformer for multi-modal vehicle re-identification},
  author={Pan, Wenjie and Wu, Hanxiao and Zhu, Jianqing and Zeng, Huanqiang and Zhu, Xiaobin},
  booktitle={CICAI},
  pages={255--267},
  year={2022},
  organization={Springer}
}
@article{he2023graph,
  title={Graph-Based Progressive Fusion Network for Multi-Modality Vehicle Re-Identification},
  author={He, Qiaolin and Lu, Zefeng and Wang, Zihan and Hu, Haifeng},
  journal={TITS},
  year={2023},
  publisher={IEEE},
  pages={1-17}
}
@inproceedings{zhu2017unpaired,
  title={Unpaired image-to-image translation using cycle-consistent adversarial networks},
  author={Zhu, Jun-Yan and Park, Taesung and Isola, Phillip and Efros, Alexei A},
  booktitle={ICCV},
  pages={2223--2232},
  year={2017}
}
@article{van2008visualizing,
  title={Visualizing data using t-SNE.},
  author={Van der Maaten, Laurens and Hinton, Geoffrey},
  journal={JMLR},
  volume={9},
  number={11},
  year={2008}
}



@article{qian2019leader,
  title={Leader-based multi-scale attention deep architecture for person re-identification},
  author={Qian, Xuelin and Fu, Yanwei and Xiang, Tao and Jiang, Yu-Gang and Xue, Xiangyang},
  journal={TPAMI},
  volume={42},
  number={2},
  pages={371--385},
  year={2019},
}

@inproceedings{tian2018eliminating,
  title={Eliminating background-bias for robust person re-identification},
  author={Tian, Maoqing and Yi, Shuai and Li, Hongsheng and Li, Shihua and Zhang, Xuesen and Shi, Jianping and Yan, Junjie and Wang, Xiaogang},
  booktitle={CVPR},
  pages={5794--5803},
  year={2018}
}

@inproceedings{he2022transfg,
  title={Transfg: A transformer architecture for fine-grained recognition},
  author={He, Ju and Chen, Jie-Neng and Liu, Shuai and Kortylewski, Adam and Yang, Cheng and Bai, Yutong and Wang, Changhu},
  booktitle={AAAI},
  volume={36},
  number={1},
  pages={852--860},
  year={2022}
}
@article{yin2023graft,
  title={GraFT: Gradual Fusion Transformer for Multimodal Re-Identification},
  author={Yin, Haoli and Li, Jiayao and Schiller, Eva and McDermott, Luke and Cummings, Daniel},
  journal={arXiv preprint arXiv:2310.16856},
  year={2023}
}


@inproceedings{kamenou2022closing,
  title={Closing the domain gap for cross-modal visible-infrared vehicle re-identification},
  author={Kamenou, Eleni and del Rincon, Jesus Martinez and Miller, Paul and Devlin-Hill, Patricia},
  booktitle={ICPR},
  pages={2728--2734},
  year={2022},
  organization={IEEE}
}


@inproceedings{zhang2023pha,
  title={PHA: Patch-Wise High-Frequency Augmentation for Transformer-Based Person Re-Identification},
  author={Zhang, Guiwei and Zhang, Yongfei and Zhang, Tianyu and Li, Bo and Pu, Shiliang},
  booktitle={CVPR},
  pages={14133--14142},
  year={2023}
}

@inproceedings{zhu2022dual,
  title={Dual cross-attention learning for fine-grained visual categorization and object re-identification},
  author={Zhu, Haowei and Ke, Wenjing and Li, Dong and Liu, Ji and Tian, Lu and Shan, Yi},
  booktitle={CVPR},
  pages={4692--4702},
  year={2022}
}

@inproceedings{zhu2022pass,
  title={Pass: Part-aware self-supervised pre-training for person re-identification},
  author={Zhu, Kuan and Guo, Haiyun and Yan, Tianyi and Zhu, Yousong and Wang, Jinqiao and Tang, Ming},
  booktitle={ECCV},
  pages={198--214},
  year={2022},
  organization={Springer}
}

@article{mallat1989theory,
  title={A theory for multiresolution signal decomposition: the wavelet representation},
  author={Mallat, Stephane G},
  journal={TPAMI},
  volume={11},
  number={7},
  pages={674--693},
  year={1989},
  publisher={Ieee}
}

@inproceedings{huang2019sbsgan,
  title={SBSGAN: Suppression of inter-domain background shift for person re-identification},
  author={Huang, Yan and Wu, Qiang and Xu, JingSong and Zhong, Yi},
  booktitle={CVPR},
  pages={9527--9536},
  year={2019}
}
@article{han2022survey,
  title={A survey on vision transformer},
  author={Han, Kai and Wang, Yunhe and Chen, Hanting and Chen, Xinghao and Guo, Jianyuan and Liu, Zhenhua and Tang, Yehui and Xiao, An and Xu, Chunjing and Xu, Yixing and others},
  journal={TPAMI},
  volume={45},
  number={1},
  pages={87--110},
  year={2022},
  publisher={IEEE}
}

@inproceedings{bolya2022token,
  title={Token Merging: Your ViT But Faster},
  author={Bolya, Daniel and Fu, Cheng-Yang and Dai, Xiaoliang and Zhang, Peizhao and Feichtenhofer, Christoph and Hoffman, Judy},
  booktitle={ICLR},
  year={2022}
}

@article{rao2021dynamicvit,
  title={Dynamicvit: Efficient vision transformers with dynamic token sparsification},
  author={Rao, Yongming and Zhao, Wenliang and Liu, Benlin and Lu, Jiwen and Zhou, Jie and Hsieh, Cho-Jui},
  journal={NeurIPS},
  volume={34},
  pages={13937--13949},
  year={2021}
}

@inproceedings{yang2023top,
  title={Top-K Visual Tokens Transformer: Selecting Tokens for Visible-Infrared Person Re-Identification},
  author={Yang, Bin and Chen, Jun and Ye, Mang},
  booktitle={ICASSP},
  pages={1--5},
  year={2023},
  organization={IEEE}
}

@inproceedings{fayyaz2022adaptive,
  title={Adaptive token sampling for efficient vision transformers},
  author={Fayyaz, Mohsen and Koohpayegani, Soroush Abbasi and Jafari, Farnoush Rezaei and Sengupta, Sunando and Joze, Hamid Reza Vaezi and Sommerlade, Eric and Pirsiavash, Hamed and Gall, J{\"u}rgen},
  booktitle={ECCV},
  pages={396--414},
  year={2022},
  organization={Springer}
}

@article{serrano2019attention,
  title={Is attention interpretable?},
  author={Serrano, Sofia and Smith, Noah A},
  journal={arXiv preprint arXiv:1906.03731},
  year={2019}
}

@article{abnar2020quantifying,
  title={Quantifying attention flow in transformers},
  author={Abnar, Samira and Zuidema, Willem},
  journal={arXiv preprint arXiv:2005.00928},
  year={2020}
}

@inproceedings{liu2022ts2,
  title={Ts2-net: Token shift and selection transformer for text-video retrieval},
  author={Liu, Yuqi and Xiong, Pengfei and Xu, Luhui and Cao, Shengming and Jin, Qin},
  booktitle={ECCV},
  pages={319--335},
  year={2022},
  organization={Springer}
}

@inproceedings{haurum2023tokens,
  title={Which tokens to use? investigating token reduction in vision transformers},
  author={Haurum, Joakim Bruslund and Escalera, Sergio and Taylor, Graham W and Moeslund, Thomas B},
  booktitle={CVPR},
  pages={773--783},
  year={2023}
}

@article{marin2021token,
  title={Token pooling in vision transformers},
  author={Marin, Dmitrii and Chang, Jen-Hao Rick and Ranjan, Anurag and Prabhu, Anish and Rastegari, Mohammad and Tuzel, Oncel},
  journal={arXiv preprint arXiv:2110.03860},
  year={2021}
}

@article{crawford2023unicat,
  title={UniCat: Crafting a Stronger Fusion Baseline for Multimodal Re-Identification},
  author={Crawford, Jennifer and Yin, Haoli and McDermott, Luke and Cummings, Daniel},
  journal={arXiv preprint arXiv:2310.18812},
  year={2023}
}

@inproceedings{liu2021swin,
  title={Swin transformer: Hierarchical vision transformer using shifted windows},
  author={Liu, Ze and Lin, Yutong and Cao, Yue and Hu, Han and Wei, Yixuan and Zhang, Zheng and Lin, Stephen and Guo, Baining},
  booktitle={CVPR},
  pages={10012--10022},
  year={2021}
}

@article{kirillov2023segment,
  title={Segment anything},
  author={Kirillov, Alexander and Mintun, Eric and Ravi, Nikhila and Mao, Hanzi and Rolland, Chloe and Gustafson, Laura and Xiao, Tete and Whitehead, Spencer and Berg, Alexander C and Lo, Wan-Yen and others},
  journal={CVPR},
  year={2023}
}

@inproceedings{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={ICML},
  pages={8748--8763},
  year={2021},
  organization={PMLR}
}


  @article{gong2021eliminate,
  title={Eliminate deviation with deviation for data augmentation and a general multi-modal data learning method},
  author={Gong, Yunpeng and Huang, Liqing and Chen, Lifei},
  journal={arXiv preprint arXiv:2101.08533},
  year={2021}
}

@article{6357194,
  author={Kviatkovsky, Igor and Adam},
  journal={TPAMI},
  title={Color Invariants for Person Reidentification},
  year={2013},
  volume={35},
  number={7},
  pages={1622-1634},
  keywords={Image color analysis;Lighting;Shape;Color;Context;Cameras;Surveillance applications;person reidentification;color invariant signatures},
  doi={10.1109/TPAMI.2012.246}}


@article{ye2024transformer,
  title={Transformer for Object Re-Identification: A Survey},
  author={Ye, Mang and Chen, Shuoyi and Li, Chenyue and Zheng, Wei-Shi and Crandall, David and Du, Bo},
  journal={arXiv preprint arXiv:2401.06960},
  year={2024}
}

@article{amiri2024comprehensive,
  title={A Comprehensive Survey on Deep-Learning-based Vehicle Re-Identification: Models, Data Sets and Challenges},
  author={Amiri, Ali and Kaya, Aydin and Keceli, Ali Seydi},
  journal={arXiv preprint arXiv:2401.10643},
  year={2024}
}

@article{liang2022mind,
  title={Mind the gap: Understanding the modality gap in multi-modal contrastive representation learning},
  author={Liang, Victor Weixin and Zhang, Yuhui and Kwon, Yongchan and Yeung, Serena and Zou, James Y},
  journal={NeurIPS},
  volume={35},
  pages={17612--17625},
  year={2022}
}


@article{zhang2023generalization,
  title={On the Generalization of Multi-modal Contrastive Learning},
  author={Zhang, Qi and Wang, Yifei and Wang, Yisen},
  journal={arXiv preprint arXiv:2306.04272},
  year={2023}
}

@article{huang2021makes,
  title={What makes multi-modal learning better than single (provably)},
  author={Huang, Yu and Du, Chenzhuang and Xue, Zihui and Chen, Xuanyao and Zhao, Hang and Huang, Longbo},
  journal={NeurIPS},
  volume={34},
  pages={10944--10956},
  year={2021}
}


@InProceedings{Kirillov_2023_ICCV,
    author    = {Kirillov, Alexander and Mintun, Eric and Ravi, Nikhila and Mao, Hanzi and Rolland, Chloe and Gustafson, Laura and Xiao, Tete and Whitehead, Spencer and Berg, Alexander C. and Lo, Wan-Yen and Dollar, Piotr and Girshick, Ross},
    title     = {Segment Anything},
    booktitle = {ICCV},
    month     = {October},
    year      = {2023},
    pages     = {4015-4026}
}

@article{yang2024depth,
  title={Depth anything: Unleashing the power of large-scale unlabeled data},
  author={Yang, Lihe and Kang, Bingyi and Huang, Zilong and Xu, Xiaogang and Feng, Jiashi and Zhao, Hengshuang},
  journal={arXiv preprint arXiv:2401.10891},
  year={2024}
}

@inproceedings{ci2023unihcp,
  title={UniHCP: A Unified Model for Human-Centric Perceptions},
  author={Ci, Yuanzheng and Wang, Yizhou and Chen, Meilin and Tang, Shixiang and Bai, Lei and Zhu, Feng and Zhao, Rui and Yu, Fengwei and Qi, Donglian and Ouyang, Wanli},
  booktitle={CVPR},
  pages={17840--17852},
  year={2023}
}

@inproceedings{yan2023universal,
  title={Universal instance perception as object discovery and retrieval},
  author={Yan, Bin and Jiang, Yi and Wu, Jiannan and Wang, Dong and Luo, Ping and Yuan, Zehuan and Lu, Huchuan},
  booktitle={CVPR},
  pages={15325--15336},
  year={2023}
}

@article{chen2022unified,
  title={A unified sequence interface for vision tasks},
  author={Chen, Ting and Saxena, Saurabh and Li, Lala and Lin, Tsung-Yi and Fleet, David J and Hinton, Geoffrey E},
  journal={NeurIPS},
  volume={35},
  pages={31333--31346},
  year={2022}
}

@article{awais2023foundational,
  title={Foundational models defining a new era in vision: A survey and outlook},
  author={Awais, Muhammad and Naseer, Muzammal and Khan, Salman and Anwer, Rao Muhammad and Cholakkal, Hisham and Shah, Mubarak and Yang, Ming-Hsuan and Khan, Fahad Shahbaz},
  journal={arXiv preprint arXiv:2307.13721},
  year={2023}
}

@article{azad2023foundational,
  title={Foundational models in medical imaging: A comprehensive survey and future vision},
  author={Azad, Bobby and Azad, Reza and Eskandari, Sania and Bozorgpour, Afshin and Kazerouni, Amirhossein and Rekik, Islem and Merhof, Dorit},
  journal={arXiv preprint arXiv:2310.18689},
  year={2023}
}

@article{bommasani2021opportunities,
  title={On the opportunities and risks of foundation models},
  author={Bommasani, Rishi and Hudson, Drew A and Adeli, Ehsan and Altman, Russ and Arora, Simran and von Arx, Sydney and Bernstein, Michael S and Bohg, Jeannette and Bosselut, Antoine and Brunskill, Emma and others},
  journal={arXiv preprint arXiv:2108.07258},
  year={2021}
}

@article{ding2023parameter,
  title={Parameter-efficient fine-tuning of large-scale pre-trained language models},
  author={Ding, Ning and Qin, Yujia and Yang, Guang and Wei, Fuchao and Yang, Zonghan and Su, Yusheng and Hu, Shengding and Chen, Yulin and Chan, Chi-Min and Chen, Weize and others},
  journal={NMI},
  volume={5},
  number={3},
  pages={220--235},
  year={2023},
  publisher={Nature Publishing Group UK London}
}

@inproceedings{fu2023effectiveness,
  title={On the effectiveness of parameter-efficient fine-tuning},
  author={Fu, Zihao and Yang, Haoran and So, Anthony Man-Cho and Lam, Wai and Bing, Lidong and Collier, Nigel},
  booktitle={AAAI},
  volume={37},
  number={11},
  pages={12799--12807},
  year={2023}
}

@article{lu2023uniadapter,
  title={Uniadapter: Unified parameter-efficient transfer learning for cross-modal modeling},
  author={Lu, Haoyu and Huo, Yuqi and Yang, Guoxing and Lu, Zhiwu and Zhan, Wei and Tomizuka, Masayoshi and Ding, Mingyu},
  journal={arXiv preprint arXiv:2302.06605},
  year={2023}
}
@article{diao2023unipt,
  title={UniPT: Universal Parallel Tuning for Transfer Learning with Efficient Parameter and Memory},
  author={Diao, Haiwen and Wan, Bo and Zhang, Ying and Jia, Xu and Lu, Huchuan and Chen, Long},
  journal={arXiv preprint arXiv:2308.14316},
  year={2023}
}
@article{donoho2005stable,
  title={Stable recovery of sparse overcomplete representations in the presence of noise},
  author={Donoho, David L and Elad, Michael and Temlyakov, Vladimir N},
  journal={IEEE Transactions on information theory},
  volume={52},
  number={1},
  pages={6--18},
  year={2005},
  publisher={IEEE}
}
@article{lewicki2000learning,
  title={Learning overcomplete representations},
  author={Lewicki, Michael S and Sejnowski, Terrence J},
  journal={Neural computation},
  volume={12},
  number={2},
  pages={337--365},
  year={2000},
  publisher={MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info~…}
}


@article{french1999catastrophic,
  title={Catastrophic forgetting in connectionist networks},
  author={French, Robert M},
  journal={Trends in cognitive sciences},
  volume={3},
  number={4},
  pages={128--135},
  year={1999},
  publisher={Elsevier}
}
@inproceedings{li2023clipreid,
  title={CLIP-ReID: exploiting vision-language model for image re-identification without concrete text labels},
  author={Li, Siyuan and Sun, Li and Li, Qingli},
  booktitle={AAAI},
  volume={37},
  number={1},
  pages={1405--1413},
  year={2023}
}

@article{gao2024clip,
  title={Clip-adapter: Better vision-language models with feature adapters},
  author={Gao, Peng and Geng, Shijie and Zhang, Renrui and Ma, Teli and Fang, Rongyao and Zhang, Yongfeng and Li, Hongsheng and Qiao, Yu},
  journal={IJCV},
  volume={132},
  number={2},
  pages={581--595},
  year={2024},
  publisher={Springer}
}


@article{hu2021lora,
  title={Lora: Low-rank adaptation of large language models},
  author={Hu, Edward J and Shen, Yelong and Wallis, Phillip and Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang, Lu and Chen, Weizhu},
  journal={arXiv preprint arXiv:2106.09685},
  year={2021}
}

@article{liu2024dora,
  title={DoRA: Weight-Decomposed Low-Rank Adaptation},
  author={Liu, Shih-Yang and Wang, Chien-Yi and Yin, Hongxu and Molchanov, Pavlo and Wang, Yu-Chiang Frank and Cheng, Kwang-Ting and Chen, Min-Hung},
  journal={arXiv preprint arXiv:2402.09353},
  year={2024}
}

@article{karimi2021compacter,
  title={Compacter: Efficient low-rank hypercomplex adapter layers},
  author={Karimi Mahabadi, Rabeeh and Henderson, James and Ruder, Sebastian},
  journal={NeurIPS},
  volume={34},
  pages={1022--1035},
  year={2021}
}

@article{yang2023aim,
  title={Aim: Adapting image models for efficient video action recognition},
  author={Yang, Taojiannan and Zhu, Yi and Xie, Yusheng and Zhang, Aston and Chen, Chen and Li, Mu},
  journal={arXiv preprint arXiv:2302.03024},
  year={2023}
}

@inproceedings{sung2022vl,
  title={Vl-adapter: Parameter-efficient transfer learning for vision-and-language tasks},
  author={Sung, Yi-Lin and Cho, Jaemin and Bansal, Mohit},
  booktitle={CVPR},
  pages={5227--5237},
  year={2022}
}

@inproceedings{houlsby2019parameter,
  title={Parameter-efficient transfer learning for NLP},
  author={Houlsby, Neil and Giurgiu, Andrei and Jastrzebski, Stanislaw and Morrone, Bruna and De Laroussilhe, Quentin and Gesmundo, Andrea and Attariyan, Mona and Gelly, Sylvain},
  booktitle={ICML},
  pages={2790--2799},
  year={2019},
  organization={PMLR}
}

@article{zhao2022tiny,
  title={Tiny-attention adapter: Contexts are more important than the number of parameters},
  author={Zhao, Hongyu and Tan, Hao and Mei, Hongyuan},
  journal={arXiv preprint arXiv:2211.01979},
  year={2022}
}

@misc{zhang2024regionprompted,
      title={A Region-Prompted Adapter Tuning for Visual Abductive Reasoning},
      author={Hao Zhang and Yeo Keat Ee and Basura Fernando},
      year={2024},
      eprint={2303.10428},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@article{gu2021ppt,
  title={Ppt: Pre-trained prompt tuning for few-shot learning},
  author={Gu, Yuxian and Han, Xu and Liu, Zhiyuan and Huang, Minlie},
  journal={arXiv preprint arXiv:2109.04332},
  year={2021}
}

@inproceedings{jia2022visual,
  title={Visual prompt tuning},
  author={Jia, Menglin and Tang, Luming and Chen, Bor-Chun and Cardie, Claire and Belongie, Serge and Hariharan, Bharath and Lim, Ser-Nam},
  booktitle={ECCV},
  pages={709--727},
  year={2022},
  organization={Springer}
}

@article{li2021prefix,
  title={Prefix-tuning: Optimizing continuous prompts for generation},
  author={Li, Xiang Lisa and Liang, Percy},
  journal={arXiv preprint arXiv:2101.00190},
  year={2021}
}

@article{zhou2022learning,
  title={Learning to prompt for vision-language models},
  author={Zhou, Kaiyang and Yang, Jingkang and Loy, Chen Change and Liu, Ziwei},
  journal={IJCV},
  volume={130},
  number={9},
  pages={2337--2348},
  year={2022},
  publisher={Springer}
}

@article{lester2021power,
  title={The power of scale for parameter-efficient prompt tuning},
  author={Lester, Brian and Al-Rfou, Rami and Constant, Noah},
  journal={arXiv preprint arXiv:2104.08691},
  year={2021}
}

@inproceedings{liu2022p,
  title={P-tuning: Prompt tuning can be comparable to fine-tuning across scales and tasks},
  author={Liu, Xiao and Ji, Kaixuan and Fu, Yicheng and Tam, Weng and Du, Zhengxiao and Yang, Zhilin and Tang, Jie},
  booktitle={ACL},
  pages={61--68},
  year={2022}
}

@article{gu2023mamba,
  title={Mamba: Linear-time sequence modeling with selective state spaces},
  author={Gu, Albert and Dao, Tri},
  journal={arXiv preprint arXiv:2312.00752},
  year={2023}
}

@article{gu2021efficiently,
  title={Efficiently modeling long sequences with structured state spaces},
  author={Gu, Albert and Goel, Karan and R{\'e}, Christopher},
  journal={arXiv preprint arXiv:2111.00396},
  year={2021}
}

@inproceedings{islam2022long,
  title={Long movie clip classification with state-space video models},
  author={Islam, Md Mohaiminul and Bertasius, Gedas},
  booktitle={ECCV},
  pages={87--104},
  year={2022},
  organization={Springer}
}

@article{nguyen2022s4nd,
  title={S4nd: Modeling images and videos as multidimensional signals with state spaces},
  author={Nguyen, Eric and Goel, Karan and Gu, Albert and Downs, Gordon and Shah, Preey and Dao, Tri and Baccus, Stephen and R{\'e}, Christopher},
  journal={NeurIPS},
  volume={35},
  pages={2846--2861},
  year={2022}
}

@inproceedings{islam2023efficient,
  title={Efficient Movie Scene Detection using State-Space Transformers},
  author={Islam, Md Mohaiminul and Hasan, Mahmudul and Athrey, Kishan Shamsundar and Braskich, Tony and Bertasius, Gedas},
  booktitle={CVPR},
  pages={18749--18758},
  year={2023}
}

@article{zhu2024vision,
  title={Vision mamba: Efficient visual representation learning with bidirectional state space model},
  author={Zhu, Lianghui and Liao, Bencheng and Zhang, Qian and Wang, Xinlong and Liu, Wenyu and Wang, Xinggang},
  journal={arXiv preprint arXiv:2401.09417},
  year={2024}
}

@article{liu2024vmamba,
  title={Vmamba: Visual state space model},
  author={Liu, Yue and Tian, Yunjie and Zhao, Yuzhong and Yu, Hongtian and Xie, Lingxi and Wang, Yaowei and Ye, Qixiang and Liu, Yunfan},
  journal={arXiv preprint arXiv:2401.10166},
  year={2024}
}

@article{ma2024u,
  title={U-mamba: Enhancing long-range dependency for biomedical image segmentation},
  author={Ma, Jun and Li, Feifei and Wang, Bo},
  journal={arXiv preprint arXiv:2401.04722},
  year={2024}
}

@article{ruan2024vm,
  title={Vm-unet: Vision mamba unet for medical image segmentation},
  author={Ruan, Jiacheng and Xiang, Suncheng},
  journal={arXiv preprint arXiv:2402.02491},
  year={2024}
}

@article{xing2024segmamba,
  title={Segmamba: Long-range sequential modeling mamba for 3d medical image segmentation},
  author={Xing, Zhaohu and Ye, Tian and Yang, Yijun and Liu, Guang and Zhu, Lei},
  journal={arXiv preprint arXiv:2401.13560},
  year={2024}
}

@misc{liang2024pointmamba,
      title={PointMamba: A Simple State Space Model for Point Cloud Analysis},
      author={Dingkang Liang and Xin Zhou and Xinyu Wang and Xingkui Zhu and Wei Xu and Zhikang Zou and Xiaoqing Ye and Xiang Bai},
      year={2024},
      eprint={2402.10739},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@article{wang2024mambabyte,
  title={MambaByte: Token-free Selective State Space Model},
  author={Wang, Junxiong and Gangavarapu, Tushaar and Yan, Jing Nathan and Rush, Alexander M},
  journal={arXiv preprint arXiv:2401.13660},
  year={2024}
}

@article{pioro2024moe,
  title={Moe-mamba: Efficient selective state space models with mixture of experts},
  author={Pi{\'o}ro, Maciej and Ciebiera, Kamil and Kr{\'o}l, Krystian and Ludziejewski, Jan and Jaszczur, Sebastian},
  journal={arXiv preprint arXiv:2401.04081},
  year={2024}
}

@misc{behrouz2024graph,
      title={Graph Mamba: Towards Learning on Graphs with State Space Models},
      author={Ali Behrouz and Farnoosh Hashemi},
      year={2024},
      eprint={2402.08678},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{wang2024weakmambaunet,
      title={Weak-Mamba-UNet: Visual Mamba Makes CNN and ViT Work Better for Scribble-based Medical Image Segmentation},
      author={Ziyang Wang and Chao Ma},
      year={2024},
      eprint={2402.10887},
      archivePrefix={arXiv},
      primaryClass={eess.IV}
}

@misc{guo2024mambair,
      title={MambaIR: A Simple Baseline for Image Restoration with State-Space Model},
      author={Hang Guo and Jinmin Li and Tao Dai and Zhihao Ouyang and Xudong Ren and Shu-Tao Xia},
      year={2024},
      eprint={2402.15648},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{chen2024resvmamba,
      title={Res-VMamba: Fine-Grained Food Category Visual Classification Using Selective State Space Models with Deep Residual Learning},
      author={Chi-Sheng Chen and Guan-Ying Chen and Dong Zhou and Di Jiang and Dai-Shi Chen},
      year={2024},
      eprint={2402.15761},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{park2024mamba,
      title={Can Mamba Learn How to Learn? A Comparative Study on In-Context Learning Tasks},
      author={Jongho Park and Jaeseung Park and Zheyang Xiong and Nayoung Lee and Jaewoong Cho and Samet Oymak and Kangwook Lee and Dimitris Papailiopoulos},
      year={2024},
      eprint={2402.04248},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{li2023clip,
  title={CLIP-based Synergistic Knowledge Transfer for Text-based Person Retrieval},
  author={Li, Yaowei and Liu, Zimo and Yang, Wenming and Wang, Yaowei and Liao, Qingmin and others},
  journal={arXiv preprint arXiv:2309.09496},
  year={2023}
}

@article{cao2023bi,
  title={Bi-directional Adapter for Multi-modal Tracking},
  author={Cao, Bing and Guo, Junliang and Zhu, Pengfei and Hu, Qinghua},
  journal={arXiv preprint arXiv:2312.10611},
  year={2023}
}

@inproceedings{khattak2023maple,
  title={Maple: Multi-modal prompt learning},
  author={Khattak, Muhammad Uzair and Rasheed, Hanoona and Maaz, Muhammad and Khan, Salman and Khan, Fahad Shahbaz},
  booktitle={CVPR},
  pages={19113--19122},
  year={2023}
}

@article{nwankpa2018activation,
  title={Activation functions: Comparison of trends in practice and research for deep learning},
  author={Nwankpa, Chigozie and Ijomah, Winifred and Gachagan, Anthony and Marshall, Stephen},
  journal={arXiv preprint arXiv:1811.03378},
  year={2018}
}

@article{elfwing2018sigmoid,
  title={Sigmoid-weighted linear units for neural network function approximation in reinforcement learning},
  author={Elfwing, Stefan and Uchibe, Eiji and Doya, Kenji},
  journal={Neural networks},
  volume={107},
  pages={3--11},
  year={2018},
  publisher={Elsevier}
}

@misc{yang2024vivim,
      title={Vivim: a Video Vision Mamba for Medical Video Object Segmentation},
      author={Yijun Yang and Zhaohu Xing and Lei Zhu},
      year={2024},
      eprint={2401.14168},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
@inproceedings{wang2024heterogeneous,
  title={Heterogeneous Test-Time Training for Multi-Modal Person Re-identification},
  author={Wang, Zi and Huang, Huaibo and Zheng, Aihua and He, Ran},
  booktitle={AAAI},
  volume={38},
  pages={5850--5858},
  year={2024}
}

@inproceedings{zhang2024magic,
  title={Magic tokens: Select diverse tokens for multi-modal object re-identification},
  author={Zhang, Pingping and Wang, Yuhao and Liu, Yang and Tu, Zhengzheng and Lu, Huchuan},
  booktitle={CVPR},
  pages={17117--17126},
  year={2024}
}

@article{zhou2022mixture,
  title={Mixture-of-experts with expert choice routing},
  author={Zhou, Yanqi and Lei, Tao and Liu, Hanxiao and Du, Nan and Huang, Yanping and Zhao, Vincent and Dai, Andrew M and Le, Quoc V and Laudon, James and others},
  journal={NIPS},
  volume={35},
  pages={7103--7114},
  year={2022}
}
@article{wang2025unity,
  title={Unity Is Strength: Unifying Convolutional and Transformeral Features for Better Person Re-Identification},
  author={Wang, Yuhao and Zhang, Pingping and Liu, Xuehu and Tu, Zhengzheng and Lu, Huchuan},
  journal={TITS},
  year={2025},
  publisher={IEEE}
}
@inproceedings{gong2024cross,
 title={Cross-Modality Perturbation Synergy Attack for Person Re-identification},
 author={Gong,Yunpeng and Zhong, Zhun and  Qu,Yansong and Luo,Zhiming and Ji,Rongrong and Jiang,Min },
 booktitle={NeurIPS},
 year={2024},
 url={https://openreview.net/forum?id=LONd7ACEjy}
}


@article{cai2024survey,
  title={A Survey on Mixture of Experts},
  author={Cai, Weilin and Jiang, Juyong and Wang, Fan and Tang, Jing and Kim, Sunghun and Huang, Jiayi},
  journal={arXiv preprint arXiv:2407.06204},
  year={2024}
}

@article{zhang2024multimodal,
  title={Multimodal fusion on low-quality data: A comprehensive survey},
  author={Zhang, Qingyang and Wei, Yake and Han, Zongbo and Fu, Huazhu and Peng, Xi and Deng, Cheng and Hu, Qinghua and Xu, Cai and Wen, Jie and Hu, Di and others},
  journal={arXiv preprint arXiv:2404.18947},
  year={2024}
}


@article{wei2024robust,
  title={Robust Multimodal Learning via Representation Decoupling},
  author={Wei, Shicai and Luo, Yang and Wang, Yuji and Luo, Chunbo},
  journal={arXiv preprint arXiv:2407.04458},
  year={2024}
}

@inproceedings{li2023decoupled,
  title={Decoupled multimodal distilling for emotion recognition},
  author={Li, Yong and Wang, Yuanzhi and Cui, Zhen},
  booktitle={CVPR},
  pages={6631--6640},
  year={2023}
}

@article{jacobs1991adaptive,
  title={Adaptive mixtures of local experts},
  author={Jacobs, Robert A and Jordan, Michael I and Nowlan, Steven J and Hinton, Geoffrey E},
  journal={Neural computation},
  volume={3},
  number={1},
  pages={79--87},
  year={1991},
  publisher={MIT Press}
}

@article{dai2024deepseekmoe,
  title={Deepseekmoe: Towards ultimate expert specialization in mixture-of-experts language models},
  author={Dai, Damai and Deng, Chengqi and Zhao, Chenggang and Xu, RX and Gao, Huazuo and Chen, Deli and Li, Jiashi and Zeng, Wangding and Yu, Xingkai and Wu, Y and others},
  journal={arXiv preprint arXiv:2401.06066},
  year={2024}
}

@article{riquelme2021scaling,
  title={Scaling vision with sparse mixture of experts},
  author={Riquelme, Carlos and Puigcerver, Joan and Mustafa, Basil and Neumann, Maxim and Jenatton, Rodolphe and Susano Pinto, Andr{\'e} and Keysers, Daniel and Houlsby, Neil},
  journal={NIPS},
  volume={34},
  pages={8583--8595},
  year={2021}
}

@article{hwang2023tutel,
  title={Tutel: Adaptive mixture-of-experts at scale},
  author={Hwang, Changho and Cui, Wei and Xiong, Yifan and Yang, Ziyue and Liu, Ze and Hu, Han and Wang, Zilong and Salas, Rafael and Jose, Jithin and Ram, Prabhat and others},
  journal={MLS},
  volume={5},
  pages={269--287},
  year={2023}
}

@article{li2024uni,
  title={Uni-MoE: Scaling Unified Multimodal LLMs with Mixture of Experts},
  author={Li, Yunxin and Jiang, Shenyuan and Hu, Baotian and Wang, Longyue and Zhong, Wanqi and Luo, Wenhan and Ma, Lin and Zhang, Min},
  journal={arXiv preprint arXiv:2405.11273},
  year={2024}
}

@inproceedings{dai2021generalizable,
  title={Generalizable person re-identification with relevance-aware mixture of experts},
  author={Dai, Yongxing and Li, Xiaotong and Liu, Jun and Tong, Zekun and Duan, Ling-Yu},
  booktitle={CVPR},
  pages={16145--16154},
  year={2021}
}

@inproceedings{xu2022mimic,
  title={Mimic embedding via adaptive aggregation: Learning generalizable person re-identification},
  author={Xu, Boqiang and Liang, Jian and He, Lingxiao and Sun, Zhenan},
  booktitle={ECCV},
  pages={372--388},
  year={2022},
  organization={Springer}
}

@article{li2023multi,
  title={Multi-granularity pseudo-label collaboration for unsupervised person re-identification},
  author={Li, Xiaobao and Li, Qingyong and Liang, Fengjiao and Wang, Wen},
  journal={CVIU},
  volume={227},
  pages={103616},
  year={2023},
  publisher={Elsevier}
}


@article{liu2024video,
  title={A video is worth three views: Trigeminal transformers for video-based person re-identification},
  author={Liu, Xuehu and Zhang, Pingping and Yu, Chenyang and Qian, Xuesheng and Yang, Xiaoyun and Lu, Huchuan},
  journal={TITS},
  year={2024},
  publisher={IEEE}
}


@article{liu2023deeply,
  title={Deeply coupled convolution--transformer with spatial--temporal complementary learning for video-based person re-identification},
  author={Liu, Xuehu and Yu, Chenyang and Zhang, Pingping and Lu, Huchuan},
  journal={TNNLS},
  year={2023},
  publisher={IEEE}
}


@inproceedings{lu2023learning,
  title={Learning progressive modality-shared transformers for effective visible-infrared person re-identification},
  author={Lu, Hu and Zou, Xuezhang and Zhang, Pingping},
  booktitle={AAAI},
  volume={37},
  pages={1835--1843},
  year={2023}
}

@inproceedings{liu2021watching,
  title={Watching you: Global-guided reciprocal learning for video-based person re-identification},
  author={Liu, Xuehu and Zhang, Pingping and Yu, Chenyang and Lu, Huchuan and Yang, Xiaoyun},
  booktitle={CVPR},
  pages={13334--13343},
  year={2021}
}

@article{wang2024other,
  title={Other tokens matter: Exploring global and local features of Vision Transformers for Object Re-Identification},
  author={Wang, Yingquan and Zhang, Pingping and Wang, Dong and Lu, Huchuan},
  journal={CVIU},
  volume={244},
  pages={104030},
  year={2024},
  publisher={Elsevier}
}

@inproceedings{yu2024tf,
  title={TF-CLIP: Learning text-free CLIP for video-based person re-identification},
  author={Yu, Chenyang and Liu, Xuehu and Wang, Yingquan and Zhang, Pingping and Lu, Huchuan},
  booktitle={AAAI},
  volume={38},
  pages={6764--6772},
  year={2024}
}

@article{liu2024completed,
  title={Completed Feature Disentanglement Learning for Multimodal MRIs Analysis},
  author={Liu, Tianling and Liu, Hongying and Shang, Fanhua and Yu, Lequan and Han, Tong and Wan, Liang},
  journal={arXiv preprint arXiv:2407.04916},
  year={2024}
}

@article{lin2024moe,
  title={Moe-llava: Mixture of experts for large vision-language models},
  author={Lin, Bin and Tang, Zhenyu and Ye, Yang and Cui, Jiaxi and Zhu, Bin and Jin, Peng and Zhang, Junwu and Ning, Munan and Yuan, Li},
  journal={arXiv preprint arXiv:2401.15947},
  year={2024}
}

@article{kuang2024unity,
  title={Unity in Diversity: Multi-expert Knowledge Confrontation and Collaboration for Generalizable Vehicle Re-identification},
  author={Kuang, Zhenyu and Zhang, Hongyang and Cheng, Lidong and Liu, Yinhao and Huang, Yue and Ding, Xinghao},
  journal={arXiv preprint arXiv:2407.07351},
  year={2024}
}

@article{chen2024emoe,
  title={eMoE-Tracker: Environmental MoE-based Transformer for Robust Event-guided Object Tracking},
  author={Chen, Yucheng and Wang, Lin},
  journal={arXiv preprint arXiv:2406.20024},
  year={2024}
}

@article{gui2024eegmamba,
  title={EEGMamba: Bidirectional State Space Models with Mixture of Experts for EEG Classification},
  author={Gui, Yiyu and Chen, MingZhi and Su, Yuqi and Luo, Guibo and Yang, Yuchao},
  journal={arXiv preprint arXiv:2407.20254},
  year={2024}
}


@inproceedings{tan2024harnessing,
  title={Harnessing the Power of MLLMs for Transferable Text-to-Image Person ReID},
  author={Tan, Wentan and Ding, Changxing and Jiang, Jiayu and Wang, Fei and Zhan, Yibing and Tao, Dapeng},
  booktitle={CVPR},
  pages={17127--17137},
  year={2024}
}

@article{han2024clip,
  title={CLIP-SCGI: Synthesized Caption-Guided Inversion for Person Re-Identification},
  author={Han, Qianru and He, Xinwei and Liu, Zhi and Liu, Sannyuya and Zhang, Ying and Xiang, Jinhai},
  journal={arXiv preprint arXiv:2410.09382},
  year={2024}
}

@inproceedings{baldrati2023zero,
  title={Zero-shot composed image retrieval with textual inversion},
  author={Baldrati, Alberto and Agnolucci, Lorenzo and Bertini, Marco and Del Bimbo, Alberto},
  booktitle={ICCV},
  pages={15338--15347},
  year={2023}
}

@inproceedings{he2024instruct,
  title={Instruct-ReID: A Multi-purpose Person Re-identification Task with Instructions},
  author={He, Weizhen and Deng, Yiheng and Tang, Shixiang and Chen, Qihao and Xie, Qingsong and Wang, Yizhou and Bai, Lei and Zhu, Feng and Zhao, Rui and Ouyang, Wanli and others},
  booktitle={CVPR},
  pages={17521--17531},
  year={2024}
}

@article{bai2023qwen,
  title={Qwen-vl: A versatile vision-language model for understanding, localization, text reading, and beyond},
  author={Bai, Jinze and Bai, Shuai and Yang, Shusheng and Wang, Shijie and Tan, Sinan and Wang, Peng and Lin, Junyang and Zhou, Chang and Zhou, Jingren},
  journal={arXiv preprint arXiv:2308.12966},
  volume={1},
  number={2},
  pages={3},
  year={2023}
}
@article{ding2021semantically,
  title={Semantically self-aligned network for text-to-image part-aware person re-identification},
  author={Ding, Zefeng and Ding, Changxing and Shao, Zhiyin and Tao, Dacheng},
  journal={arXiv preprint arXiv:2107.12666},
  year={2021}
}

@article{zuo2023plip,
  title={Plip: Language-image pre-training for person representation learning},
  author={Zuo, Jialong and Hong, Jiahao and Zhang, Feng and Yu, Changqian and Zhou, Hanyu and Gao, Changxin and Sang, Nong and Wang, Jingdong},
  journal={arXiv preprint arXiv:2305.08386},
  year={2023}
}
@article{liu2023visual,
  title={Visual instruction tuning},
  author={Liu, Haotian and Li, Chunyuan and Wu, Qingyang and Lee, Yong Jae},
  journal={NeurIPS},
  volume={36},
  pages={34892--34916},
  year={2023}
}

@article{lu2024deepseek,
  title={Deepseek-vl: towards real-world vision-language understanding},
  author={Lu, Haoyu and Liu, Wen and Zhang, Bo and Wang, Bingxuan and Dong, Kai and Liu, Bo and Sun, Jingxiang and Ren, Tongzheng and Li, Zhuoshu and Yang, Hao and others},
  journal={arXiv preprint arXiv:2403.05525},
  year={2024}
}

@inproceedings{chollet2017xception,
  title={Xception: Deep learning with depthwise separable convolutions},
  author={Chollet, Fran{\c{c}}ois},
  booktitle={CVPR},
  pages={1251--1258},
  year={2017}
}
@inproceedings{li2017person,
  title={Person search with natural language description},
  author={Li, Shuang and Xiao, Tong and Li, Hongsheng and Zhou, Bolei and Yue, Dayu and Wang, Xiaogang},
  booktitle={CVPR},
  pages={1970--1979},
  year={2017}
  
}

@inproceedings{jiang2023cross,
  title={Cross-modal implicit relation reasoning and aligning for text-to-image person retrieval},
  author={Jiang, Ding and Ye, Mang},
  booktitle={CVPR},
  pages={2787--2797},
  year={2023}
}

@inproceedings{shao2022learning,
  title={Learning granularity-unified representations for text-to-image person re-identification},
  author={Shao, Zhiyin and Zhang, Xinyu and Fang, Meng and Lin, Zhifeng and Wang, Jian and Ding, Changxing},
  booktitle={ACM MM},
  pages={5566--5574},
  year={2022}
}

@inproceedings{yang2023towards,
  title={Towards unified text-based person retrieval: A large-scale multi-attribute and language search benchmark},
  author={Yang, Shuyu and Zhou, Yinan and Zheng, Zhedong and Wang, Yaxiong and Zhu, Li and Wu, Yujiao},
  booktitle={ACM MM},
  pages={4492--4501},
  year={2023}
}


@inproceedings{li2024all,
  title={All in One Framework for Multimodal Re-identification in the Wild},
  author={Li, He and Ye, Mang and Zhang, Ming and Du, Bo},
  booktitle={CVPR},
  pages={17459--17469},
  year={2024}
}
@inproceedings{zhai2022trireid,
  title={Trireid: Towards multi-modal person re-identification via descriptive fusion model},
  author={Zhai, Yajing and Zeng, Yawen and Cao, Da and Lu, Shaofei},
  booktitle={ICMR},
  pages={63--71},
  year={2022}
}

@inproceedings{chen2023towards,
  title={Towards modality-agnostic person re-identification with descriptive query},
  author={Chen, Cuiqun and Ye, Mang and Jiang, Ding},
  booktitle={CVPR},
  pages={15128--15137},
  year={2023}
}