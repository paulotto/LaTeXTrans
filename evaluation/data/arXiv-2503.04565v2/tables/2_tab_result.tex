%



\begin{table*}[t!]
    \centering
    \setlength{\tabcolsep}{4pt}
    \resizebox{2\columnwidth}{!}{%
    \begin{tabular}{c|l|l|ll|lllll}
        % \toprule
        \topline
          \rowcolor{mygray} & Association Method & Detection Method& HOTA $ \uparrow$ & IDF1$\uparrow$ & OSPA $\downarrow$  & MOTA$\uparrow$ & DetA $\uparrow$ & AssA $\uparrow$ & FPS $\uparrow$ \\
         % \midrule
         \hline
        \parbox[t]{3mm}{\multirow{12}{*}{\rotatebox[origin=c]{90}{Track-By- Detection (TBD)}}} 
         %
         & \multirow{3}{*}{SORT~\cite{bewley2016simple}} & YOLO11~\cite{yolo11} (baseline) & 25.83 & 29.56 & 0.915 & 31.02 & 27.62 & 24.51  & 49.18\\
         
         &  & OmniTrack$_{Det}$~\text{(ours)} & 26.34 \textcolor{codegreen}{(+0.51)} & 31.11 \textcolor{codegreen}{(+1.55)} & 0.907 \textcolor{codegreen}{(-0.008)} & 34.21 \textcolor{codegreen}{(+3.19)} & 30.52 \textcolor{codegreen}{(+2.90)} & 22.96 \textcolor{black}{(-1.55)} & 12.14 \\

        
        
        &  & OmniTrack$_{DA}$~\text{(ours)} & 29.44 \textcolor{codegreen}{(+3.10)} & 33.27 \textcolor{codegreen}{(+2.16)} & 0.927\textcolor{black}{(+0.020)} & 33.44 \textcolor{black}{(-0.77)} & 35.16 \textcolor{codegreen}{(+4.64)} & 25.06 \textcolor{codegreen}{(+2.10)} & 11.78\\
         \cline{2-10}
         % \cmidrule{2-9}

        & \multirow{3}{*}{ByteTrack~\cite{zhang2022bytetrack}} & YOLO11~\cite{yolo11} (baseline) & 27.85 & 32.20 & 0.896 & 34.46 & 31.49 & 25.15 & 50.36\\
         &  & OmniTrack$_{Det}$\text{(ours)} & 28.14 \textcolor{codegreen}{(+0.29)} & 32.97 \textcolor{codegreen}{(+0.77)} & 0.870 \textcolor{codegreen}{(-0.026)} & 37.36 \textcolor{codegreen}{(+2.90)} & 32.94 \textcolor{codegreen}{(+1.45)} & 24.29 \textcolor{black}{(-0.86)} & 12.24\\
         &  & OmniTrack$_{DA}$~\text{(ours)} & 29.58 \textcolor{codegreen}{(+1.44)} & 34.54 \textcolor{codegreen}{(+1.57)} & 0.859 \textcolor{codegreen}{(-0.011)} & 38.14 \textcolor{codegreen}{(+0.78)} & 34.71 \textcolor{codegreen}{(+1.77)} & 25.49 \textcolor{codegreen}{(+1.20)} & 11.83\\
         % \cline{2-11}
         % \cmidrule{2-9}
         \cline{2-10}


         
        

        & \multirow{3}{*}{OC-SORT~\cite{cao2023observation}} & YOLO11~\cite{yolo11} (baseline) & 29.26 & 33.69 & 0.874 & 34.22 & 31.81 & 27.48 & 46.33\\
         &  & OmniTrack$_{Det}$~\text{(ours)} & 29.43 \textcolor{codegreen}{(+0.17)} & 34.11 \textcolor{codegreen}{(+0.42)} & 0.851 \textcolor{codegreen}{(-0.023)} & 38.72 \textcolor{codegreen}{(+4.50)} & 34.48 \textcolor{codegreen}{(+2.67)} & 25.39 \textcolor{black}{(-2.09)} & 11.59\\
         &  & OmniTrack$_{DA}$~\text{(ours)} & 30.65 \textcolor{codegreen}{(+1.22)} & 34.83 \textcolor{codegreen}{(+0.72)} & 0.838 \textcolor{codegreen}{(-0.013)} & 36.37 \textcolor{black}{(-2.35)} & 35.58 \textcolor{codegreen}{(+1.10)} & 26.76 \textcolor{codegreen}{(+1.37)} & 11.13\\
         % \cline{2-11}
         % \cmidrule{2-9}
         \cline{2-10}



        

        & \multirow{3}{*}{HybridSORT~\cite{yang2024hybrid}} & YOLO11~\cite{yolo11} (baseline) & 29.71 & 34.16 & 0.877 & 34.71 & 31.70 & 28.39 & 44.34\\
         &  & OmniTrack$_{Det}$~\text{(ours)} & 30.00 \textcolor{codegreen}{(+0.29)} & 34.09 \textcolor{black}{(-0.07)} & 0.853 \textcolor{codegreen}{(-0.024)} & 32.32 \textcolor{black}{(-2.39)} & 35.02 \textcolor{codegreen}{(+3.32)} & 26.09 \textcolor{black}{(-2.30)} & 11.65\\
         &  & OmniTrack$_{DA}$~\text{(ours)} & 31.05 \textcolor{codegreen}{(+1.05)} & 36.06 \textcolor{codegreen}{(+1.97)} & 0.850 \textcolor{codegreen}{(-0.003)} & 38.13 \textcolor{codegreen}{(+5.81)} & 35.08 \textcolor{codegreen}{(+0.06)} & 27.78 \textcolor{codegreen}{(+1.69)} & 10.96\\
         % \cline{2-11}
         % \cmidrule{2-11}
         

    
         \hline
         \hline
         	 	 	 	 	 

         \parbox[t]{3mm}{\multirow{4}{*}{\rotatebox[origin=c]{90}{ E2E}}} 
         %
         & TrackFormer~\cite{meinhardt2021trackformer} & \multicolumn{1}{c|}{\centering\textit{n.a.}}  & 22.22 & 23.38 & 0.959 & 23.83 & 30.30 & 16.93 & 7.38\\
         & MOTR~\cite{zeng2022motr} & \multicolumn{1}{c|}{\centering\textit{n.a.}} & 19.78 & 23.25 & 0.928 & 25.44  & 25.51 & 15.61 & 12.73\\
         & MOTRv2~\cite{zhang2023motrv2} & \multicolumn{1}{c|}{\centering\textit{n.a.}} & 24.68 & 25.49 & \textbf{0.911} & 17.05 & 26.83 & 22.97 & \textbf{13.01}\\
         &   \name{}$_{E2E}$~\text{(ours)} &  \multicolumn{1}{c|}{\centering\textit{n.a.}}  & \textbf{25.12} & \textbf{27.42} & 0.925 & \textbf{34.99} & \textbf{33.35} & \textbf{19.17}  & 11.64\\
         % \bottomrule
         \bottomline
    \end{tabular}
    }        
        
    \caption{Results on the JRDB validation set~\cite{martin2021jrdb}. The first four groups compare methods under the TBD paradigm, whereas the last group presents a comparison under the E2E paradigm. In the TBD paradigm, each method is evaluated under three detection methods: the baseline with YOLO11 \cite{yolo11} as the detector, the OmniTrack$_{Det}$ detector, and OmniTrack$_{DA}$. The \textcolor{codegreen}{numbers} represent the improvement relative to the previous line's method. The FPS metric is measured on a single RTX 3090 GPU with an image resolution of $4160\times480$.
    %
    }
    \vspace{-3mm}
    \label{tab:baseline}
\end{table*}