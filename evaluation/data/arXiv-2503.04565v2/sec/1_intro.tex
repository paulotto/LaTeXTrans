%

\section{Introduction}
\label{sec:intro}


%

Panoramic cameras, with a 360{\textdegree} Field of View (FoV), capture comprehensive surrounding information, making them essential for applications like autonomous driving~\cite{Wen_2024_CVPR,cao2024occlusion}, robotic navigation~\cite{van2024visual,shi2023panoflow}, and human-computer interaction~\cite{wu2024effect,han2022panoramic_activity}. 
For small-scale mobile robots, such as quadrupedal robots, panoramic cameras are especially advantageous, allowing complete environmental awareness within a single compact setup, as illustrated in Fig.~\ref{fig:1}(a).

%

Despite progress in Multi-Object Tracking (MOT), panoramic MOT remains underexplored. 
Existing MOT algorithms~\cite{Chen_2024_CVPR,lv2024diffmot}, developed for pinhole cameras, struggle in panoramic settings due to inherent challenges like resolution loss, geometric distortion, and uneven color and brightness distribution when unfolded (Fig.~\ref{fig:1}~(d)). 
These challenges often lead to performance degradation when applying pinhole-based algorithms to panoramic images, limiting their effectiveness for panoramic scene perception.
%

To address these challenges, developing an MOT algorithm capable of comprehensive perception in panoramic images with panoramic FoV is a pressing problem. 
To this end, this paper, for the first time, proposes an omnidirectional multi-object tracking framework, \textbf{OmniTrack}, specifically designed for such tasks in 360{\textdegree} panoramic imagery. 
OmniTrack unifies two mainstream MOT paradigms—Tracking-By-Detection (TBD) and End-To-End (E2E) tracking—and introduces a feedback mechanism that effectively reduces uncertainty in panoramic FoV with rapid sensor motion, enabling fast and accurate target localization and association.

This framework consists of three core components: a \emph{CircularStatE Module}, \emph{FlexiTrack Instance}, and \emph{Tracklets Management}. 
The CircularStatE Module is designed to mitigate wide-angle distortion and enhance consistency in lighting and color.
The FlexiTrack Instance exploits the temporal continuity of objects, guiding the perception module to focus on key areas within the panoramic FoV and aiding in localization and association. 
This approach helps mitigate the difficulty of object localization in panoramic FoV. 
The Tracklets Management module collects and manages trajectory data, providing prior knowledge to the FlexiTrack Instance. 
Through these components, OmniTrack unifies the two MOT paradigms: disabling data association within Tracklets Management results in an End-to-End tracker, OmniTrack$_{E2E}$, while enabling association yields a TBD-style tracker, OmniTrack$_{DA}$. 
By employing the same data association strategy, as shown in Fig.~\ref{fig:1} (c), the framework of OmniTrack$_{DA}$ achieves significantly stronger performance. 
Disabling both the FlexiTrack Instance and Tracklets Management reduces the system to a panoramic object detector, OmniTrack$_{Det}$, as shown in Fig.~\ref{fig:1}~(b).

%

Moreover, to support panoramic MOT research, we developed \textbf{QuadTrack}, a dataset collected with a $360^{\circ}{\times}70^{\circ}$ panoramic camera mounted on a quadrupedal robot. This mobile platform’s biomimetic gait introduces realistic, complex motion characteristics, challenging existing MOT algorithms. Collected across five campuses in two cities, QuadTrack includes $19,200$ images, encompassing a wide variety of dynamic, real-world scenarios. In contrast to typical MOT datasets~\cite{milan2016mot16, caesar2020nuscenes,dendorfer2020mot20,semantickitti,bdd100k,cui2023sportsmot} that use static or linearly moving platforms, QuadTrack provides a new benchmark for evaluating MOT performance in panoramic-FoV scenarios with rapid and non-linear sensor motion. 

%

At a glance, our work makes the following contributions:
\begin{itemize}
    \item To address the gap in omnidirectional multi-object tracking, we propose \textbf{OmniTrack}, a novel framework that unifies both E2E and TBD tracking paradigms. This approach reduces uncertainty and enhances perceptual and association performance in panoramic-FoV scenarios.
    %

    \item We present \textbf{QuadTrack}, a new panoramic MOT dataset with complex motion dynamics, providing a challenging benchmark for panoramic-FoV multi-object tracking.
    
    %

    \item Extensive experiments on JRDB and QuadTrack datasets show OmniTrack’s superior performance, achieving a $26.92\%$ HOTA on JRDB and $23.45\%$ on QuadTrack test splits, advancing the state-of-the-art in panoramic MOT.
\end{itemize}

%
