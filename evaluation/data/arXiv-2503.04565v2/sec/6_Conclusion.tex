\section{Conclusion}
\label{sec:Conclusion}
%
This paper presents OmniTrack, a multi-object tracking framework tailored for panoramic images, effectively addressing key challenges like geometric distortion, low resolution, and lighting inconsistencies. Central to OmniTrack is a feedback mechanism that reduces uncertainty in panoramic-FoV tracking. The framework incorporates Tracklets Management for temporal stability, FlexiTrack Instance for rapid localization and association, and the CircularStatE Module to mitigate distortion and improve visual consistency.
%
Additionally, we present QuadTrack, a cross-campus multi-object tracking dataset collected using a quadruped robot to support dynamic motion scenarios. 
This challenging dataset is designed to advance research in omnidirectional perception for robotics. Experiments verify that OmniTrack achieves state-of-the-art performance on public JRDB and the established QuadTrack datasets, demonstrating its effectiveness in handling panoramic tracking tasks.


\noindent\textbf{Limitations.} 
%
While OmniTrack demonstrates strong performance, our approach is currently limited to 2D panoramic tracking without 3D capabilities, restricting depth perception in complex scenes. Additionally, the method is centered around a mobile robotic platform. Future work could consider extending to 3D panoramic MOT or exploring human-robot collaborative perception to enhance situational awareness.

