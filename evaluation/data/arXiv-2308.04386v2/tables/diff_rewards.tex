\begin{table}[!t]
\centering
\caption{
    Employing RL to train translation models with different reference-based rewards on the IWSLT’14 task.
}
\scalebox{0.83}{
\begin{tabular}{l>{\centering\arraybackslash}p{1cm}>{\centering\arraybackslash}p{1.4cm}>{\centering\arraybackslash}p{1.4cm}>{\centering\arraybackslash}p{1.3cm}>{\centering\arraybackslash}p{1.2cm}}
    \toprule[1.1pt]
        Reward              & BLEU & COMET-20 & COMET-22 & ChatRef. & Human R. \\ \midrule
        ChatGPT             & 34.12 & 38.33 & 79.69 & 66.41 & 3.87  \\ \midrule
        CSEM (Ours)&    34.73&  38.06&  79.55&  \bf{66.16}&     \bf{3.83}       \\
        BLEU&   \bf{34.91}&     37.67&  78.40&  64.80&  3.69    \\
        COMET-20&       32.29&  \bf{38.52}&     79.42&  65.28&  3.75    \\
        COMET-22&       32.78&  37.93&  \bf{79.65}&     65.37&  3.78    \\
    \toprule[1.1pt]
    \multicolumn{6}{l}{\parbox{10cm}{
        We report the results of RL with CSEM-large-ref in the “CSEM” row.
        We also report the human evaluation results for each translation model as described in Section \ref{sec:human_evaluation}.
    }}
\end{tabular}}
\vspace{-2mm}
\label{tab:diff_rewards}
\end{table}