@book{kahneman2011thinking,
    title={Thinking, Fast and Slow},
    author={Kahneman, D.},
    isbn={9781429969352},
    lccn={2011027143},
    year={2011},
    publisher={Farrar, Straus and Giroux}
}
@article{daniel2003maps,
    ISSN = {00028282},
    author = {Daniel Kahneman},
    journal = {The American Economic Review},  
    volume={93},
    number = {5},
    pages = {1449--1475},
    publisher = {American Economic Association},
    title = {Maps of Bounded Rationality: Psychology for Behavioral Economics},
    year = {2003}
}
@article{Evans1984-EVAHAA,
	author = {Jonathan Evans},
	journal = {British Journal of Psychology},  
    volume={75},
	number = {4},
	pages = {451--468},
	title = {Heuristic and Analytic Processes in Reasoning},
	year = {1984}
}
@inproceedings{marjanović2025deepseekr1thoughtologyletsthink,
      title={DeepSeek-R1 Thoughtology: Let's <think> about LLM Reasoning}, 
      author={Sara Vera Marjanović and Arkil Patel and Vaibhav Adlakha and Milad Aghajohari and Parishad BehnamGhader and Mehar Bhatia and Aditi Khandelwal and Austin Kraft and Benno Krojer and Xing Han Lù and Nicholas Meade and Dongchan Shin and Amirhossein Kazemnejad and Gaurav Kamath and Marius Mosbach and Karolina Stańczak and Siva Reddy},
      year={2025},
      eprint={2504.07128},
      booktitle={arXiv},
      url={https://arxiv.org/abs/2504.07128}, 
}
@inproceedings{brown2020languagemodelsfewshotlearners,
    title={Language Models are Few-Shot Learners}, 
    author={Tom B. Brown and Benjamin Mann and Nick Ryder and Melanie Subbiah and Jared Kaplan and Prafulla Dhariwal and Arvind Neelakantan and Pranav Shyam and Girish Sastry and Amanda Askell and Sandhini Agarwal and Ariel Herbert-Voss and Gretchen Krueger and Tom Henighan and Rewon Child and Aditya Ramesh and Daniel M. Ziegler and Jeffrey Wu and Clemens Winter and Christopher Hesse and Mark Chen and Eric Sigler and Mateusz Litwin and Scott Gray and Benjamin Chess and Jack Clark and Christopher Berner and Sam McCandlish and Alec Radford and Ilya Sutskever and Dario Amodei},
    year={2020},
    eprint={2005.14165},
    booktitle={arXiv},
    url={https://arxiv.org/abs/2005.14165}, 
}
@inproceedings{wu2024comparativestudyreasoningpatterns,
      title={A Comparative Study on Reasoning Patterns of OpenAI's o1 Model}, 
      author={Siwei Wu and Zhongyuan Peng and Xinrun Du and Tuney Zheng and Minghao Liu and Jialong Wu and Jiachen Ma and Yizhi Li and Jian Yang and Wangchunshu Zhou and Qunshu Lin and Junbo Zhao and Zhaoxiang Zhang and Wenhao Huang and Ge Zhang and Chenghua Lin and J. H. Liu},
      year={2024},
      eprint={2410.13639},
      booktitle={arXiv},
      url={https://arxiv.org/abs/2410.13639}, 
}
@inproceedings{bubeck2023sparksartificialgeneralintelligence,
    title={Sparks of Artificial General Intelligence: Early experiments with GPT-4}, 
    author={Sébastien Bubeck and Varun Chandrasekaran and Ronen Eldan and Johannes Gehrke and Eric Horvitz and Ece Kamar and Peter Lee and Yin Tat Lee and Yuanzhi Li and Scott Lundberg and Harsha Nori and Hamid Palangi and Marco Tulio Ribeiro and Yi Zhang},
    year={2023},
    eprint={2303.12712},
    booktitle={arXiv},
    url={https://arxiv.org/abs/2303.12712}, 
}
@article{Goertzel2014148,
    author = {Goertzel, Ben},
    title = {Artificial General Intelligence: Concept, State of the Art, and Future Prospects},
    journal = {Journal of Artificial General Intelligence},
    year = {2014},
    pages = {1--48}
}
@inproceedings{kaplan2020scalinglawsneurallanguage,
    title={Scaling Laws for Neural Language Models}, 
    author={Jared Kaplan and Sam McCandlish and Tom Henighan and Tom B. Brown and Benjamin Chess and Rewon Child and Scott Gray and Alec Radford and Jeffrey Wu and Dario Amodei},
    year={2020},
    eprint={2001.08361},
    booktitle={arXiv},
    url={https://arxiv.org/abs/2001.08361}, 
}
@inproceedings{hoffmann2022trainingcomputeoptimallargelanguage,
    title={Training Compute-Optimal Large Language Models}, 
    author={Jordan Hoffmann and Sebastian Borgeaud and Arthur Mensch and Elena Buchatskaya and Trevor Cai and Eliza Rutherford and Diego de Las Casas and Lisa Anne Hendricks and Johannes Welbl and Aidan Clark and Tom Hennigan and Eric Noland and Katie Millican and George van den Driessche and Bogdan Damoc and Aurelia Guy and Simon Osindero and Karen Simonyan and Erich Elsen and Jack W. Rae and Oriol Vinyals and Laurent Sifre},
    year={2022},
    eprint={2203.15556},
    booktitle={arXiv},
    url={https://arxiv.org/abs/2203.15556}, 
}


# method
@article{wei2022chain,
    title={Chain-of-thought prompting elicits reasoning in large language models},
    author={Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Xia, Fei and Chi, Ed and Le, Quoc V and Zhou, Denny and others},
    journal={Advances in neural information processing systems},
    volume={35},
    pages={24824--24837},
    year={2022},
    url={https://proceedings.neurips.cc/paper_files/paper/2022/hash/9d5609613524ecf4f15af0f7b31abca4-Abstract-Conference.html}
}
@article{snell2024scaling,
    title={Scaling llm test-time compute optimally can be more effective than scaling model parameters},
    author={Snell, Charlie and Lee, Jaehoon and Xu, Kelvin and Kumar, Aviral},
    journal={arXiv preprint arXiv:2408.03314},
    year={2024},
    url={https://arxiv.org/abs/2408.03314}
}
@article{liu2025can,
    title={Can 1B LLM Surpass 405B LLM? Rethinking Compute-Optimal Test-Time Scaling},
    author={Liu, Runze and Gao, Junqi and Zhao, Jian and Zhang, Kaiyan and Li, Xiu and Qi, Biqing and Ouyang, Wanli and Zhou, Bowen},
    journal={arXiv preprint arXiv:2502.06703},
    year={2025},
    url={https://arxiv.org/abs/2502.06703}
}
@inproceedings{ouyang2022training,
    title={Training language models to follow instructions with human feedback},
    author={Long Ouyang and Jeffrey Wu and Xu Jiang and Diogo Almeida and Carroll Wainwright and Pamela Mishkin and Chong Zhang and Sandhini Agarwal and Katarina Slama and Alex Gray and John Schulman and Jacob Hilton and Fraser Kelton and Luke Miller and Maddie Simens and Amanda Askell and Peter Welinder and Paul Christiano and Jan Leike and Ryan Lowe},
    booktitle={Advances in Neural Information Processing Systems},
    editor={Alice H. Oh and Alekh Agarwal and Danielle Belgrave and Kyunghyun Cho},  
    volume={35},
    pages={27730--27744},
    year={2022},
    url={https://openreview.net/forum?id=TG8KACxEON}
}
@inproceedings{ankner2024critique,
  title={Critique-out-Loud Reward Models},
  author={Ankner, Zachary and Paul, Mansheej and Cui, Brandon and Chang, Jonathan Daniel and Ammanabrolu, Prithviraj},
  booktitle={Pluralistic Alignment Workshop at NeurIPS 2024},
  year={2024},
}
@InProceedings{pmlrlazic19a,
    title = 	 {{POLITEX}: Regret Bounds for Policy Iteration using Expert Prediction},
    author =       {Abbasi-Yadkori, Yasin and Bartlett, Peter and Bhatia, Kush and Lazic, Nevena and Szepesvari, Csaba and Weisz, Gellert},
    booktitle = {International Conference on Machine Learning},
    pages = 	 {3692--3702},
    year = 	 {2019},
    url= {https://proceedings.mlr.press/v97/lazic19a.html}
}
@inproceedings{tomar2021mirrordescentpolicyoptimization,
  title={Mirror Descent Policy Optimization},
  author={Tomar, Manan and Shani, Lior and Efroni, Yonathan and Ghavamzadeh, Mohammad},
  year={2022},
  booktitle={International Conference on Learning Representations},
  url={https://openreview.net/forum?id=aBO5SvgSt1}
}
@inproceedings{brown2024large,
    title={Large Language Monkeys: Scaling Inference Compute with Repeated Sampling}, 
    author={Bradley Brown and Jordan Juravsky and Ryan Ehrlich and Ronald Clark and Quoc V. Le and Christopher Ré and Azalia Mirhoseini},
    year={2024},
    eprint={2407.21787},
    booktitle={arXiv},
    url={https://arxiv.org/abs/2407.21787}, 
}
@inproceedings{irvine2023rewarding,
    title={Rewarding Chatbots for Real-World Engagement with Millions of Users}, 
    author={Robert Irvine and Douglas Boubert and Vyas Raina and Adian Liusie and Ziyi Zhu and Vineet Mudupalli and Aliaksei Korshuk and Zongyi Liu and Fritz Cremer and Valentin Assassi and Christie-Carol Beauchamp and Xiaoding Lu and Thomas Rialan and William Beauchamp},
    year={2023},
    eprint={2303.06135},
    booktitle={arXiv},
    url={https://arxiv.org/abs/2303.06135}, 
}
@inproceedings{wang2023selfconsistency,
    title={Self-Consistency Improves Chain of Thought Reasoning in Language Models},
    author={Xuezhi Wang and Jason Wei and Dale Schuurmans and Quoc V Le and Ed H. Chi and Sharan Narang and Aakanksha Chowdhery and Denny Zhou},
    booktitle={International Conference on Learning Representations },
    year={2023},
    url={https://openreview.net/forum?id=1PL1NIMMrw}
}
@inproceedings{pfau2024lets,
    title={Let{\textquoteright}s Think Dot by Dot: Hidden computation in transformer language models},
    author={Jacob Pfau and William Merrill and Samuel R. Bowman},
    booktitle={Conference on Language Modeling},
    year={2024},
    url={https://openreview.net/forum?id=NikbrdtYvG}
}
@inproceedings{song2024good,
    title={The Good, The Bad, and The Greedy: Evaluation of LLMs Should Not Ignore Non-Determinism}, 
    author={Yifan Song and Guoyin Wang and Sujian Li and Bill Yuchen Lin},
    year={2024},
    eprint={2407.10457},
    booktitle={arXiv},
    url={https://arxiv.org/abs/2407.10457}, 
}
@inproceedings{aggarwal2025l1,
      title={L1: Controlling How Long A Reasoning Model Thinks With Reinforcement Learning}, 
      author={Pranjal Aggarwal and Sean Welleck},
      year={2025},
      eprint={2503.04697},
      booktitle={arXiv},
      url={https://arxiv.org/abs/2503.04697}, 
}
@inproceedings{nguyen2024consistent,
    title={When is the consistent prediction likely to be a correct prediction?}, 
    author={Alex Nguyen and Dheeraj Mekala and Chengyu Dong and Jingbo Shang},
    year={2024},
    eprint={2407.05778},
    booktitle={arXiv},
    url={https://arxiv.org/abs/2407.05778}, 
}
@inproceedings{yeo2025demystifying,
    title={Demystifying Long Chain-of-Thought Reasoning in LLMs}, 
    author={Edward Yeo and Yuxuan Tong and Morry Niu and Graham Neubig and Xiang Yue},
    year={2025},
    eprint={2502.03373},
    booktitle={arXiv},
    url={https://arxiv.org/abs/2502.03373}, 
}
@inproceedings{liu2025inferencetimescalinggeneralistreward,
      title={Inference-Time Scaling for Generalist Reward Modeling}, 
      author={Zijun Liu and Peiyi Wang and Runxin Xu and Shirong Ma and Chong Ruan and Peng Li and Yang Liu and Yu Wu},
      year={2025},
      eprint={2504.02495},
      booktitle={arXiv},
      url={https://arxiv.org/abs/2504.02495}, 
}
@inproceedings{chen2025judgelrmlargereasoningmodels,
      title={{JudgeLRM}: Large Reasoning Models as a Judge}, 
      author={Nuo Chen and Zhiyuan Hu and Qingyun Zou and Jiaying Wu and Qian Wang and Bryan Hooi and Bingsheng He},
      year={2025},
      eprint={2504.00050},
      booktitle={arXiv},
      url={https://arxiv.org/abs/2504.00050}, 
}
@inproceedings{han2025tokenbudgetawarellmreasoning,
    title={Token-Budget-Aware LLM Reasoning}, 
    author={Tingxu Han and Zhenting Wang and Chunrong Fang and Shiyu Zhao and Shiqing Ma and Zhenyu Chen},
    year={2025},
    eprint={2412.18547},
    booktitle={arXiv},
    url={https://arxiv.org/abs/2412.18547}, 
}
@inproceedings{tan2025judgebenchbenchmarkevaluatingllmbased,
      title={JudgeBench: A Benchmark for Evaluating LLM-based Judges}, 
      author={Sijun Tan and Siyuan Zhuang and Kyle Montgomery and William Y. Tang and Alejandro Cuadron and Chenguang Wang and Raluca Ada Popa and Ion Stoica},
      year={2025},
      eprint={2410.12784},
      booktitle={arXiv},
      url={https://arxiv.org/abs/2410.12784}, 
}
@inproceedings{skalse2025definingcharacterizingrewardhacking,
      title={Defining and Characterizing Reward Hacking}, 
      author={Joar Skalse and Nikolaus H. R. Howe and Dmitrii Krasheninnikov and David Krueger},
      year={2025},
      eprint={2209.13085},
      booktitle={arXiv},
      url={https://arxiv.org/abs/2209.13085}, 
}
@inproceedings{chen2025scalingautonomousagentsautomatic,
      title={Scaling Autonomous Agents via Automatic Reward Modeling And Planning}, 
      author={Zhenfang Chen and Delin Chen and Rui Sun and Wenjun Liu and Chuang Gan},
      year={2025},
      eprint={2502.12130},
      booktitle={arXiv},
      url={https://arxiv.org/abs/2502.12130}, 
}
@inproceedings{zhang2024buildingcooperativeembodiedagents,
      title={Building Cooperative Embodied Agents Modularly with Large Language Models}, 
      author={Hongxin Zhang and Weihua Du and Jiaming Shan and Qinhong Zhou and Yilun Du and Joshua B. Tenenbaum and Tianmin Shu and Chuang Gan},
      year={2024},
      eprint={2307.02485},
      booktitle={arXiv},
      url={https://arxiv.org/abs/2307.02485}, 
}
@inproceedings{song2024trialerrorexplorationbasedtrajectory,
      title={Trial and Error: Exploration-Based Trajectory Optimization for LLM Agents}, 
      author={Yifan Song and Da Yin and Xiang Yue and Jie Huang and Sujian Li and Bill Yuchen Lin},
      year={2024},
      eprint={2403.02502},
      booktitle={arXiv},
      url={https://arxiv.org/abs/2403.02502}, 
}
@inproceedings{NEURIPS2023_a3621ee9,
 title = {CAMEL: Communicative Agents for "Mind" Exploration of Large Language Model Society},
 author = {Li, Guohao and Hammoud, Hasan and Itani, Hani and Khizbullin, Dmitrii and Ghanem, Bernard},
 booktitle = {Advances in Neural Information Processing Systems},
 pages = {51991--52008},
 year = {2023}
}
@inproceedings{chen2024routerdcquerybasedrouterdual,
      title={{RouterDC}: Query-Based Router by Dual Contrastive Learning for Assembling Large Language Models}, 
      author={Shuhao Chen and Weisen Jiang and Baijiong Lin and James T. Kwok and Yu Zhang},
      year={2024},
      eprint={2409.19886},
      booktitle={arXiv},
      url={https://arxiv.org/abs/2409.19886}, 
}
@inproceedings{shen2025exploringdatascalingtrends,
      title={Exploring Data Scaling Trends and Effects in Reinforcement Learning from Human Feedback}, 
      author={Wei Shen and Guanlin Liu and Zheng Wu and Ruofei Zhu and Qingping Yang and Chao Xin and Yu Yue and Lin Yan},
      year={2025},
      eprint={2503.22230},
      booktitle={arXiv},
      url={https://arxiv.org/abs/2503.22230}, 
}
@inproceedings{
chakraborty2025collab,
title={Collab: Controlled Decoding using Mixture of Agents for {LLM} Alignment},
author={Souradip Chakraborty and Sujay Bhatt and Udari Madhushani Sehwag and Soumya Suvra Ghosal and Jiahao Qiu and Mengdi Wang and Dinesh Manocha and Furong Huang and Alec Koppel and Sumitra Ganesh},
booktitle={International Conference on Learning Representations},
year={2025},
url={https://openreview.net/forum?id=7ohlQUbTpp}
}
@inproceedings{luong2024reftreasoningreinforcedfinetuning,
      title={ReFT: Reasoning with Reinforced Fine-Tuning}, 
      author={Trung Quoc Luong and Xinbo Zhang and Zhanming Jie and Peng Sun and Xiaoran Jin and Hang Li},
      year={2024},
      eprint={2401.08967},
      booktitle={arXiv},
      url={https://arxiv.org/abs/2401.08967}, 
}
@inproceedings{zeng2025itoolboostingtooluse,
      title={iTool: Boosting Tool Use of Large Language Models via Iterative Reinforced Fine-Tuning}, 
      author={Yirong Zeng and Xiao Ding and Yuxian Wang and Weiwen Liu and Wu Ning and Yutai Hou and Xu Huang and Bing Qin and Ting Liu},
      year={2025},
      eprint={2501.09766},
      booktitle={arXiv},
      url={https://arxiv.org/abs/2501.09766}, 
}
@inproceedings{pareja2024unveilingsecretrecipeguide,
      title={Unveiling the Secret Recipe: A Guide For Supervised Fine-Tuning Small LLMs}, 
      author={Aldo Pareja and Nikhil Shivakumar Nayak and Hao Wang and Krishnateja Killamsetty and Shivchander Sudalairaj and Wenlong Zhao and Seungwook Han and Abhishek Bhandwaldar and Guangxuan Xu and Kai Xu and Ligong Han and Luke Inglis and Akash Srivastava},
      year={2024},
      eprint={2412.13337},
      booktitle={arXiv},
      url={https://arxiv.org/abs/2412.13337}, 
}
@inproceedings{kim2025scalingevaluationtimecomputereasoning,
      title={Scaling Evaluation-time Compute with Reasoning Models as Process Evaluators}, 
      author={Seungone Kim and Ian Wu and Jinu Lee and Xiang Yue and Seongyun Lee and Mingyeong Moon and Kiril Gashteovski and Carolin Lawrence and Julia Hockenmaier and Graham Neubig and Sean Welleck},
      year={2025},
      eprint={2503.19877},
      booktitle={arXiv},
      url={https://arxiv.org/abs/2503.19877}, 
}
@inproceedings{yuan2023scalingrelationshiplearningmathematical,
      title={Scaling Relationship on Learning Mathematical Reasoning with Large Language Models}, 
      author={Zheng Yuan and Hongyi Yuan and Chengpeng Li and Guanting Dong and Keming Lu and Chuanqi Tan and Chang Zhou and Jingren Zhou},
      year={2023},
      eprint={2308.01825},
      archivePrefix={arXiv},
      url={https://arxiv.org/abs/2308.01825}, 
}
@inproceedings{li2025llmseasilylearnreason,
    title={LLMs Can Easily Learn to Reason from Demonstrations Structure, not content, is what matters!}, 
    author={Dacheng Li and Shiyi Cao and Tyler Griggs and Shu Liu and Xiangxi Mo and Eric Tang and Sumanth Hegde and Kourosh Hakhamaneshi and Shishir G. Patil and Matei Zaharia and Joseph E. Gonzalez and Ion Stoica},
    year={2025},
    eprint={2502.07374},
    booktitle={arXiv},
    url={https://arxiv.org/abs/2502.07374}, 
}
@inproceedings{saunshi2025reasoninglatentthoughtspower,
      title={Reasoning with Latent Thoughts: On the Power of Looped Transformers}, 
      author={Nikunj Saunshi and Nishanth Dikkala and Zhiyuan Li and Sanjiv Kumar and Sashank J. Reddi},
      year={2025},
      eprint={2502.17416},
      booktitle={arXiv},
      url={https://arxiv.org/abs/2502.17416}, 
}
@inproceedings{shen2025efficientreasoninghiddenthinking,
      title={Efficient Reasoning with Hidden Thinking}, 
      author={Xuan Shen and Yizhou Wang and Xiangxi Shi and Yanzhi Wang and Pu Zhao and Jiuxiang Gu},
      year={2025},
      eprint={2501.19201},
      booktitle={arXiv},
      url={https://arxiv.org/abs/2501.19201}, 
}
@inproceedings{wu2025lessunderstandingchainofthoughtlength,
    title={When More is Less: Understanding Chain-of-Thought Length in LLMs}, 
    author={Yuyang Wu and Yifei Wang and Tianqi Du and Stefanie Jegelka and Yisen Wang},
    year={2025},
    eprint={2502.07266},
    booktitle={arXiv},
    url={https://arxiv.org/abs/2502.07266}, 
}
@inproceedings{zhang2024chain,
    title={Chain of Preference Optimization: Improving Chain-of-Thought Reasoning in {LLM}s},
    author={Xuan Zhang and Chao Du and Tianyu Pang and Qian Liu and Wei Gao and Min Lin},
    booktitle={Conference on Neural Information Processing Systems},
    year={2024},
    url={https://openreview.net/forum?id=2cczgOfMP4}
}
@inproceedings{geiping2025scalingtesttimecomputelatent,
      title={Scaling up Test-Time Compute with Latent Reasoning: A Recurrent Depth Approach}, 
      author={Jonas Geiping and Sean McLeish and Neel Jain and John Kirchenbauer and Siddharth Singh and Brian R. Bartoldson and Bhavya Kailkhura and Abhinav Bhatele and Tom Goldstein},
      year={2025},
      eprint={2502.05171},
      booktitle={arXiv},
      url={https://arxiv.org/abs/2502.05171}, 
}
@inproceedings{chen2024teaching,
    title={Teaching Large Language Models to Self-Debug},
    author={Xinyun Chen and Maxwell Lin and Nathanael Sch{\"a}rli and Denny Zhou},
    booktitle={International Conference on Learning Representations},
    year={2024},
    url={https://openreview.net/forum?id=KuPixIqPiq}
}
@inproceedings{NEURIPS2023_a85b405e,
    title = {Direct Preference Optimization: Your Language Model is Secretly a Reward Model},
    author = {Rafailov, Rafael and Sharma, Archit and Mitchell, Eric and Manning, Christopher D and Ermon, Stefano and Finn, Chelsea},
    booktitle = {Advances in Neural Information Processing Systems},
    editor = {A. Oh and T. Naumann and A. Globerson and K. Saenko and M. Hardt and S. Levine},
    pages = {53728--53741},
    publisher = {Curran Associates, Inc.},
    volume = {36},
    url = {https://proceedings.neurips.cc/paper_files/paper/2023/file/a85b405ed65c6477a4fe8302b5e06ce7-Paper-Conference.pdf},
    year = {2023},
}
@inproceedings{gou2024critic,
    title={{CRITIC}: Large Language Models Can Self-Correct with Tool-Interactive Critiquing},
    author={Zhibin Gou and Zhihong Shao and Yeyun Gong and yelong shen and Yujiu Yang and Nan Duan and Weizhu Chen},
    booktitle={International Conference on Learning Representations},
    year={2024},
    url={https://openreview.net/forum?id=Sx038qxjek}
}
@inproceedings{chen2024tree,
    title = {When is Tree Search Useful for {LLM} Planning? It Depends on the Discriminator},
    author = {Chen, Ziru  and
      White, Michael  and
      Mooney, Ray  and
      Payani, Ali  and
      Su, Yu  and
      Sun, Huan},
    booktitle = {Annual Meeting of the Association for Computational Linguistics},
    year = {2024},
    pages = {13659--13678},
    url = {https://aclanthology.org/2024.acl-long.738/}
}
@inproceedings{zhang2024smalllanguagemodelsneed,
  title={Small Language Models Need Strong Verifiers to Self-Correct Reasoning},
  author={Zhang, Yunxiang and Khalifa, Muhammad and Logeswaran, Lajanugen and Kim, Jaekyeom and Lee, Moontae and Lee, Honglak and Wang, Lu},
  booktitle={ACL (Findings)},
  year={2024},
  url={https://aclanthology.org/2024.findings-acl.924/}
}
@inproceedings{shen2025codicompressingchainofthoughtcontinuous,
      title={CODI: Compressing Chain-of-Thought into Continuous Space via Self-Distillation}, 
      author={Zhenyi Shen and Hanqi Yan and Linhai Zhang and Zhanghao Hu and Yali Du and Yulan He},
      year={2025},
      eprint={2502.21074},
      booktitle={arXiv},
      url={https://arxiv.org/abs/2502.21074}, 
}
@inproceedings{madaan2023selfrefine,
    title={Self-Refine: Iterative Refinement with Self-Feedback},
    author={Aman Madaan and Niket Tandon and Prakhar Gupta and Skyler Hallinan and Luyu Gao and Sarah Wiegreffe and Uri Alon and Nouha Dziri and Shrimai Prabhumoye and Yiming Yang and Shashank Gupta and Bodhisattwa Prasad Majumder and Katherine Hermann and Sean Welleck and Amir Yazdanbakhsh and Peter Clark},
    booktitle={Conference on Neural Information Processing Systems},
    year={2023},
    url={https://openreview.net/forum?id=S37hOerQLB}
}
@inproceedings{wang2025mixtureofagents,
    title={Mixture-of-Agents Enhances Large Language Model Capabilities},
    author={Junlin Wang and Jue WANG and Ben Athiwaratkun and Ce Zhang and James Zou},
    booktitle={International Conference on Learning Representations},
    year={2025},
    url={https://openreview.net/forum?id=h0ZfDIrj7T}
}
@inproceedings{li2023making,
    title={Making language models better reasoners with step-aware verifier},
    author={Li, Yifei and Lin, Zeqi and Zhang, Shizhuo and Fu, Qiang and Chen, Bei and Lou, Jian-Guang and Chen, Weizhu},
    booktitle={Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
    pages={5315--5333},
    year={2023},
    url={https://aclanthology.org/2023.acl-long.291/}
}
@inproceedings{chen2024are,
    title={Are More {LLM} Calls All You Need? Towards the Scaling Properties of Compound {AI} Systems},
    author={Lingjiao Chen and Jared Quincy Davis and Boris Hanin and Peter Bailis and Ion Stoica and Matei Zaharia and James Zou},
    booktitle={Conference on Neural Information Processing Systems},
    year={2024},
    url={https://openreview.net/forum?id=m5106RRLgx}
}
@misc{li2025stesttimescaling,
      title={S*: Test Time Scaling for Code Generation}, 
      author={Dacheng Li and Shiyi Cao and Chengkun Cao and Xiuyu Li and Shangyin Tan and Kurt Keutzer and Jiarong Xing and Joseph E. Gonzalez and Ion Stoica},
      year={2025},
      eprint={2502.14382},
      booktitle={arXiv},
      url={https://arxiv.org/abs/2502.14382}, 
}
@article{Stanovich_West_2000,
    title={Advancing the rationality debate}, 
    journal={Behavioral and Brain Sciences}, 
    author={Stanovich, Keith E. and West, Richard F.}, 
    year={2000}, 
    pages={701–717}
} 
@inproceedings{jiang2023llm,
    title = {{LLM}-Blender: Ensembling Large Language Models with Pairwise Ranking and Generative Fusion},
    author = {Jiang, Dongfu  and
      Ren, Xiang  and
      Lin, Bill Yuchen},
    booktitle = {Annual Meeting of the Association for Computational Linguistics},
    year = {2023},
    pages = {14165--14178},
    url = {https://aclanthology.org/2023.acl-long.792/}
}
@inproceedings{lambert2025tulu3pushingfrontiers,
  title={Tulu 3: Pushing Frontiers in Open Language Model Post-Training}, 
  author={Nathan Lambert and Jacob Morrison and Valentina Pyatkin and Shengyi Huang and Hamish Ivison and Faeze Brahman and Lester James V. Miranda and Alisa Liu and Nouha Dziri and Shane Lyu and Yuling Gu and Saumya Malik and Victoria Graf and Jena D. Hwang and Jiangjiang Yang and Ronan Le Bras and Oyvind Tafjord and Chris Wilhelm and Luca Soldaini and Noah A. Smith and Yizhong Wang and Pradeep Dasigi and Hannaneh Hajishirzi},
  year={2025},
  eprint={2411.15124},
  booktitle={arXiv},
  url={https://arxiv.org/abs/2411.15124}, 
}
@inproceedings{renze2024effectsamplingtemperatureproblem,
  title={The effect of sampling temperature on problem solving in large language models},
  author={Renze, Matthew},
  booktitle={Findings of the Association for Computational Linguistics: EMNLP 2024},
  pages={7346--7356},
  year={2024},
  url={https://aclanthology.org/2024.findings-emnlp.432/}
}
@inproceedings{yu2024distilling21,
  title={Distilling System 2 into System 1},
  author={Yu, Ping and Xu, Jing and Weston, Jason E and Kulikov, Ilia},
  booktitle={The First Workshop on System-2 Reasoning at Scale, NeurIPS'24},
  year={2024},
  url={https://openreview.net/forum?id=WUoC4BpJBC}
}
@inproceedings{wang2024planningnaturallanguageimproves,
      title={Planning In Natural Language Improves LLM Search For Code Generation}, 
      author={Evan Wang and Federico Cassano and Catherine Wu and Yunfeng Bai and Will Song and Vaskar Nath and Ziwen Han and Sean Hendryx and Summer Yue and Hugh Zhang},
      year={2024},
      eprint={2409.03733},
      booktitle={arXiv},
      url={https://arxiv.org/abs/2409.03733}, 
}
@inproceedings{ling2023deductive,
 author = {Ling, Zhan and Fang, Yunhao and Li, Xuanlin and Huang, Zhiao and Lee, Mingu and Memisevic, Roland and Su, Hao},
 booktitle = {Advances in Neural Information Processing Systems},
 pages = {36407--36433},
 title = {Deductive Verification of Chain-of-Thought Reasoning},
 volume = {36},
 year = {2023},
 url = {https://proceedings.neurips.cc/paper_files/paper/2023/hash/72393bd47a35f5b3bee4c609e7bba733-Abstract-Conference.html}
}
@inproceedings{ranaldi2025improvingchainofthoughtreasoningquasisymbolic,
      title={Improving Chain-of-Thought Reasoning via Quasi-Symbolic Abstractions}, 
      author={Leonardo Ranaldi and Marco Valentino and Alexander Polonsky and Andrè Freitas},
      year={2025},
      eprint={2502.12616},
      booktitle={arXiv},
      url={https://arxiv.org/abs/2502.12616}, 
}
@inproceedings{
wang2024guiding,
title={Guiding Language Model Reasoning with Planning Tokens},
author={Xinyi Wang and Lucas Caccia and Oleksiy Ostapenko and Xingdi Yuan and William Yang Wang and Alessandro Sordoni},
booktitle={Conference on Language Modeling},
year={2024},
url={https://openreview.net/forum?id=wi9IffRhVM}
}
@inproceedings{kong2025scalablelanguagemodelsposterior,
      title={Scalable Language Models with Posterior Inference of Latent Thought Vectors}, 
      author={Deqian Kong and Minglu Zhao and Dehong Xu and Bo Pang and Shu Wang and Edouardo Honig and Zhangzhang Si and Chuan Li and Jianwen Xie and Sirui Xie and Ying Nian Wu},
      year={2025},
      eprint={2502.01567},
      booktitle={arXiv},
      url={https://arxiv.org/abs/2502.01567}, 
}
@inproceedings{hosseini2024vstartrainingverifiersselftaught,
  title={V-STaR: Training Verifiers for Self-Taught Reasoners},
  author={Hosseini, Arian and Yuan, Xingdi and Malkin, Nikolay and Courville, Aaron and Sordoni, Alessandro and Agarwal, Rishabh},
  booktitle={First Conference on Language Modeling},
  year={2024},
  url={https://openreview.net/forum?id=stmqBSW2dV}
}
@inproceedings{havrilla2024glorewhenwhereimprove,
  title={GLoRe: When, Where, and How to Improve LLM Reasoning via Global and Local Refinements},
  author={Havrilla, Alexander and Raparthy, Sharath Chandra and Nalmpantis, Christoforos and Dwivedi-Yu, Jane and Zhuravinskyi, Maksym and Hambro, Eric and Raileanu, Roberta},
  booktitle={Forty-first International Conference on Machine Learning},
  year={2024},
  url={https://openreview.net/forum?id=LH6R06NxdB}
}
@inproceedings{ferraz2024llmselfcorrectiondecrimdecompose,
  title={LLM Self-Correction with DeCRIM: Decompose, Critique, and Refine for Enhanced Following of Instructions with Multiple Constraints},
  author={Ferraz, Thomas Palmeira and Mehta, Kartik and Lin, Yu-Hsiang and Chang, Haw-Shiuan and Oraby, Shereen and Liu, Sijia and Subramanian, Vivek and Chung, Tagyoung and Bansal, Mohit and Peng, Nanyun},
  booktitle={Findings of the Association for Computational Linguistics: EMNLP 2024},
  pages={7773--7812},
  year={2024},
  url={https://aclanthology.org/2024.findings-emnlp.458/}
}
@inproceedings{li2025draftsanswersunlockingllm,
      title={From Drafts to Answers: Unlocking LLM Potential via Aggregation Fine-Tuning}, 
      author={Yafu Li and Zhilin Wang and Tingchen Fu and Ganqu Cui and Sen Yang and Yu Cheng},
      year={2025},
      eprint={2501.11877},
      booktitle={arXiv},
      url={https://arxiv.org/abs/2501.11877}, 
}
@inproceedings{wang2024seedctsunleashingpowertree,
      title={Seed-CTS: Unleashing the Power of Tree Search for Superior Performance in Competitive Coding Tasks}, 
      author={Hao Wang and Boyi Liu and Yufeng Zhang and Jie Chen},
      year={2024},
      eprint={2412.12544},
      booktitle={arXiv},
      url={https://arxiv.org/abs/2412.12544}, 
}
@inproceedings{li2025reasoningaslogicunitsscalingtesttimereasoning,
      title={Reasoning-as-Logic-Units: Scaling Test-Time Reasoning in Large Language Models Through Logic Unit Alignment}, 
      author={Cheryl Li and Tianyuan Xu and Yiwen Guo},
      year={2025},
      eprint={2502.07803},
      booktitle={arXiv},
      url={https://arxiv.org/abs/2502.07803}, 
}
@inproceedings{li2025metalmultiagentframeworkchart,
      title={{METAL}: A Multi-Agent Framework for Chart Generation with Test-Time Scaling}, 
      author={Bingxuan Li and Yiwei Wang and Jiuxiang Gu and Kai-Wei Chang and Nanyun Peng},
      year={2025},
      eprint={2502.17651},
      booktitle={arXiv},
      url={https://arxiv.org/abs/2502.17651}, 
}
@inproceedings{guan2025rstarmath,
      title={rStar-Math: Small LLMs Can Master Math Reasoning with Self-Evolved Deep Thinking}, 
      author={Xinyu Guan and Li Lyna Zhang and Yifei Liu and Ning Shang and Youran Sun and Yi Zhu and Fan Yang and Mao Yang},
      year={2025},
      eprint={2501.04519},
      booktitle={arXiv},
      url={https://arxiv.org/abs/2501.04519}, 
}
@inproceedings{xiang2024atomthinkslowthinkingframework,
      title={AtomThink: A Slow Thinking Framework for Multimodal Mathematical Reasoning}, 
      author={Kun Xiang and Zhili Liu and Zihao Jiang and Yunshuang Nie and Runhui Huang and Haoxiang Fan and Hanhui Li and Weiran Huang and Yihan Zeng and Jianhua Han and Lanqing Hong and Hang Xu and Xiaodan Liang},
      year={2024},
      eprint={2411.11930},
      booktitle={arXiv},
      url={https://arxiv.org/abs/2411.11930}, 
}
@inproceedings{wang2025critiquefinetuninglearningcritique,
      title={Critique Fine-Tuning: Learning to Critique is More Effective than Learning to Imitate}, 
      author={Yubo Wang and Xiang Yue and Wenhu Chen},
      year={2025},
      eprint={2501.17703},
      booktitle={arXiv},
      url={https://arxiv.org/abs/2501.17703}, 
}
@inproceedings{liu2024improvingmultistepreasoningabilities,
      title={Improving Multi-Step Reasoning Abilities of Large Language Models with Direct Advantage Policy Optimization}, 
      author={Jiacai Liu and Chaojie Wang and Chris Yuhao Liu and Liang Zeng and Rui Yan and Yiwen Sun and Yang Liu and Yahui Zhou},
      year={2024},
      eprint={2412.18279},
      booktitle={arXiv},
      url={https://arxiv.org/abs/2412.18279}, 
}
@inproceedings{mahan2024generativerewardmodels,
      title={Generative Reward Models}, 
      author={Dakota Mahan and Duy Van Phung and Rafael Rafailov and Chase Blagden and Nathan Lile and Louis Castricato and Jan-Philipp Fränken and Chelsea Finn and Alon Albalak},
      year={2024},
      eprint={2410.12832},
      booktitle={arXiv},
      url={https://arxiv.org/abs/2410.12832}, 
}
@inproceedings{zhang2025generativeverifiersrewardmodeling,
      title={Generative Verifiers: Reward Modeling as Next-Token Prediction}, 
      author={Lunjun Zhang and Arian Hosseini and Hritik Bansal and Mehran Kazemi and Aviral Kumar and Rishabh Agarwal},
      year={2025},
      eprint={2408.15240},
      booktitle={arXiv},
      url={https://arxiv.org/abs/2408.15240}, 
}
@inproceedings{yu2024siamselfimprovingcodeassistedmathematical,
      title={SIaM: Self-Improving Code-Assisted Mathematical Reasoning of Large Language Models}, 
      author={Dian Yu and Baolin Peng and Ye Tian and Linfeng Song and Haitao Mi and Dong Yu},
      year={2024},
      eprint={2408.15565},
      booktitle={arXiv},
      url={https://arxiv.org/abs/2408.15565}, 
}
@inproceedings{chen2025iterativedeepeningsamplinglarge,
      title={Iterative Deepening Sampling for Large Language Models}, 
      author={Weizhe Chen and Sven Koenig and Bistra Dilkina},
      year={2025},
      eprint={2502.05449},
      booktitle={arXiv},
      url={https://arxiv.org/abs/2502.05449}, 
}
@inproceedings{he2025enhancingllmreasoningmultipath,
      title={Enhancing LLM Reasoning with Multi-Path Collaborative Reactive and Reflection agents}, 
      author={Chengbo He and Bochao Zou and Xin Li and Jiansheng Chen and Junliang Xing and Huimin Ma},
      year={2025},
      eprint={2501.00430},
      booktitle={arXiv},
      url={https://arxiv.org/abs/2501.00430}, 
}
@inproceedings{pan2025coatchainofassociatedthoughtsframeworkenhancing,
      title={CoAT: Chain-of-Associated-Thoughts Framework for Enhancing Large Language Models Reasoning}, 
      author={Jianfeng Pan and Senyou Deng and Shaomang Huang},
      year={2025},
      eprint={2502.02390},
      booktitle={arXiv},
      url={https://arxiv.org/abs/2502.02390}, 
}
@inproceedings{lin2025leveragingconstrainedmontecarlo,
      title={Leveraging Constrained Monte Carlo Tree Search to Generate Reliable Long Chain-of-Thought for Mathematical Reasoning}, 
      author={Qingwen Lin and Boyan Xu and Zijian Li and Zhifeng Hao and Keli Zhang and Ruichu Cai},
      year={2025},
      eprint={2502.11169},
      booktitle={arXiv},
      url={https://arxiv.org/abs/2502.11169}, 
}
@inproceedings{chen2024braininspiredtwostageapproachenhancing,
      title={Brain-Inspired Two-Stage Approach: Enhancing Mathematical Reasoning by Imitating Human Thought Processes}, 
      author={Yezeng Chen and Zui Chen and Yi Zhou},
      year={2024},
      eprint={2403.00800},
      booktitle={arXiv},
      url={https://arxiv.org/abs/2403.00800}, 
}
@inproceedings{zhou2023leasttomostpromptingenablescomplex,
  title={Least-to-Most Prompting Enables Complex Reasoning in Large Language Models},
  author={Zhou, Denny and Sch{\"a}rli, Nathanael and Hou, Le and Wei, Jason and Scales, Nathan and Wang, Xuezhi and Schuurmans, Dale and Cui, Claire and Bousquet, Olivier and Le, Quoc V and others},
  booktitle={The Eleventh International Conference on Learning Representations},
  year={2023},
  url={https://openreview.net/forum?id=WZH7099tgfM}
}
@inproceedings{zhang2024wrongofthoughtintegratedreasoningframework,
  title={Wrong-of-Thought: An Integrated Reasoning Framework with Multi-Perspective Verification and Wrong Information},
  author={Zhang, Yongheng and Chen, Qiguang and Zhou, Jingxuan and Wang, Peng and Si, Jiasheng and Wang, Jin and Lu, Wenpeng and Qin, Libo},
  booktitle={Findings of the Association for Computational Linguistics: EMNLP 2024},
  pages={6644--6653},
  year={2024},
  url={https://aclanthology.org/2024.findings-emnlp.388/}
}
@inproceedings{liang2024encouraging,
    title = {Encouraging Divergent Thinking in Large Language Models through Multi-Agent Debate},
    author = {Liang, Tian  and
      He, Zhiwei  and
      Jiao, Wenxiang  and
      Wang, Xing  and
      Wang, Yan  and
      Wang, Rui  and
      Yang, Yujiu  and
      Shi, Shuming  and
      Tu, Zhaopeng},
    booktitle = {Conference on Empirical Methods in Natural Language Processing},
    year = {2024},
    url = {https://aclanthology.org/2024.emnlp-main.992/},
    pages = {17889--17904}
}
@inproceedings{schaul2024boundlesssocraticlearninglanguage,
  title={Boundless Socratic Learning with Language Games},
  author={Schaul, Tom},
  booktitle={Language Gamification-NeurIPS 2024 Workshop},
  year={2024},
  url={https://openreview.net/forum?id=6U4pQf3tlL}
}

@article{zelikman2022star,
  title={Star: Bootstrapping reasoning with reasoning},
  author={Zelikman, Eric and Wu, Yuhuai and Mu, Jesse and Goodman, Noah},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={15476--15488},
  year={2022}
}
@inproceedings{li2025startselftaughtreasonertools,
      title={{START}: Self-taught Reasoner with Tools}, 
      author={Chengpeng Li and Mingfeng Xue and Zhenru Zhang and Jiaxi Yang and Beichen Zhang and Xiang Wang and Bowen Yu and Binyuan Hui and Junyang Lin and Dayiheng Liu},
      year={2025},
      eprint={2503.04625},
      booktitle={arXiv},
      url={https://arxiv.org/abs/2503.04625}, 
}
@inproceedings{ong2025routellm,
    title={Route{LLM}: Learning to Route {LLM}s from Preference Data},
    author={Isaac Ong and Amjad Almahairi and Vincent Wu and Wei-Lin Chiang and Tianhao Wu and Joseph E. Gonzalez and M Waleed Kadous and Ion Stoica},
    booktitle={International Conference on Learning Representations},
    year={2025},
    url={https://openreview.net/forum?id=8sSqNntaMr}
}
@inproceedings{yao2023tree,
    title={Tree of Thoughts: Deliberate Problem Solving with Large Language Models},
    author={Shunyu Yao and Dian Yu and Jeffrey Zhao and Izhak Shafran and Thomas L. Griffiths and Yuan Cao and Karthik R Narasimhan},
    booktitle={Conference on Neural Information Processing Systems},
    year={2023},
    url={https://openreview.net/forum?id=5Xc1ecxO1h}
}
@article{Besta2024graph,
    title={Graph of Thoughts: Solving Elaborate Problems with Large Language Models},
    journal={AAAI Conference on Artificial Intelligence},
    author={Besta, Maciej and Blach, Nils and Kubicek, Ales and Gerstenberger, Robert and Podstawski, Michal and Gianinazzi, Lukas and Gajda, Joanna and Lehmann, Tomasz and Niewiadomski, Hubert and Nyczyk, Piotr and Hoefler, Torsten},
    year={2024},
    pages={17682–17690}
}
@inproceedings{kang2025scalablebestofnselectionlarge,
      title={Scalable Best-of-N Selection for Large Language Models via Self-Certainty}, 
      author={Zhewei Kang and Xuandong Zhao and Dawn Song},
      year={2025},
      eprint={2502.18581},
      booktitle={arXiv},
      url={https://arxiv.org/abs/2502.18581}, 
}
@inproceedings{tian2024toward,
    title={Toward Self-Improvement of {LLM}s via Imagination, Searching, and Criticizing},
    author={Ye Tian and Baolin Peng and Linfeng Song and Lifeng Jin and Dian Yu and Lei Han and Haitao Mi and Dong Yu},
    booktitle={Conference on Neural Information Processing Systems},
    year={2024},
    url={https://openreview.net/forum?id=tPdJ2qHkOB}
}
@inproceedings{ma2025inferencetimescalingdiffusionmodels,
      title={Inference-Time Scaling for Diffusion Models beyond Scaling Denoising Steps}, 
      author={Nanye Ma and Shangyuan Tong and Haolin Jia and Hexiang Hu and Yu-Chuan Su and Mingda Zhang and Xuan Yang and Yandong Li and Tommi Jaakkola and Xuhui Jia and Saining Xie},
      year={2025},
      eprint={2501.09732},
      booktitle={arXiv},
      url={https://arxiv.org/abs/2501.09732}, 
}
@inproceedings{uesato2022solvingmathwordproblems,
      title={Solving math word problems with process- and outcome-based feedback}, 
      author={Jonathan Uesato and Nate Kushman and Ramana Kumar and Francis Song and Noah Siegel and Lisa Wang and Antonia Creswell and Geoffrey Irving and Irina Higgins},
      year={2022},
      eprint={2211.14275},
      booktitle={arXiv},
      url={https://arxiv.org/abs/2211.14275}, 
}
@inproceedings{choudhury2025processrewardmodelsllm,
      title={Process Reward Models for LLM Agents: Practical Framework and Directions}, 
      author={Sanjiban Choudhury},
      year={2025},
      eprint={2502.10325},
      booktitle={arXiv},
      url={https://arxiv.org/abs/2502.10325}, 
}
@inproceedings{ma2025steplevelrewardmodelsrewarding,
      title={What Are Step-Level Reward Models Rewarding? Counterintuitive Findings from MCTS-Boosted Mathematical Reasoning}, 
      author={Yiran Ma and Zui Chen and Tianqiao Liu and Mi Tian and Zhuo Liu and Zitao Liu and Weiqi Luo},
      year={2025},
      eprint={2412.15904},
      booktitle={arXiv},
      url={https://arxiv.org/abs/2412.15904}, 
}
@inproceedings{yao2023react,
    title={ReAct: Synergizing Reasoning and Acting in Language Models},
    author={Shunyu Yao and Jeffrey Zhao and Dian Yu and Nan Du and Izhak Shafran and Karthik R Narasimhan and Yuan Cao},
    booktitle={International Conference on Learning Representations },
    year={2023},
    url={https://openreview.net/forum?id=WE_vluYUL-X}
}
@inproceedings{gao2024interpretable,
    title={Interpretable Contrastive Monte Carlo Tree Search Reasoning}, 
    author={Zitian Gao and Boye Niu and Xuzheng He and Haotian Xu and Hongzhang Liu and Aiwei Liu and Xuming Hu and Lijie Wen},
    year={2024},
    eprint={2410.01707},
    booktitle={arXiv},
    url={https://arxiv.org/abs/2410.01707}, 
}
@misc{yuan2023scaling,
    title={Scaling Relationship on Learning Mathematical Reasoning with Large Language Models}, 
    author={Zheng Yuan and Hongyi Yuan and Chengpeng Li and Guanting Dong and Keming Lu and Chuanqi Tan and Chang Zhou and Jingren Zhou},
    year={2023},
    eprint={2308.01825},
    booktitle={arXiv},
    url={https://arxiv.org/abs/2308.01825}, 
}
@article{singh2024beyond,
    title={Beyond Human Data: Scaling Self-Training for Problem-Solving with Language Models},
    author={Avi Singh and John D Co-Reyes and Rishabh Agarwal and Ankesh Anand and Piyush Patil and Xavier Garcia and Peter J Liu and James Harrison and Jaehoon Lee and Kelvin Xu and Aaron T Parisi and Abhishek Kumar and Alexander A Alemi and Alex Rizkowsky and Azade Nova and Ben Adlam and Bernd Bohnet and Gamaleldin Fathy Elsayed and Hanie Sedghi and Igor Mordatch and Isabelle Simpson and Izzeddin Gur and Jasper Snoek and Jeffrey Pennington and Jiri Hron and Kathleen Kenealy and Kevin Swersky and Kshiteej Mahajan and Laura A Culp and Lechao Xiao and Maxwell Bileschi and Noah Constant and Roman Novak and Rosanne Liu and Tris Warkentin and Yamini Bansal and Ethan Dyer and Behnam Neyshabur and Jascha Sohl-Dickstein and Noah Fiedel},
    journal={Transactions on Machine Learning Research},
    issn={2835-8856},
    year={2024},
    url={https://openreview.net/forum?id=lNAyUngGFK},
}
@misc{xiang20252reasoningllmslearning,
    title={Towards System 2 Reasoning in LLMs: Learning How to Think With Meta Chain-of-Thought}, 
    author={Violet Xiang and Charlie Snell and Kanishk Gandhi and Alon Albalak and Anikait Singh and Chase Blagden and Duy Phung and Rafael Rafailov and Nathan Lile and Dakota Mahan and Louis Castricato and Jan-Philipp Franken and Nick Haber and Chelsea Finn},
    year={2025},
    eprint={2501.04682},
    booktitle={arXiv},
    url={https://arxiv.org/abs/2501.04682}, 
}
@inproceedings{xie2023selfevaluation,
    title={Self-Evaluation Guided Beam Search for Reasoning},
    author={Yuxi Xie and Kenji Kawaguchi and Yiran Zhao and Xu Zhao and Min-Yen Kan and Junxian He and Qizhe Xie},
    booktitle={Thirty-seventh Conference on Neural Information Processing Systems},
    year={2023},
    url={https://openreview.net/forum?id=Bw82hwg5Q3}
}
@inproceedings{zhang2023planning,
    title={Planning with Large Language Models for Code Generation},
    author={Shun Zhang and Zhenfang Chen and Yikang Shen and Mingyu Ding and Joshua B. Tenenbaum and Chuang Gan},
    booktitle={International Conference on Learning Representations },
    year={2023},
    url={https://openreview.net/forum?id=Lr8cOOtYbfL}
}
@inproceedings{xu2025redstardoesscalinglongcot,
    title={RedStar: Does Scaling Long-CoT Data Unlock Better Slow-Reasoning Systems?}, 
    author={Haotian Xu and Xing Wu and Weinong Wang and Zhongzhi Li and Da Zheng and Boyuan Chen and Yi Hu and Shijia Kang and Jiaming Ji and Yingying Zhang and Zhijiang Guo and Yaodong Yang and Muhan Zhang and Debing Zhang},
    year={2025},
    eprint={2501.11284},
    booktitle={arXiv},
    url={https://arxiv.org/abs/2501.11284}, 
}
@misc{bespoke_stratos,  
    author = {Bespoke},  
    title = {Bespoke-Stratos: The unreasonable effectiveness of reasoning distillation},  
    howpublished = {www.bespokelabs.ai/blog/bespoke-stratos-the-unreasonable-effectiveness-of-reasoning-distillation}, 
    note = {Accessed: 2025-01-22},  
    year = {2025}
}
@misc{guo2024direct,
    title={Direct Language Model Alignment from Online AI Feedback}, 
    author={Shangmin Guo and Biao Zhang and Tianlin Liu and Tianqi Liu and Misha Khalman and Felipe Llinares and Alexandre Rame and Thomas Mesnard and Yao Zhao and Bilal Piot and Johan Ferret and Mathieu Blondel},
    year={2024},
    eprint={2402.04792},
    archivePrefix={arXiv},
    primaryClass={cs.AI},
    url={https://arxiv.org/abs/2402.04792}, 
}
@misc{schulman2017proximalpolicyoptimizationalgorithms,
    title={Proximal Policy Optimization Algorithms}, 
    author={John Schulman and Filip Wolski and Prafulla Dhariwal and Alec Radford and Oleg Klimov},
    year={2017},
    eprint={1707.06347},
    booktitle={arXiv},
    url={https://arxiv.org/abs/1707.06347}, 
}
@misc{hou2025advancing,
    title={Advancing Language Model Reasoning through Reinforcement Learning and Inference Scaling}, 
    author={Zhenyu Hou and Xin Lv and Rui Lu and Jiajie Zhang and Yujiang Li and Zijun Yao and Juanzi Li and Jie Tang and Yuxiao Dong},
    year={2025},
    eprint={2501.11651},
    booktitle={arXiv},
    url={https://arxiv.org/abs/2501.11651}, 
}
@misc{chen2025reasoningerasurveylong,
      title={Towards Reasoning Era: A Survey of Long Chain-of-Thought for Reasoning Large Language Models}, 
      author={Qiguang Chen and Libo Qin and Jinhao Liu and Dengyun Peng and Jiannan Guan and Peng Wang and Mengkang Hu and Yuhang Zhou and Te Gao and Wanxiang Che},
      year={2025},
      eprint={2503.09567},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2503.09567}, 
}
@inproceedings{lee2025evolvingdeeperllmthinking,
    title={Evolving Deeper LLM Thinking}, 
    author={Kuang-Huei Lee and Ian Fischer and Yueh-Hua Wu and Dave Marwood and Shumeet Baluja and Dale Schuurmans and Xinyun Chen},
    year={2025},
    eprint={2501.09891},
    booktitle={arXiv},
    url={https://arxiv.org/abs/2501.09891}, 
}
@inproceedings{xi2024enhancingllmreasoningcritique,
      title={Enhancing LLM Reasoning via Critique Models with Test-Time and Training-Time Supervision}, 
      author={Zhiheng Xi and Dingwen Yang and Jixuan Huang and Jiafu Tang and Guanyu Li and Yiwen Ding and Wei He and Boyang Hong and Shihan Do and Wenyu Zhan and Xiao Wang and Rui Zheng and Tao Ji and Xiaowei Shi and Yitao Zhai and Rongxiang Weng and Jingang Wang and Xunliang Cai and Tao Gui and Zuxuan Wu and Qi Zhang and Xipeng Qiu and Xuanjing Huang and Yu-Gang Jiang},
      year={2024},
      eprint={2411.16579},
      booktitle={arXiv},
      url={https://arxiv.org/abs/2411.16579}, 
}
@misc{ji2024steiner,
    title = {A Small Step Towards Reproducing OpenAI o1: Progress Report on the Steiner Open Source Models},
    url = {https://medium.com/@peakji/b9a756a00855},
    author = {Yichao Ji},
    month = {October},
    year = {2024}
}
@inproceedings{bhargava2024whatsmagicwordcontrol,
      title={What's the Magic Word? A Control Theory of LLM Prompting}, 
      author={Aman Bhargava and Cameron Witkowski and Shi-Zhuo Looi and Matt Thomson},
      year={2024},
      eprint={2310.04444},
      booktitle={arXiv},
      url={https://arxiv.org/abs/2310.04444}, 
}
@inproceedings{li2024chainthoughtempowerstransformers,
  title={Chain of Thought Empowers Transformers to Solve Inherently Serial Problems},
  author={Li, Zhiyuan and Liu, Hong and Zhou, Denny and Ma, Tengyu},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2024},
  url={https://openreview.net/forum?id=3EWTEy9MTM}
}
@inproceedings{huang2025thinkbenchdynamicoutofdistributionevaluation,
      title={ThinkBench: Dynamic Out-of-Distribution Evaluation for Robust LLM Reasoning}, 
      author={Shulin Huang and Linyi Yang and Yan Song and Shuang Chen and Leyang Cui and Ziyu Wan and Qingcheng Zeng and Ying Wen and Kun Shao and Weinan Zhang and Jun Wang and Yue Zhang},
      year={2025},
      eprint={2502.16268},
      booktitle={arXiv},
      url={https://arxiv.org/abs/2502.16268}, 
}
@inproceedings{wu2025evaluatingsocialbiasesllm,
      title={Evaluating Social Biases in LLM Reasoning}, 
      author={Xuyang Wu and Jinming Nian and Zhiqiang Tao and Yi Fang},
      year={2025},
      eprint={2502.15361},
      booktitle={arXiv},
      url={https://arxiv.org/abs/2502.15361}, 
}
@article{xiao2024comprehensive,
  title={A Comprehensive Survey of Direct Preference Optimization: Datasets, Theories, Variants, and Applications},
  author={Xiao, Wenyi and Wang, Zechuan and Gan, Leilei and Zhao, Shuai and He, Wanggui and Tuan, Luu Anh and Chen, Long and Jiang, Hao and Zhao, Zhou and Wu, Fei},
  journal={arXiv preprint arXiv:2410.15595},
  year={2024},
  url={https://arxiv.org/abs/2410.15595}
}
@article{lai2024step,
  title={Step-dpo: Step-wise preference optimization for long-chain reasoning of llms},
  author={Lai, Xin and Tian, Zhuotao and Chen, Yukang and Yang, Senqiao and Peng, Xiangru and Jia, Jiaya},
  journal={arXiv preprint arXiv:2406.18629},
  year={2024},
  url={https://arxiv.org/abs/2406.18629}
}
@inproceedings{wu2024thinkingllmsgeneralinstruction,
      title={Thinking LLMs: General Instruction Following with Thought Generation}, 
      author={Tianhao Wu and Janice Lan and Weizhe Yuan and Jiantao Jiao and Jason Weston and Sainbayar Sukhbaatar},
      year={2024},
      eprint={2410.10630},
      booktitle={arXiv},
      url={https://arxiv.org/abs/2410.10630}, 
}
@article{lin2024critical,
  title={Critical Tokens Matter: Token-Level Contrastive Estimation Enhence LLM's Reasoning Capability},
  author={Lin, Zicheng and Liang, Tian and Xu, Jiahao and Wang, Xing and Luo, Ruilin and Shi, Chufan and Li, Siheng and Yang, Yujiu and Tu, Zhaopeng},
  journal={arXiv preprint arXiv:2411.19943},
  year={2024},
  url={https://arxiv.org/abs/2411.19943}
}
@article{ji2024enhancing,
  title={Enhancing multi-step reasoning abilities of language models through direct q-function optimization},
  author={Ji, Kaixuan and Liu, Guanlin and Dai, Ning and Yang, Qingping and Zheng, Renjie and Wu, Zheng and Dun, Chen and Gu, Quanquan and Yan, Lin},
  journal={arXiv preprint arXiv:2410.09302},
  year={2024},
  abs={https://arxiv.org/abs/2410.09302}
}
@article{zhang2024codedpo,
  title={Codedpo: Aligning code models with self generated and verified source code},
  author={Zhang, Kechi and Li, Ge and Dong, Yihong and Xu, Jingjing and Zhang, Jun and Su, Jing and Liu, Yongfei and Jin, Zhi},
  journal={arXiv preprint arXiv:2410.05605},
  year={2024},
  url={https://arxiv.org/abs/2410.05605}
}
@article{zhang2025reasoning,
  title={Reasoning with reinforced functional token tuning},
  author={Zhang, Kongcheng and Yao, Qi and Lai, Baisheng and Huang, Jiaxing and Fang, Wenkai and Tao, Dacheng and Song, Mingli and Liu, Shunyu},
  journal={arXiv preprint arXiv:2502.13389},
  year={2025},
  abs={https://arxiv.org/abs/2502.13389}
}
@inproceedings{gandhi2024streams,
    title={Stream of Search (SoS): Learning to Search in Language}, 
    author={Kanishk Gandhi and Denise Lee and Gabriel Grand and Muxin Liu and Winson Cheng and Archit Sharma and Noah D. Goodman},
    year={2024},
    eprint={2404.03683},
    booktitle={arXiv},
    url={https://arxiv.org/abs/2404.03683}, 
}
@article{wang2024cpl,
  title={CPL: Critical Plan Step Learning Boosts LLM Generalization in Reasoning Tasks},
  author={Wang, Tianlong and Chen, Junzhe and Han, Xueting and Bai, Jing},
  journal={arXiv preprint arXiv:2409.08642},
  year={2024},
  url={https://arxiv.org/abs/2409.08642}
}
@article{zhang2025focused,
  title={Focused-DPO: Enhancing Code Generation Through Focused Preference Optimization on Error-Prone Points},
  author={Zhang, Kechi and Li, Ge and Li, Jia and Dong, Yihong and Jin, Zhi},
  journal={arXiv preprint arXiv:2502.11475},
  year={2025},
  url={https://arxiv.org/abs/2502.11475}
}
@article{wang2024offline,
  title={Offline Reinforcement Learning for LLM Multi-Step Reasoning},
  author={Wang, Huaijie and Hao, Shibo and Dong, Hanze and Zhang, Shenao and Bao, Yilin and Yang, Ziran and Wu, Yi},
  journal={arXiv preprint arXiv:2412.16145},
  year={2024},
  url={https://arxiv.org/abs/2412.16145}
}

@misc{zeng2025simplerl,
  title={7B Model and 8K Examples: Emerging Reasoning with Reinforcement Learning is Both Effective and Efficient},
  author={Weihao Zeng and Yuzhen Huang and Wei Liu and Keqing He and Qian Liu and Zejun Ma and Junxian He},
  year={2025},
  howpublished={\url{https://hkust-nlp.notion.site/simplerl-reason}},
  note={Notion Blog}
}
@misc{deepscaler2025,
  title={DeepScaleR: Surpassing O1-Preview with a 1.5B Model by Scaling RL},
  author={Michael Luo and Sijun Tan and Justin Wong and Xiaoxiang Shi and William Y. Tang and Manan Roongta and Colin Cai and Jeffrey Luo and Tianjun Zhang and Li Erran Li and Raluca Ada Popa and Ion Stoica},
  year={2025},
  howpublished={\url{https://pretty-radio-b75.notion.site/DeepScaleR-Surpassing-O1-Preview-with-a-1-5B-Model-by-Scaling-RL-19681902c1468005bed8ca303013a4e2}},
  note={Notion Blog}
}
@misc{xr12025,
  title={X-R1},
  author={X-R1Team},
  year={2025},
  howpublished={\url{https://github.com/dhcode-cpp/X-R1}},
  note={Github}
}
@misc{tinyzero,
author       = {Jiayi Pan and Junjie Zhang and Xingyao Wang and Lifan Yuan and Hao Peng and Alane Suhr},
title        = {TinyZero},
howpublished = {https://github.com/Jiayi-Pan/TinyZero},
note         = {Accessed: 2025-01-24},
year         = {2025}
}
@misc{OpenReasonerZero2025,
  title={Open-Reasoner-Zero: An Open Source Approach to Scaling Reinforcement Learning on the Base Model},
  author={Jingcheng Hu and Yinmin Zhang and Qi Han and Daxin Jiang and Xiangyu Zhang, Heung-Yeung Shum},
  year={2025},
  howpublished={\url{https://github.com/Open-Reasoner-Zero/Open-Reasoner-Zero}},
}
@article{wang2024openr,
  title={OpenR: An Open Source Framework for Advanced Reasoning with Large Language Models},
  author={Wang, Jun and Fang, Meng and Wan, Ziyu and Wen, Muning and Zhu, Jiachen and Liu, Anjie and Gong, Ziqin and Song, Yan and Chen, Lei and Ni, Lionel M and others},
  journal={arXiv preprint arXiv:2410.09671},
  year={2024},
  url={https://arxiv.org/abs/2410.09671}
}
@article{hu2024openrlhf,
  title={OpenRLHF: An Easy-to-use, Scalable and High-performance RLHF Framework},
  author={Jian Hu and Xibin Wu and Zilin Zhu and Xianyu and Weixun Wang and Dehao Zhang and Yu Cao},
  journal={arXiv preprint arXiv:2405.11143},
  year={2024},
  url={https://arxiv.org/abs/2405.11143}
}
@misc{openr1,
    title = {Open R1: A fully open reproduction of DeepSeek-R1},
    url = {https://github.com/huggingface/open-r1},
    author = {HuggingFace},
    month = {January},
    year = {2025}
}
@article{xie2025logic,
  title={Logic-rl: Unleashing llm reasoning with rule-based reinforcement learning},
  author={Xie, Tian and Gao, Zitian and Ren, Qingnan and Luo, Haoming and Hong, Yuqian and Dai, Bryan and Zhou, Joey and Qiu, Kai and Wu, Zhirong and Luo, Chong},
  journal={arXiv preprint arXiv:2502.14768},
  year={2025},
  url={https://arxiv.org/abs/2502.14768}
}
@article{li2023remax,
  title={Remax: A simple, effective, and efficient reinforcement learning method for aligning large language models},
  author={Li, Ziniu and Xu, Tian and Zhang, Yushun and Lin, Zhihang and Yu, Yang and Sun, Ruoyu and Luo, Zhi-Quan},
  journal={arXiv preprint arXiv:2310.10505},
  year={2023},
  url={https://arxiv.org/abs/2310.10505}
}
@inproceedings{sun2025uncertain,
  title={Uncertainty and Influence aware Reward Model Refinement for Reinforcement Learning from Human Feedback},
  author={Sun, Zexu and Guo, Yiju and Lin, Yankai and Chen, Xu and Qi, Qi and Tang, Xing and Wen, Ji-Rong},
  booktitle={The Thirteenth International Conference on Learning Representations},
  year={2025},
  url={https://openreview.net/forum?id=iamWnRpMuQ}
}
@article{shao2024deepseekmath,
  title={Deepseekmath: Pushing the limits of mathematical reasoning in open language models},
  author={Shao, Zhihong and Wang, Peiyi and Zhu, Qihao and Xu, Runxin and Song, Junxiao and Bi, Xiao and Zhang, Haowei and Zhang, Mingchuan and Li, YK and Wu, Y and others},
  journal={arXiv preprint arXiv:2402.03300},
  year={2024},
  url={https://arxiv.org/abs/2402.03300}
}
@article{hu2025reinforce++,
  title={REINFORCE++: A Simple and Efficient Approach for Aligning Large Language Models},
  author={Hu, Jian and Liu, Jason Klein and Wei, Shen},
  journal={arXiv preprint arXiv:2501.03262},
  year={2025},
  url={https://arxiv.org/abs/2501.03262}
}
@article{huang2025lean,
  title={Lean and Mean: Decoupled Value Policy Optimization with Global Value Guidance},
  author={Huang, Chenghua and Wang, Lu and Yang, Fangkai and Zhao, Pu and Li, Zhixu and Lin, Qingwei and Zhang, Dongmei and Rajmohan, Saravan and Zhang, Qi},
  journal={arXiv preprint arXiv:2502.16944},
  year={2025},
  url={https://arxiv.org/abs/2502.16944}
}
@article{cui2025process,
  title={Process reinforcement through implicit rewards},
  author={Cui, Ganqu and Yuan, Lifan and Wang, Zefan and Wang, Hanbin and Li, Wendi and He, Bingxiang and Fan, Yuchen and Yu, Tianyu and Xu, Qixin and Chen, Weize and others},
  journal={arXiv preprint arXiv:2502.01456},
  year={2025},
  url={https://arxiv.org/abs/2502.01456}
}
@article{kazemnejad2024vineppo,
  title={Vineppo: Unlocking rl potential for llm reasoning through refined credit assignment},
  author={Kazemnejad, Amirhossein and Aghajohari, Milad and Portelance, Eva and Sordoni, Alessandro and Reddy, Siva and Courville, Aaron and Roux, Nicolas Le},
  journal={arXiv preprint arXiv:2410.01679},
  year={2024},
  url={https://arxiv.org/abs/2410.01679}
}
@article{gao2025principled,
  title={Principled Data Selection for Alignment: The Hidden Risks of Difficult Examples},
  author={Gao, Chengqian and Li, Haonan and Liu, Liu and Xie, Zeke and Zhao, Peilin and Xu, Zhiqiang},
  journal={arXiv preprint arXiv:2502.09650},
  year={2025},
  url={https://arxiv.org/abs/2502.09650}
}
@article{sutton1999policy,
  title={Policy gradient methods for reinforcement learning with function approximation},
  author={Sutton, Richard S and McAllester, David and Singh, Satinder and Mansour, Yishay},
  journal={Advances in neural information processing systems},
  volume={12},
  year={1999},
  url={https://proceedings.neurips.cc/paper_files/paper/1999/hash/464d828b85b0bed98e80ade0a5c43b0f-Abstract.html}
}
@article{vassoyan2025ignore,
  title={Ignore the KL Penalty! Boosting Exploration on Critical Tokens to Enhance RL Fine-Tuning},
  author={Vassoyan, Jean and Beau, Nathana{\"e}l and Plaud, Roman},
  journal={arXiv preprint arXiv:2502.06533},
  year={2025},
  url={https://arxiv.org/abs/2502.06533}
}
@article{zhou2025q,
  title={Q$\backslash$sharp : Provably Optimal Distributional RL for LLM Post-Training},
  author={Zhou, Jin Peng and Wang, Kaiwen and Chang, Jonathan and Gao, Zhaolin and Kallus, Nathan and Weinberger, Kilian Q and Brantley, Kiant{\'e} and Sun, Wen},
  journal={arXiv preprint arXiv:2502.20548},
  year={2025},
  url={https://arxiv.org/abs/2502.20548}
}
@article{zheng2023secrets,
  title={Secrets of rlhf in large language models part i: Ppo},
  author={Zheng, Rui and Dou, Shihan and Gao, Songyang and Hua, Yuan and Shen, Wei and Wang, Binghai and Liu, Yan and Jin, Senjie and Liu, Qin and Zhou, Yuhao and others},
  journal={arXiv preprint arXiv:2307.04964},
  year={2023},
  url={https://arxiv.org/abs/2307.04964}
}
@article{yi2025sppd,
  title={SPPD: Self-training with Process Preference Learning Using Dynamic Value Margin},
  author={Yi, Hao and Li, Qingyang and Hu, Yulan and Zhang, Fuzheng and Zhang, Di and Liu, Yong},
  journal={arXiv preprint arXiv:2502.13516},
  year={2025},
  url={https://arxiv.org/abs/2502.13516}
}
@article{pang2024iterative,
  title={Iterative reasoning preference optimization},
  author={Pang, Richard Yuanzhe and Yuan, Weizhe and He, He and Cho, Kyunghyun and Sukhbaatar, Sainbayar and Weston, Jason},
  journal={Advances in Neural Information Processing Systems},
  volume={37},
  pages={116617--116637},
  year={2024}
}
@article{dong2024rlhf,
  title={Rlhf workflow: From reward modeling to online rlhf},
  author={Dong, Hanze and Xiong, Wei and Pang, Bo and Wang, Haoxiang and Zhao, Han and Zhou, Yingbo and Jiang, Nan and Sahoo, Doyen and Xiong, Caiming and Zhang, Tong},
  journal={arXiv preprint arXiv:2405.07863},
  year={2024},
  url={https://arxiv.org/abs/2405.07863}
}
@inproceedings{ye2024evolvingalignmentasymmetricselfplay,
      title={Evolving Alignment via Asymmetric Self-Play}, 
      author={Ziyu Ye and Rishabh Agarwal and Tianqi Liu and Rishabh Joshi and Sarmishta Velury and Quoc V. Le and Qijun Tan and Yuan Liu},
      year={2024},
      eprint={2411.00062},
      booktitle={arXiv},
      url={https://arxiv.org/abs/2411.00062}, 
}
@inproceedings{lau2024dipperdiversitypromptsproducing,
      title={Dipper: Diversity in Prompts for Producing Large Language Model Ensembles in Reasoning tasks}, 
      author={Gregory Kang Ruey Lau and Wenyang Hu and Diwen Liu and Jizhuo Chen and See-Kiong Ng and Bryan Kian Hsiang Low},
      year={2024},
      eprint={2412.15238},
      booktitle={arXiv},
      url={https://arxiv.org/abs/2412.15238}, 
}
@inproceedings{ma2025nonmyopic,
    title={Non-myopic Generation of Language Models for Reasoning and Planning},
    author={Chang Ma and Haiteng Zhao and Junlei Zhang and Junxian He and Lingpeng Kong},
    booktitle={International Conference on Learning Representations},
    year={2025},
    url={https://openreview.net/forum?id=OoNazl6T7D}
}
@inproceedings{zhong2025britebootstrappingreinforcedthinking,
  title={BRiTE: Bootstrapping Reinforced Thinking Process to Enhance Language Model Reasoning}, 
  author={Han Zhong and Yutong Yin and Shenao Zhang and Xiaojun Xu and Yuanxin Liu and Yifei Zuo and Zhihan Liu and Boyi Liu and Sirui Zheng and Hongyi Guo and Liwei Wang and Mingyi Hong and Zhaoran Wang},
  year={2025},
  eprint={2501.18858},
  booktitle={arXiv},
  url={https://arxiv.org/abs/2501.18858}, 
}
@inproceedings{cheng2025sparselfplaytreesearchrefinement,
  title={SPaR: Self-Play with Tree-Search Refinement to Improve Instruction-Following in Large Language Models}, 
  author={Jiale Cheng and Xiao Liu and Cunxiang Wang and Xiaotao Gu and Yida Lu and Dan Zhang and Yuxiao Dong and Jie Tang and Hongning Wang and Minlie Huang},
  year={2025},
  eprint={2412.11605},
  booktitle={arXiv},
  url={https://arxiv.org/abs/2412.11605}, 
}
@inproceedings{kim2025neuralgeneticsearchdiscrete,
  title={Neural Genetic Search in Discrete Spaces}, 
  author={Hyeonah Kim and Sanghyeok Choi and Jiwoo Son and Jinkyoo Park and Changhyun Kwon},
  year={2025},
  eprint={2502.10433},
  booktitle={arXiv},
  url={https://arxiv.org/abs/2502.10433}, 
}
@article{qiu2024treebonenhancinginferencetimealignment,
  title={Treebon: Enhancing inference-time alignment with speculative tree-search and best-of-n sampling},
  author={Qiu, Jiahao and Lu, Yifu and Zeng, Yifan and Guo, Jiacheng and Geng, Jiayi and Wang, Huazheng and Huang, Kaixuan and Wu, Yue and Wang, Mengdi},
  journal={arXiv preprint arXiv:2410.16033},
  year={2024}
}
@inproceedings{lifshitz2025multiagent,
    title={Multi-Agent Verification: Scaling Test-Time Compute with Goal Verifiers},
    author={Shalev Lifshitz and Sheila A. McIlraith and Yilun Du},
    booktitle={Workshop on Reasoning and Planning for Large Language Models},
    year={2025},
    url={https://openreview.net/forum?id=H22e93wnMe}
}
@inproceedings{saha2025learningplanreason,
  title={Learning to Plan \& Reason for Evaluation with Thinking-LLM-as-a-Judge}, 
  author={Swarnadeep Saha and Xian Li and Marjan Ghazvininejad and Jason Weston and Tianlu Wang},
  year={2025},
  eprint={2501.18099},
  booktitle={arXiv},
  url={https://arxiv.org/abs/2501.18099}, 
}
@misc{sui2025metareasonerdynamicguidanceoptimized,
  title={Meta-Reasoner: Dynamic Guidance for Optimized Inference-time Reasoning in Large Language Models}, 
  author={Yuan Sui and Yufei He and Tri Cao and Simeng Han and Bryan Hooi},
  year={2025},
  eprint={2502.19918},
  booktitle={arXiv},
  url={https://arxiv.org/abs/2502.19918}, 
}
@ARTICLE{10460413,
  author={Hong, Ruixin and Pang, Xinyu and Zhang, Changshui},
  journal={Cybernetics and Intelligence}, 
  title={Advances in reasoning by prompting large language models: A survey}, 
  year={2024},
  pages={1-15},
}
@inproceedings{kang2024mindstarenhancingmathreasoning,
  title={MindStar: Enhancing Math Reasoning in Pre-trained LLMs at Inference Time}, 
  author={Jikun Kang and Xin Zhe Li and Xi Chen and Amirreza Kazemi and Qianyi Sun and Boxing Chen and Dong Li and Xu He and Quan He and Feng Wen and Jianye Hao and Jun Yao},
  year={2024},
  eprint={2405.16265},
  booktitle={arXiv},
  url={https://arxiv.org/abs/2405.16265}, 
}
@inproceedings{jin2025wellthinkingenhancingllm,
  title={"Well, Keep Thinking": Enhancing LLM Reasoning with Adaptive Injection Decoding}, 
  author={Hyunbin Jin and Je Won Yeom and Seunghyun Bae and Taesup Kim},
  year={2025},
  eprint={2503.10167},
  booktitle={arXiv},
  url={https://arxiv.org/abs/2503.10167}, 
}
@inproceedings{xu2025chaindraftthinkingfaster,
  title={Chain of Draft: Thinking Faster by Writing Less}, 
  author={Silei Xu and Wenhao Xie and Lingxiao Zhao and Pengcheng He},
  year={2025},
  eprint={2502.18600},
  booktitle={arXiv},
  url={https://arxiv.org/abs/2502.18600}, 
}
@inproceedings{parmar2025plangenmultiagentframeworkgenerating,
  title={PlanGEN: A Multi-Agent Framework for Generating Planning and Reasoning Trajectories for Complex Problem Solving}, 
  author={Mihir Parmar and Xin Liu and Palash Goyal and Yanfei Chen and Long Le and Swaroop Mishra and Hossein Mobahi and Jindong Gu and Zifeng Wang and Hootan Nakhost and Chitta Baral and Chen-Yu Lee and Tomas Pfister and Hamid Palangi},
  year={2025},
  eprint={2502.16111},
  booktitle={arXiv},
  url={https://arxiv.org/abs/2502.16111}, 
}
@inproceedings{mu2025planningheuristicsstrategicplanning,
  title={Planning of Heuristics: Strategic Planning on Large Language Models with Monte Carlo Tree Search for Automating Heuristic Optimization}, 
  author={Chaoxu Mu and Xufeng Zhang and Hui Wang},
  year={2025},
  eprint={2502.11422},
  booktitle={arXiv},
  url={https://arxiv.org/abs/2502.11422}, 
}
@inproceedings{puri2025probabilisticinferenceapproachinferencetime,
  title={A Probabilistic Inference Approach to Inference-Time Scaling of LLMs using Particle-Based Monte Carlo Methods}, 
  author={Isha Puri and Shivchander Sudalairaj and Guangxuan Xu and Kai Xu and Akash Srivastava},
  year={2025},
  eprint={2502.01618},
  booktitle={arXiv},
  url={https://arxiv.org/abs/2502.01618}, 
}
@inproceedings{saadfalcon2024archonarchitecturesearchframework,
  title={Archon: An Architecture Search Framework for Inference-Time Techniques}, 
  author={Jon Saad-Falcon and Adrian Gamarra Lafuente and Shlok Natarajan and Nahum Maru and Hristo Todorov and Etash Guha and E. Kelly Buchanan and Mayee Chen and Neel Guha and Christopher Ré and Azalia Mirhoseini},
  year={2024},
  eprint={2409.15254},
  booktitle={arXiv},
  url={https://arxiv.org/abs/2409.15254}, 
}
@inproceedings{wu2025inferencescalinglawsempirical,
  title={Inference scaling laws: An empirical analysis of compute-optimal inference for LLM problem-solving},
  author={Wu, Yangzhen and Sun, Zhiqing and Li, Shanda and Welleck, Sean and Yang, Yiming},
  booktitle={The Thirteenth International Conference on Learning Representations},
  year={2025},
  url={https://openreview.net/forum?id=VNckp7JEHn}
}
@inproceedings{misaki2025widerdeeperscalingllm,
  title={Wider or Deeper? Scaling LLM Inference-Time Compute with Adaptive Branching Tree Search}, 
  author={Kou Misaki and Yuichi Inoue and Yuki Imajuku and So Kuroki and Taishi Nakamura and Takuya Akiba},
  year={2025},
  eprint={2503.04412},
  booktitle={arXiv},
  url={https://arxiv.org/abs/2503.04412}, 
}
@inproceedings{singh2025selfevolvedpreferenceoptimizationenhancing,
  title={Self-Evolved Preference Optimization for Enhancing Mathematical Reasoning in Small Language Models}, 
  author={Joykirat Singh and Tanmoy Chakraborty and Akshay Nambi},
  year={2025},
  eprint={2503.04813},
  booktitle={arXiv},
  url={https://arxiv.org/abs/2503.04813}, 
}
@inproceedings{liu2025pairjudgermperformbestofn,
  title={PairJudge RM: Perform Best-of-N Sampling with Knockout Tournament}, 
  author={Yantao Liu and Zijun Yao and Rui Min and Yixin Cao and Lei Hou and Juanzi Li},
  year={2025},
  eprint={2501.13007},
  booktitle={arXiv},
  url={https://arxiv.org/abs/2501.13007}, 
}
@inproceedings{gao2024llmcriticshelpcatch,
  title={LLM Critics Help Catch Bugs in Mathematics: Towards a Better Mathematical Verifier with Natural Language Feedback}, 
  author={Bofei Gao and Zefan Cai and Runxin Xu and Peiyi Wang and Ce Zheng and Runji Lin and Keming Lu and Dayiheng Liu and Chang Zhou and Wen Xiao and Junjie Hu and Tianyu Liu and Baobao Chang},
  year={2024},
  eprint={2406.14024},
  booktitle={arXiv},
  url={https://arxiv.org/abs/2406.14024}, 
}
@inproceedings{li2025learningreasonfeedbacktesttime,
  title={Learning to Reason from Feedback at Test-Time}, 
  author={Yanyang Li and Michael Lyu and Liwei Wang},
  year={2025},
  eprint={2502.15771},
  booktitle={arXiv},
  url={https://arxiv.org/abs/2502.15771}, 
}
@inproceedings{mcaleese2024llmcriticshelpcatch,
  title={LLM Critics Help Catch LLM Bugs}, 
  author={Nat McAleese and Rai Michael Pokorny and Juan Felipe Ceron Uribe and Evgenia Nitishinskaya and Maja Trebacz and Jan Leike},
  year={2024},
  eprint={2407.00215},
  booktitle={arXiv},
  url={https://arxiv.org/abs/2407.00215}, 
}
@inproceedings{NEURIPS2023_91f18a12,
 author = {Zheng, Lianmin and Chiang, Wei-Lin and Sheng, Ying and Zhuang, Siyuan and Wu, Zhanghao and Zhuang, Yonghao and Lin, Zi and Li, Zhuohan and Li, Dacheng and Xing, Eric and Zhang, Hao and Gonzalez, Joseph E and Stoica, Ion},
 booktitle = {Advances in Neural Information Processing Systems},
 pages = {46595--46623},
 title = {Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena},
 volume = {36},
 year = {2023}
}
@inproceedings{zhang2025reviseval,
    title={RevisEval: Improving {LLM}-as-a-Judge via Response-Adapted References},
    author={Qiyuan Zhang and Yufei Wang and Tiezheng YU and Yuxin Jiang and Chuhan Wu and Liangyou Li and Yasheng Wang and Xin Jiang and Lifeng Shang and Ruiming Tang and Fuyuan Lyu and Chen Ma},
    booktitle={International Conference on Learning Representations},
    year={2025},
    url={https://openreview.net/forum?id=1tBvzOYTLF}
}
@inproceedings{xu2023instructscore,
    title={{INSTRUCTSCORE}: Towards Explainable Text Generation Evaluation with Automatic Feedback},
    author={Wenda Xu and Danqing Wang and Liangming Pan and Zhenqiao Song and Markus Freitag and William Yang Wang and Lei Li},
    booktitle={Conference on Empirical Methods in Natural Language Processing},
    year={2023},
    url={https://openreview.net/forum?id=eaUi1mcvrM}
}
@inproceedings{liu2023gevalnlgevaluationusing,
  title={G-Eval: NLG Evaluation using GPT-4 with Better Human Alignment}, 
  author={Yang Liu and Dan Iter and Yichong Xu and Shuohang Wang and Ruochen Xu and Chenguang Zhu},
  year={2023},
  eprint={2303.16634},
  booktitle={arXiv},
  url={https://arxiv.org/abs/2303.16634}, 
}
@inproceedings{jiang2024tigerscorebuildingexplainablemetric,
  title={TIGERScore: Towards Building Explainable Metric for All Text Generation Tasks}, 
  author={Dongfu Jiang and Yishan Li and Ge Zhang and Wenhao Huang and Bill Yuchen Lin and Wenhu Chen},
  year={2024},
  eprint={2310.00752},
  booktitle={arXiv},
  url={https://arxiv.org/abs/2310.00752}, 
}
@inproceedings{lambert2024rewardbenchevaluatingrewardmodels,
  title={RewardBench: Evaluating Reward Models for Language Modeling}, 
  author={Nathan Lambert and Valentina Pyatkin and Jacob Morrison and LJ Miranda and Bill Yuchen Lin and Khyathi Chandu and Nouha Dziri and Sachin Kumar and Tom Zick and Yejin Choi and Noah A. Smith and Hannaneh Hajishirzi},
  year={2024},
  eprint={2403.13787},
  booktitle={arXiv},
  url={https://arxiv.org/abs/2403.13787}, 
}
@inproceedings{wettig2024quratingselectinghighqualitydata,
  title={QuRating: Selecting High-Quality Data for Training Language Models}, 
  author={Alexander Wettig and Aatmik Gupta and Saumya Malik and Danqi Chen},
  year={2024},
  eprint={2402.09739},
  booktitle={arXiv},
  url={https://arxiv.org/abs/2402.09739}, 
}
@inproceedings{zhao2024marcoo1openreasoningmodels,
  title={Marco-o1: Towards Open Reasoning Models for Open-Ended Solutions}, 
  author={Yu Zhao and Huifeng Yin and Bo Zeng and Hao Wang and Tianqi Shi and Chenyang Lyu and Longyue Wang and Weihua Luo and Kaifu Zhang},
  year={2024},
  eprint={2411.14405},
  booktitle={arXiv},
  url={https://arxiv.org/abs/2411.14405}, 
}
@inproceedings{li2024dnaevalenhancinglargelanguage,
  title={DnA-Eval: Enhancing Large Language Model Evaluation through Decomposition and Aggregation}, 
  author={Minzhi Li and Zhengyuan Liu and Shumin Deng and Shafiq Joty and Nancy F. Chen and Min-Yen Kan},
  year={2024},
  eprint={2405.15329},
  booktitle={arXiv},
  url={https://arxiv.org/abs/2405.15329}, 
}
@inproceedings{taubenfeld2025confidenceimprovesselfconsistencyllms,
  title={Confidence Improves Self-Consistency in LLMs}, 
  author={Amir Taubenfeld and Tom Sheffer and Eran Ofek and Amir Feder and Ariel Goldstein and Zorik Gekhman and Gal Yona},
  year={2025},
  eprint={2502.06233},
  booktitle={arXiv},
  url={https://arxiv.org/abs/2502.06233}, 
}
@inproceedings{wan2025reasoningawareselfconsistencyleveraging,
  title={Reasoning Aware Self-Consistency: Leveraging Reasoning Paths for Efficient LLM Sampling}, 
  author={Guangya Wan and Yuqi Wu and Jie Chen and Sheng Li},
  year={2025},
  eprint={2408.17017},
  booktitle={arXiv},
  url={https://arxiv.org/abs/2408.17017}, 
}
@inproceedings{mahmud2025enhancingllmcodegeneration,
  title={Enhancing LLM Code Generation with Ensembles: A Similarity-Based Selection Approach}, 
  author={Tarek Mahmud and Bin Duan and Corina Pasareanu and Guowei Yang},
  year={2025},
  eprint={2503.15838},
  booktitle={arXiv},
  url={https://arxiv.org/abs/2503.15838}, 
}
@inproceedings{wang2025malotmultiagentleanbasedlong,
  title={MA-LoT: Multi-Agent Lean-based Long Chain-of-Thought Reasoning enhances Formal Theorem Proving}, 
  author={Ruida Wang and Rui Pan and Yuxin Li and Jipeng Zhang and Yizhen Jia and Shizhe Diao and Renjie Pi and Junjie Hu and Tong Zhang},
  year={2025},
  eprint={2503.03205},
  booktitle={arXiv},
  url={https://arxiv.org/abs/2503.03205}, 
}
@inproceedings{wan2025mammrefinerecipeimprovingfaithfulness,
  title={MAMM-Refine: A Recipe for Improving Faithfulness in Generation with Multi-Agent Collaboration}, 
  author={David Wan and Justin Chih-Yao Chen and Elias Stengel-Eskin and Mohit Bansal},
  year={2025},
  eprint={2503.15272},
  booktitle={arXiv},
  url={https://arxiv.org/abs/2503.15272}, 
}
@inproceedings{wu2025hiddenstrengthdisagreementunraveling,
  title={The Hidden Strength of Disagreement: Unraveling the Consensus-Diversity Tradeoff in Adaptive Multi-Agent Systems}, 
  author={Zengqing Wu and Takayuki Ito},
  year={2025},
  eprint={2502.16565},
  booktitle={arXiv},
  url={https://arxiv.org/abs/2502.16565}, 
}
@inproceedings{wang2025talkstructurallyacthierarchically,
  title={Talk Structurally, Act Hierarchically: A Collaborative Framework for LLM Multi-Agent Systems}, 
  author={Zhao Wang and Sota Moriyama and Wei-Yao Wang and Briti Gangopadhyay and Shingo Takamatsu},
  year={2025},
  eprint={2502.11098},
  booktitle={arXiv},
  url={https://arxiv.org/abs/2502.11098}, 
}
@inproceedings{feng2024diverseagententropyquantifyingblackboxllm,
  title={DiverseAgentEntropy: Quantifying Black-Box LLM Uncertainty through Diverse Perspectives and Multi-Agent Interaction}, 
  author={Yu Feng and Phu Mon Htut and Zheng Qi and Wei Xiao and Manuel Mager and Nikolaos Pappas and Kishaloy Halder and Yang Li and Yassine Benajiba and Dan Roth},
  year={2024},
  eprint={2412.09572},
  booktitle={arXiv},
  url={https://arxiv.org/abs/2412.09572}, 
}
@inproceedings{chen2024reconcileroundtableconferenceimproves,
  title={ReConcile: Round-Table Conference Improves Reasoning via Consensus among Diverse LLMs}, 
  author={Justin Chih-Yao Chen and Swarnadeep Saha and Mohit Bansal},
  year={2024},
  eprint={2309.13007},
  booktitle={arXiv},
  url={https://arxiv.org/abs/2309.13007}, 
}
@inproceedings{ni2024nextteachinglargelanguage,
  title={NExT: Teaching Large Language Models to Reason about Code Execution}, 
  author={Ansong Ni and Miltiadis Allamanis and Arman Cohan and Yinlin Deng and Kensen Shi and Charles Sutton and Pengcheng Yin},
  year={2024},
  eprint={2404.14662},
  booktitle={arXiv},
  url={https://arxiv.org/abs/2404.14662}, 
}
@inproceedings{yang2024exploringunleashingpowerlarge,
  title={Exploring and Unleashing the Power of Large Language Models in Automated Code Translation}, 
  author={Zhen Yang and Fang Liu and Zhongxing Yu and Jacky Wai Keung and Jia Li and Shuo Liu and Yifan Hong and Xiaoxue Ma and Zhi Jin and Ge Li},
  year={2024},
  eprint={2404.14646},
  booktitle={arXiv},
  url={https://arxiv.org/abs/2404.14646}, 
}
@inproceedings{ni2023leverlearningverifylanguagetocode,
  title={LEVER: Learning to Verify Language-to-Code Generation with Execution}, 
  author={Ansong Ni and Srini Iyer and Dragomir Radev and Ves Stoyanov and Wen-tau Yih and Sida I. Wang and Xi Victoria Lin},
  year={2023},
  eprint={2302.08468},
  booktitle={arXiv},
  url={https://arxiv.org/abs/2302.08468}, 
}
@inproceedings{tian2025codehaluinvestigatingcodehallucinations,
  title={CodeHalu: Investigating Code Hallucinations in LLMs via Execution-based Verification}, 
  author={Yuchen Tian and Weixiang Yan and Qian Yang and Xuandong Zhao and Qian Chen and Wen Wang and Ziyang Luo and Lei Ma and Dawn Song},
  year={2025},
  eprint={2405.00253},
  booktitle={arXiv},
  url={https://arxiv.org/abs/2405.00253}, 
}
@inproceedings{wei2024longformfactualitylargelanguage,
  title={Long-form factuality in large language models}, 
  author={Jerry Wei and Chengrun Yang and Xinying Song and Yifeng Lu and Nathan Hu and Jie Huang and Dustin Tran and Daiyi Peng and Ruibo Liu and Da Huang and Cosmo Du and Quoc V. Le},
  year={2024},
  eprint={2403.18802},
  booktitle={arXiv},
  url={https://arxiv.org/abs/2403.18802}, 
}
@inproceedings{salemi2024searchenginemachinesunified,
  title={Towards a Search Engine for Machines: Unified Ranking for Multiple Retrieval-Augmented Large Language Models}, 
  author={Alireza Salemi and Hamed Zamani},
  year={2024},
  eprint={2405.00175},
  booktitle={arXiv},
  url={https://arxiv.org/abs/2405.00175}, 
}
@inproceedings{vladika2024improvinghealthquestionanswering,
  title={Improving Health Question Answering with Reliable and Time-Aware Evidence Retrieval},
  author={Vladika, Juraj and Matthes, Florian},
  booktitle={Findings of the Association for Computational Linguistics: NAACL 2024},
  pages={4752--4763},
  year={2024},
  url={https://aclanthology.org/2024.findings-naacl.295/}
}
@inproceedings{zhang2025lightthinkerthinkingstepbystepcompression,
  title={LightThinker: Thinking Step-by-Step Compression}, 
  author={Jintian Zhang and Yuqi Zhu and Mengshu Sun and Yujie Luo and Shuofei Qiao and Lun Du and Da Zheng and Huajun Chen and Ningyu Zhang},
  year={2025},
  eprint={2502.15589},
  booktitle={arXiv},
  url={https://arxiv.org/abs/2502.15589}, 
}
@inproceedings{asai2023selfraglearningretrievegenerate,
  title={Self-rag: Learning to retrieve, generate, and critique through self-reflection},
  author={Asai, Akari and Wu, Zeqiu and Wang, Yizhong and Sil, Avirup and Hajishirzi, Hannaneh},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2023},
  url={https://openreview.net/forum?id=hSyW5go0v8}
}
@inproceedings{huang2025efficienttesttimescalingselfcalibration,
  title={Efficient Test-Time Scaling via Self-Calibration}, 
  author={Chengsong Huang and Langlin Huang and Jixuan Leng and Jiacheng Liu and Jiaxin Huang},
  year={2025},
  eprint={2503.00031},
  booktitle={arXiv},
  url={https://arxiv.org/abs/2503.00031}, 
}
@inproceedings{peng2023checkfactstryagain,
  title={Check Your Facts and Try Again: Improving Large Language Models with External Knowledge and Automated Feedback}, 
  author={Baolin Peng and Michel Galley and Pengcheng He and Hao Cheng and Yujia Xie and Yu Hu and Qiuyuan Huang and Lars Liden and Zhou Yu and Weizhu Chen and Jianfeng Gao},
  year={2023},
  eprint={2302.12813},
  booktitle={arXiv},
  url={https://arxiv.org/abs/2302.12813}, 
}
@inproceedings{bai2022constitutionalaiharmlessnessai,
  title={Constitutional AI: Harmlessness from AI Feedback}, 
  author={Yuntao Bai and Saurav Kadavath and Sandipan Kundu and Amanda Askell and Jackson Kernion and Andy Jones and Anna Chen and Anna Goldie and Azalia Mirhoseini and Cameron McKinnon and Carol Chen and Catherine Olsson and Christopher Olah and Danny Hernandez and Dawn Drain and Deep Ganguli and Dustin Li and Eli Tran-Johnson and Ethan Perez and Jamie Kerr and Jared Mueller and Jeffrey Ladish and Joshua Landau and Kamal Ndousse and Kamile Lukosuite and Liane Lovitt and Michael Sellitto and Nelson Elhage and Nicholas Schiefer and Noemi Mercado and Nova DasSarma and Robert Lasenby and Robin Larson and Sam Ringer and Scott Johnston and Shauna Kravec and Sheer El Showk and Stanislav Fort and Tamera Lanham and Timothy Telleen-Lawton and Tom Conerly and Tom Henighan and Tristan Hume and Samuel R. Bowman and Zac Hatfield-Dodds and Ben Mann and Dario Amodei and Nicholas Joseph and Sam McCandlish and Tom Brown and Jared Kaplan},
  year={2022},
  eprint={2212.08073},
  booktitle={arXiv},
  url={https://arxiv.org/abs/2212.08073}, 
}
@inproceedings{NEURIPS2023_0764db11,
 title = {Principle-Driven Self-Alignment of Language Models from Scratch with Minimal Human Supervision},
 author = {Sun, Zhiqing and Shen, Yikang and Zhou, Qinhong and Zhang, Hongxin and Chen, Zhenfang and Cox, David and Yang, Yiming and Gan, Chuang},
 booktitle = {Advances in Neural Information Processing Systems},
 pages = {2511--2565},
 year = {2023}
}
@inproceedings{weber2024redpajamaopendatasettraining,
  title={RedPajama: an Open Dataset for Training Large Language Models}, 
  author={Maurice Weber and Daniel Fu and Quentin Anthony and Yonatan Oren and Shane Adams and Anton Alexandrov and Xiaozhong Lyu and Huu Nguyen and Xiaozhe Yao and Virginia Adams and Ben Athiwaratkun and Rahul Chalamala and Kezhen Chen and Max Ryabinin and Tri Dao and Percy Liang and Christopher Ré and Irina Rish and Ce Zhang},
  year={2024},
  eprint={2411.12372},
  booktitle={arXiv},
  url={https://arxiv.org/abs/2411.12372}, 
}
@inproceedings{sessa2024bondaligningllmsbestofn,
  title={BOND: Aligning LLMs with Best-of-N Distillation}, 
  author={Pier Giuseppe Sessa and Robert Dadashi and Léonard Hussenot and Johan Ferret and Nino Vieillard and Alexandre Ramé and Bobak Shariari and Sarah Perrin and Abe Friesen and Geoffrey Cideron and Sertan Girgin and Piotr Stanczyk and Andrea Michi and Danila Sinopalnikov and Sabela Ramos and Amélie Héliou and Aliaksei Severyn and Matt Hoffman and Nikola Momchev and Olivier Bachem},
  year={2024},
  eprint={2407.14622},
  booktitle={arXiv},
  url={https://arxiv.org/abs/2407.14622}, 
}
@inproceedings{li2025llmsgeneratebetteranswer,
  title={LLMs Can Generate a Better Answer by Aggregating Their Own Responses}, 
  author={Zichong Li and Xinyu Feng and Yuheng Cai and Zixuan Zhang and Tianyi Liu and Chen Liang and Weizhu Chen and Haoyu Wang and Tuo Zhao},
  year={2025},
  eprint={2503.04104},
  booktitle={arXiv},
  url={https://arxiv.org/abs/2503.04104}, 
}
@article{meng2024simpo,
  title={Simpo: Simple preference optimization with a reference-free reward},
  author={Meng, Yu and Xia, Mengzhou and Chen, Danqi},
  journal={Advances in Neural Information Processing Systems},
  volume={37},
  pages={124198--124235},
  year={2024}
}
@article{wu2024meta,
  title={Meta-rewarding language models: Self-improving alignment with llm-as-a-meta-judge},
  author={Wu, Tianhao and Yuan, Weizhe and Golovneva, Olga and Xu, Jing and Tian, Yuandong and Jiao, Jiantao and Weston, Jason and Sukhbaatar, Sainbayar},
  journal={arXiv preprint arXiv:2407.19594},
  year={2024}
}
@inproceedings{wu2024scaling,
    title={Scaling Inference Computation: Compute-Optimal Inference for Problem-Solving with Language Models},
    author={Yangzhen Wu and Zhiqing Sun and Shanda Li and Sean Welleck and Yiming Yang},
    booktitle={Workshop on Mathematical Reasoning and AI at NeurIPS'24},
    year={2024},
    url={https://openreview.net/forum?id=j7DZWSc8qu}
}
@article{welleck2024from,
    title={From Decoding to Meta-Generation: Inference-time Algorithms for Large Language Models},
    author={Sean Welleck and Amanda Bertsch and Matthew Finlayson and Hailey Schoelkopf and Alex Xie and Graham Neubig and Ilia Kulikov and Zaid Harchaoui},
    journal={Transactions on Machine Learning Research},
    issn={2835--8856},
    year={2024},
    url={https://openreview.net/forum?id=eskQMcIbMS},
    note={Survey Certification}
}
@inproceedings{ye2025limoreasoning,
    title={{LIMO}: Less is More for Reasoning}, 
    author={Yixin Ye and Zhen Huang and Yang Xiao and Ethan Chern and Shijie Xia and Pengfei Liu},
    year={2025},
    eprint={2502.03387},
    booktitle={arXiv},
    url={https://arxiv.org/abs/2502.03387}, 
}
@inproceedings{lightman2023let,
    title={Let's verify step by step},
    author={Lightman, Hunter and Kosaraju, Vineet and Burda, Yuri and Edwards, Harrison and Baker, Bowen and Lee, Teddy and Leike, Jan and Schulman, John and Sutskever, Ilya and Cobbe, Karl},
    booktitle={The Twelfth International Conference on Learning Representations},
    year={2023},
    url={https://openreview.net/forum?id=v8L0pN6EOi}
}
@inproceedings{wan2024alphazero,
    title={Alphazero-like tree-search can guide large language model decoding and training},
    author={Wan, Ziyu and Feng, Xidong and Wen, Muning and McAleer, Stephen Marcus and Wen, Ying and Zhang, Weinan and Wang, Jun},
    booktitle={Forty-first International Conference on Machine Learning},
    year={2024},
    url={https://openreview.net/forum?id=C4OpREezgj}
}
@inproceedings{chenalphamath,
    title={AlphaMath Almost Zero: Process Supervision without Process},
    author={Chen, Guoxin and Liao, Minpeng and Li, Chengxi and Fan, Kai},
    booktitle={The Thirty-eighth Annual Conference on Neural Information Processing Systems},
    year={2024},
    url={https://openreview.net/forum?id=VaXnxQ3UKo}
}
@article{li2025system,
    title={From System 1 to System 2: A Survey of Reasoning Large Language Models},
    author={Li, Zhong-Zhi and Zhang, Duzhen and Zhang, Ming-Liang and Zhang, Jiaxin and Liu, Zengyan and Yao, Yuxuan and Xu, Haotian and Zheng, Junhao and Wang, Pei-Jie and Chen, Xiuyi and others},
    journal={arXiv preprint arXiv:2502.17419},
    year={2025},
    url={https://arxiv.org/abs/2502.17419}, 
}
@article{ji2025test,
    title={Test-time Computing: from System-1 Thinking to System-2 Thinking},
    author={Ji, Yixin and Li, Juntao and Ye, Hai and Wu, Kaixin and Xu, Jia and Mo, Linjian and Zhang, Min},
    journal={arXiv preprint arXiv:2501.02497},
    year={2025},
    url={https://arxiv.org/abs/2501.02497}, 
}
@inproceedings{zhang2024collaborative,
    title={Collaborative Performance Prediction for Large Language Models},
    author={Zhang, Qiyuan and Lyu, Fuyuan and Liu, Xue and Ma, Chen},
    booktitle={Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing},
    pages={2576--2596},
    year={2024},
    url={https://aclanthology.org/2024.emnlp-main.150/}
}
@inproceedings{yu2024ovm,
  title={OVM, Outcome-supervised Value Models for Planning in Mathematical Reasoning},
  author={Yu, Fei and Gao, Anningzhe and Wang, Benyou},
  booktitle={Findings of the Association for Computational Linguistics: NAACL 2024},
  pages={858--875},
  year={2024},
  url={https://aclanthology.org/2024.findings-naacl.55/}
}
@inproceedings{ahmadian2024back,
  title={Back to Basics: Revisiting REINFORCE-Style Optimization for Learning from Human Feedback in LLMs},
  author={Ahmadian, Arash and Cremer, Chris and Gall{\'e}, Matthias and Fadaee, Marzieh and Kreutzer, Julia and Pietquin, Olivier and {\"U}st{\"u}n, Ahmet and Hooker, Sara},
  booktitle={Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={12248--12267},
  year={2024},
  url={https://aclanthology.org/2024.acl-long.662/}
}
@inproceedings{chaffin2022ppl,
  title={PPL-MCTS: Constrained Textual Generation Through Discriminator-Guided MCTS Decoding},
  author={Chaffin, Antoine and Claveau, Vincent and Kijak, Ewa},
  booktitle={NAACL 2022-Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies},
  pages={1--15},
  year={2022},
  url={https://aclanthology.org/2022.naacl-main.215/}
}
@inproceedings{coulom2006efficient,
  title={Efficient selectivity and backup operators in Monte-Carlo tree search},
  author={Coulom, R{\'e}mi},
  booktitle={International conference on computers and games},
  pages={72--83},
  year={2006},
  organization={Springer}
}
@article{chen2023program,
  title={Program of Thoughts Prompting: Disentangling Computation from Reasoning for Numerical Reasoning Tasks},
  author={Chen, Wenhu and Ma, Xueguang and Wang, Xinyi and Cohen, William W},
  journal={Transactions on Machine Learning Research},
  year={2023},
  url={https://openreview.net/forum?id=YfZ4ZPt8zd}
}
@inproceedings{liu2023plan,
  title={Plan, Verify and Switch: Integrated Reasoning with Diverse X-of-Thoughts},
  author={Liu, Tengxiao and Guo, Qipeng and Yang, Yuqing and Hu, Xiangkun and Zhang, Yue and Qiu, Xipeng and Zhang, Zheng},
  booktitle={Conference on Empirical Methods in Natural Language Processing},
  year={2023},
  url={https://aclanthology.org/2023.emnlp-main.169/}
}
@inproceedings{zeng2024mrben,
    title={{MR}-Ben: A Meta-Reasoning Benchmark for Evaluating System-2 Thinking in {LLM}s},
    author={Zhongshen Zeng and Yinhong Liu and Yingjia Wan and Jingyao Li and Pengguang Chen and Jianbo Dai and Yuxuan Yao and Rongwu Xu and Zehan Qi and Wanru Zhao and Linling Shen and Jianqiao Lu and Haochen Tan and Yukang Chen and Hao Zhang and Zhan Shi and Bailin Wang and Zhijiang Guo and Jiaya Jia},
    booktitle={Conference on Neural Information Processing Systems},
    year={2024},
    url={https://openreview.net/forum?id=GN2qbxZlni}
}
@inproceedings{chen2025benchmarkinglargelanguagemodels,
  title={Benchmarking Large Language Models on Answering and Explaining Challenging Medical Questions}, 
  author={Hanjie Chen and Zhouxiang Fang and Yash Singla and Mark Dredze},
  year={2025},
  eprint={2402.18060},
  booktitle={arXiv},
  url={https://arxiv.org/abs/2402.18060}, 
}
@inproceedings{jin2020diseasedoespatienthave,
  title={What Disease does this Patient Have? A Large-scale Open Domain Question Answering Dataset from Medical Exams}, 
  author={Di Jin and Eileen Pan and Nassim Oufattole and Wei-Hung Weng and Hanyi Fang and Peter Szolovits},
  year={2020},
  eprint={2009.13081},
  booktitle={arXiv},
  url={https://arxiv.org/abs/2009.13081}, 
}
@inproceedings{yao2023webshop,
  title={WebShop: Towards Scalable Real-World Web Interaction with Grounded Language Agents}, 
  author={Shunyu Yao and Howard Chen and John Yang and Karthik Narasimhan},
  year={2023},
  eprint={2207.01206},
  booktitle={arXiv},
  url={https://arxiv.org/abs/2207.01206}, 
}
@article{zhou2023webarena,
  title={WebArena: A Realistic Web Environment for Building Autonomous Agents},
  author={Zhou, Shuyan and Xu, Frank F and Zhu, Hao and Zhou, Xuhui and Lo, Robert and Sridhar, Abishek and Cheng, Xianyi and Bisk, Yonatan and Fried, Daniel and Alon, Uri and others},
  journal={arXiv preprint arXiv:2307.13854},
  url={https://webarena.dev},
  year={2023}
}
@inproceedings{wang2023selfconsistencyimproveschainthought,
  title={Self-Consistency Improves Chain of Thought Reasoning in Language Models},
  author={Wang, Xuezhi and Wei, Jason and Schuurmans, Dale and Le, Quoc V and Chi, Ed H and Narang, Sharan and Chowdhery, Aakanksha and Zhou, Denny},
  booktitle={The Eleventh International Conference on Learning Representations},
  year={2023},
  url={https://openreview.net/forum?id=1PL1NIMMrw}, 
}
@inproceedings{wang2022sciworld,
  title={ScienceWorld: Is your Agent Smarter than a 5th Grader?},
  author={Wang, Ruoyao and Jansen, Peter and C{\^o}t{\'e}, Marc-Alexandre and Ammanabrolu, Prithviraj},
  booktitle={Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing},
  pages={11279--11298},
  year={2022},
  url={https://aclanthology.org/2022.emnlp-main.775/}
}
@inproceedings{prasad2024adaptasneededdecompositionplanning,
  title={ADaPT: As-Needed Decomposition and Planning with Language Models},
  author={Prasad, Archiki and Koller, Alexander and Hartmann, Mareike and Clark, Peter and Sabharwal, Ashish and Bansal, Mohit and Khot, Tushar},
  booktitle={Findings of the Association for Computational Linguistics: NAACL 2024},
  pages={4226--4252},
  year={2024},
  url={https://aclanthology.org/2024.findings-naacl.264/}
}
@inproceedings{wang2025thoughtsplaceunderthinkingo1like,
  title={Thoughts Are All Over the Place: On the Underthinking of o1-Like LLMs}, 
  author={Yue Wang and Qiuzhi Liu and Jiahao Xu and Tian Liang and Xingyu Chen and Zhiwei He and Linfeng Song and Dian Yu and Juntao Li and Zhuosheng Zhang and Rui Wang and Zhaopeng Tu and Haitao Mi and Dong Yu},
  year={2025},
  eprint={2501.18585},
  booktitle={arXiv},
  url={https://arxiv.org/abs/2501.18585}, 
}
@inproceedings{xu2025softcotsoftchainofthoughtefficient,
  title={SoftCoT: Soft Chain-of-Thought for Efficient Reasoning with LLMs}, 
  author={Yige Xu and Xu Guo and Zhiwei Zeng and Chunyan Miao},
  year={2025},
  eprint={2502.12134},
  booktitle={arXiv},
  url={https://arxiv.org/abs/2502.12134}, 
}
@inproceedings{wang2025makepennycountdifficultyadaptive,
  title={Make Every Penny Count: Difficulty-Adaptive Self-Consistency for Cost-Efficient Reasoning}, 
  author={Xinglin Wang and Shaoxiong Feng and Yiwei Li and Peiwen Yuan and Yueqi Zhang and Chuyi Tan and Boyuan Pan and Yao Hu and Kan Li},
  year={2025},
  eprint={2408.13457},
  booktitle={arXiv},
  url={https://arxiv.org/abs/2408.13457}, 
}
@inproceedings{hooper2025etsefficienttreesearch,
  title={ETS: Efficient Tree Search for Inference-Time Scaling}, 
  author={Coleman Hooper and Sehoon Kim and Suhong Moon and Kerem Dilmen and Monishwaran Maheswaran and Nicholas Lee and Michael W. Mahoney and Sophia Shao and Kurt Keutzer and Amir Gholami},
  year={2025},
  eprint={2502.13575},
  booktitle={arXiv},
  url={https://arxiv.org/abs/2502.13575}, 
}
@inproceedings{aytes2025sketchofthoughtefficientllmreasoning,
  title={Sketch-of-Thought: Efficient LLM Reasoning with Adaptive Cognitive-Inspired Sketching}, 
  author={Simon A. Aytes and Jinheon Baek and Sung Ju Hwang},
  year={2025},
  eprint={2503.05179},
  booktitle={arXiv},
  url={https://arxiv.org/abs/2503.05179}, 
}
@inproceedings{li2025cmmath,
    title = {{CMM}a{TH}: A {C}hinese Multi-modal Math Skill Evaluation Benchmark for Foundation Models},
    author = {Li, Zhongzhi  and
      Zhang, Ming-Liang  and
      Wang, Pei-Jie  and
      Xu, Jian  and
      Zhang, Rui-Song  and
      Fei, Yin  and
      Ji, Zhi-Long  and
      Bai, Jin-Feng  and
      Pan, Zhen-Ru  and
      Zhang, Jiaxin  and
      Liu, Cheng-Lin},
    booktitle = {International Conference on Computational Linguistics},
    year = {2025},
    pages = {2690--2726},
}
@inproceedings{zhang2023multimodalneuralgeometricsolver,
  title={A multi-modal neural geometric solver with textual clauses parsed from diagram},
  author={Zhang, Ming-Liang and Yin, Fei and Liu, Cheng-Lin},
  booktitle={Proceedings of the Thirty-Second International Joint Conference on Artificial Intelligence},
  pages={3374--3382},
  year={2023},
  url={https://www.ijcai.org/proceedings/2023/0376.pdf}
}
@misc{beenching2024scaling,
    title = {Scaling test-time compute with open models},
    year = {2024},
    url = {https://huggingface.co/spaces/HuggingFaceH4/blogpost-scaling-test-time-compute},
    author = {Edward Beeching, Lewis Tunstall, Sasha Rush},
}
@inproceedings{zhai2024finetuninglargevisionlanguagemodels,
  title={Fine-Tuning Large Vision-Language Models as Decision-Making Agents via Reinforcement Learning}, 
  author={Yuexiang Zhai and Hao Bai and Zipeng Lin and Jiayi Pan and Shengbang Tong and Yifei Zhou and Alane Suhr and Saining Xie and Yann LeCun and Yi Ma and Sergey Levine},
  year={2024},
  eprint={2405.10292},
  booktitle={arXiv},
  url={https://arxiv.org/abs/2405.10292}, 
}
@inproceedings{xie2024travelplannerbenchmarkrealworldplanning,
  title={TravelPlanner: A Benchmark for Real-World Planning with Language Agents},
  author={Xie, Jian and Zhang, Kai and Chen, Jiangjie and Zhu, Tinghui and Lou, Renze and Tian, Yuandong and Xiao, Yanghua and Su, Yu},
  booktitle={International Conference on Machine Learning},
  pages={54590--54613},
  year={2024},
  organization={PMLR}
}
@inproceedings{zheng2024naturalplanbenchmarkingllms,
  title={NATURAL PLAN: Benchmarking LLMs on Natural Language Planning}, 
  author={Huaixiu Steven Zheng and Swaroop Mishra and Hugh Zhang and Xinyun Chen and Minmin Chen and Azade Nova and Le Hou and Heng-Tze Cheng and Quoc V. Le and Ed H. Chi and Denny Zhou},
  year={2024},
  eprint={2406.04520},
  booktitle={arXiv},
  url={https://arxiv.org/abs/2406.04520}, 
}
@inproceedings{nguyen2025codemmlu,
    title={Code{MMLU}: A Multi-Task Benchmark for Assessing Code Understanding \& Reasoning Capabilities of Code{LLM}s},
    author={Dung Manh Nguyen and Thang Chau Phan and Nam Le Hai and Tien-Thong Doan and Nam V. Nguyen and Quang Pham and Nghi D. Q. Bui},
    booktitle={International Conference on Learning Representations},
    year={2025},
    url={https://openreview.net/forum?id=CahIEKCu5Q}
}
@inproceedings{liu2024codemindframeworkchallengelarge,
  title={CodeMind: A Framework to Challenge Large Language Models for Code Reasoning}, 
  author={Changshu Liu and Shizhuo Dylan Zhang and Ali Reza Ibrahimzada and Reyhaneh Jabbarvand},
  year={2024},
  eprint={2402.09664},
  booktitle={arXiv},
  url={https://arxiv.org/abs/2402.09664}, 
}

@inproceedings{li2024cmmlumeasuringmassivemultitask,
  title={CMMLU: Measuring massive multitask language understanding in Chinese}, 
  author={Haonan Li and Yixuan Zhang and Fajri Koto and Yifei Yang and Hai Zhao and Yeyun Gong and Nan Duan and Timothy Baldwin},
  year={2024},
  eprint={2306.09212},
  booktitle={arXiv},
  url={https://arxiv.org/abs/2306.09212}, 
}
@inproceedings{bai2024longbenchbilingualmultitaskbenchmark,
  title={LongBench: A Bilingual, Multitask Benchmark for Long Context Understanding}, 
  author={Yushi Bai and Xin Lv and Jiajie Zhang and Hongchang Lyu and Jiankai Tang and Zhidian Huang and Zhengxiao Du and Xiao Liu and Aohan Zeng and Lei Hou and Yuxiao Dong and Jie Tang and Juanzi Li},
  year={2024},
  eprint={2308.14508},
  booktitle={arXiv},
  url={https://arxiv.org/abs/2308.14508}, 
}
@inproceedings{chollet2019measureintelligence,
  title={On the Measure of Intelligence}, 
  author={François Chollet},
  eprint={1911.01547},
  booktitle={arXiv},
  year={2019},
  url={https://arxiv.org/abs/1911.01547}, 
}
@inproceedings{yao2024taubenchbenchmarktoolagentuserinteraction,
  title={$\tau$-bench: A Benchmark for Tool-Agent-User Interaction in Real-World Domains}, 
  author={Shunyu Yao and Noah Shinn and Pedram Razavi and Karthik Narasimhan},
  year={2024},
  eprint={2406.12045},
  booktitle={arXiv},
  url={https://arxiv.org/abs/2406.12045}, 
}
@misc{berkeley-function-calling-leaderboard,
  title={Berkeley Function Calling Leaderboard},
  author={Fanjia Yan and Huanzhi Mao and Charlie Cheng-Jie Ji and Tianjun Zhang and Shishir G. Patil and Ion Stoica and Joseph E. Gonzalez},
  year={2024},
  howpublished={\url{https://gorilla.cs.berkeley.edu/blogs/8_berkeley_function_calling_leaderboard.html}},
}
@inproceedings{he2024webvoyagerbuildingendtoendweb,
  title={WebVoyager: Building an End-to-End Web Agent with Large Multimodal Models}, 
  author={Hongliang He and Wenlin Yao and Kaixin Ma and Wenhao Yu and Yong Dai and Hongming Zhang and Zhenzhong Lan and Dong Yu},
  year={2024},
  eprint={2401.13919},
  booktitle={arXiv},
  url={https://arxiv.org/abs/2401.13919}, 
}
@inproceedings{jiang2024followbenchmultilevelfinegrainedconstraints,
  title={FollowBench: A Multi-level Fine-grained Constraints Following Benchmark for Large Language Models}, 
  author={Yuxin Jiang and Yufei Wang and Xingshan Zeng and Wanjun Zhong and Liangyou Li and Fei Mi and Lifeng Shang and Xin Jiang and Qun Liu and Wei Wang},
  year={2024},
  eprint={2310.20410},
  booktitle={arXiv},
  url={https://arxiv.org/abs/2310.20410}, 
}
@inproceedings{wen2024benchmarking,
    title={Benchmarking Complex Instruction-Following with Multiple Constraints Composition},
    author={Bosi Wen and Pei Ke and Xiaotao Gu and Lindong Wu and Hao Huang and Jinfeng Zhou and Wenchuang Li and Binxin Hu and Wendy Gao and Jiaxing Xu and Yiming Liu and Jie Tang and Hongning Wang and Minlie Huang},
    booktitle={Conference on Neural Information Processing Systems Datasets and Benchmarks Track},
    year={2024},
    url={https://openreview.net/forum?id=U2aVNDrZGx}
}
@inproceedings{sel2024algorithm,
  title={Algorithm of Thoughts: Enhancing Exploration of Ideas in Large Language Models},
  author={Sel, Bilgehan and Tawaha, Ahmad and Khattar, Vanshaj and Jia, Ruoxi and Jin, Ming},
  booktitle={International Conference on Machine Learning},
  pages={44136--44189},
  year={2024},
  organization={PMLR}
}
@article{yuan2025s,
  title={What's Behind PPO's Collapse in Long-CoT? Value Optimization Holds the Secret},
  author={Yuan, Yufeng and Yue, Yu and Zhu, Ruofei and Fan, Tiantian and Yan, Lin},
  journal={arXiv preprint arXiv:2503.01491},
  year={2025},
  url={https://arxiv.org/abs/2503.01491}
}
@article{wen2025lightxi,
  title={Light-r1: Curriculum sft, dpo and rl for long cot from scratch and beyond},
  author={Wen, Liang and Cai, Yunke and Xiao, Fenrui and He, Xin and An, Qi and Duan, Zhenyu and Du, Yimin and Liu, Junchen and Tang, Lifu and Lv, Xiaowei and others},
  journal={arXiv preprint arXiv:2503.10460},
  year={2025},
  url={https://arxiv.org/abs/2503.10460}
}
@article{yu2025dapo,
  title={DAPO: An Open-Source LLM Reinforcement Learning System at Scale},
  author={Yu, Qiying and Zhang, Zheng and Zhu, Ruofei and Yuan, Yufeng and Zuo, Xiaochen and Yue, Yu and Fan, Tiantian and Liu, Gaohong and Liu, Lingjun and Liu, Xin and others},
  journal={arXiv preprint arXiv:2503.14476},
  year={2025},
  URL={https://arxiv.org/abs/2503.14476}
}
@article{zeng2025simplerlzoo,
  title={SimpleRL-Zoo: Investigating and Taming Zero Reinforcement Learning for Open Base Models in the Wild},
  author={Zeng, Weihao and Huang, Yuzhen and Liu, Qian and Liu, Wei and He, Keqing and Ma, Zejun and He, Junxian},
  journal={arXiv preprint arXiv:2503.18892},
  url={https://arxiv.org/abs/2503.18892},
  year={2025}
}
@misc{areal2025,
  author = {AntResearch-RL-Lab},
  title = {AReaL: Ant Reasoning RL},
  year = {2025},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/inclusionAI/AReaL}},
}
@inproceedings{jin2024impact,
  title={The Impact of Reasoning Step Length on Large Language Models},
  author={Jin, Mingyu and Yu, Qinkai and Shu, Dong and Zhao, Haiyan and Hua, Wenyue and Meng, Yanda and Zhang, Yongfeng and Du, Mengnan},
  booktitle={Findings of the Association for Computational Linguistics ACL 2024},
  pages={1830--1842},
  year={2024},
  url={https://aclanthology.org/2024.findings-acl.108/}
}
@article{hao2024training,
  title={Training large language models to reason in a continuous latent space},
  author={Hao, Shibo and Sukhbaatar, Sainbayar and Su, DiJia and Li, Xian and Hu, Zhiting and Weston, Jason and Tian, Yuandong},
  journal={arXiv preprint arXiv:2412.06769},
  year={2024},
  url={https://arxiv.org/abs/2412.06769}
}
