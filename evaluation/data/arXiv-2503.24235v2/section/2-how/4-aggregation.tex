
\subsubsection{Aggregation}
\label{subsec:aggregation}
Aggregation techniques consolidate multiple solutions into a final decision to enhance the reliability and robustness of model predictions at test time. 
Based on how the final output is generated, we empirically categorize them into two key classes: (i) Selection, which selects the best-performed sample among all candidates, where the selection criteria may vary across different approaches; and (ii) Fusion, which fuse multiple samples into one though tricks like weighting or generation.

\paragraph{Selection} 
In this category, the aggregation process can be viewed as a selection problem. 
One well-known example is to select the most consistent answer, commonly known as \textit{self-consistency}. \citet{wang2023selfconsistency} improves accuracy by leveraging statistical redundancy—if different reasoning paths converge to the same conclusion, the answer is more likely to be correct. Self-consistency effectively reduces variance in model outputs and mitigates occasional hallucinations. However, as the final output is voted based on consistency, inaccurate and low-quality samples would inevitably influence the output quality. Therefore, various approaches are proposed to filter the candidates before voting. \citet{chen2024are} incorporates an LM as a filter, while \citet{wu2025lessunderstandingchainofthoughtlength} proposes a Length-filtered vote, where prediction uncertainty is adopted as a proxy to filter reliable CoT length. 

Best-of-N~\citep{irvine2023rewarding} follows the same process but replaces the self-consistency criteria with scalar scores generated by external verifiers. 
\citet{song2024good} further demonstrates that best-of-N on small LLMs can yield competitive performance against SOTA propriety models.
\citet{munkhbat2025selftrainingelicitsconcisereasoning} attaches a few-conditioning filtering before the best-of-N selection. This aims to alleviate its sample inefficiency and achieves significant length reduction.
Motivated by particle filtering, \citet{puri2025probabilisticinferenceapproachinferencetime} proposes to consider filtering upon the samples.
\citet{sessa2024bondaligningllmsbestofn} went one step further in reducing sample inefficiency. It tunes the best-of-N results into the LM via RLHF.
With the blooming of the agentic approach, \citet{parmar2025plangenmultiagentframeworkgenerating} proposes a selection agent considering complex factors with both historical and current status.
Apart from selecting samples from one single LM, \citet{ong2025routellm} views the selection of samples generated by weak and strong LLMs as a routing problem and proposes constraints on computation costs. 

\paragraph{Fusion}
Directly selecting the final output sample among candidates may yield unsatisfactory results, especially when the sample quality of candidates is low. Fusion approaches propose to merge multiple samples into one to solve such a problem.
\citet{brown2024large} and \citet{li2023making} extend the idea from Best-of-N and weigh each sample by its score from external verifiers.
\citet{jiang2023llm}, on the other hand, directly prompts another LLM as a summarizer to merge multiple selected samples.
\citet{li2025llmsgeneratebetteranswer} shares similar intuition by replacing the majority voting in self-consistency~\citep{wang-etal-2024-math} with generative self-aggregation.
\citet{li2025reasoningaslogicunitsscalingtesttimereasoning} also adopts LLM as the synthesizer, given the intermediate consideration in previous steps.


\begin{table}[!htbp]
    % \rowcolors{2}{gray!10}{white}
    \centering
    \resizebox{0.98\textwidth}{!}{
    \begin{tabular}{l|l|c|l|l}
    \hline
        \rowcolor{gray!10}
        Category & Approach & External Verifier & Approach Description & Also Utilized in \\
    \hline
        & Majority Voting~\citep{wang2023selfconsistency} & \xmark & Select the most common sample & \cite{chen2024are} \\
        & Best-of-N~\citep{irvine2023rewarding} & \cmark & Select the highest scored sample & \cite{song2024good} \\
        & Few-shot BoN~\citep{munkhbat2025selftrainingelicitsconcisereasoning} & \cmark & BoN with few-shot conditioning \\
        \multirow{-4}{*}{Selection}
        & Agentic~\citep{parmar2025plangenmultiagentframeworkgenerating} & \xmark & agent considering both current and previous status \\
    \hline
        \rowcolor{gray!10}
        & Weighted BoN~\citep{li2023making} & \cmark & Weight each sample by its score & \cite{brown2024large} \\
        \rowcolor{gray!10} 
        & Synthesize~\citep{jiang2023llm} & \xmark & Fuse the selected samples via GenAI & \cite{wang2025mixtureofagents,li2025reasoningaslogicunitsscalingtesttimereasoning} \\
        \rowcolor{gray!10} \multirow{-3}{*}{Fusion}
        & Ensemble Fusion~\citep{saadfalcon2024archonarchitecturesearchframework}& \xmark & Conduct ensemble before fusion & \\
    \hline
    \end{tabular}}
    \caption{Summary of Certain Aggregation Techniques. BoN stands for Best-of-N.}
    \label{tab:aggregation}
\end{table}


% Based on the sample to aggregate, these approaches can be categorized into two key classes and summarized in Table~\ref{tab:aggregation}.
% \paragraph{Self-Repetition} Instead of relying on a single reasoning trajectory, the model samples multiple independent CoTs from the sample basic LLM. One example is to select the most consistent answer, commonly known as \textit{self-consistency}~\citep{wang2023selfconsistency}. This approach improves accuracy by leveraging statistical redundancy—if different reasoning paths converge to the same conclusion, the answer is more likely to be correct. Self-consistency effectively reduces variance in model outputs and mitigates occasional hallucinations. Other methods, including Best-of-N~\citep{irvine2023rewarding} and its variants~\citep{brown2024large}, rely on external verifiers to score each sample and output the best-performed sample.

% \paragraph{Mixture of Models} Instead of relying on a single model, multiple models perform repeated sampling during the test-time scaling. This could further expand coverage and ensure a more comprehensive exploration of possible solutions, as different models tend to show different strengths on various tasks~\citep{jiang2023llm, zhang2024collaborative}. This paradigm enables diverse perspectives to contribute to the final answer, fostering a more reliable decision-making process.