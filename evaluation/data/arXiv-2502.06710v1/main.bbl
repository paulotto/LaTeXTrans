\begin{thebibliography}{41}
\providecommand{\natexlab}[1]{#1}

\bibitem[{Agostinelli et~al.(2023)Agostinelli, Denk, Borsos, Engel, Verzetti, Caillon, Huang, Jansen, Roberts, Tagliasacchi et~al.}]{agostinelli2023musiclm}
Andrea Agostinelli, Timo~I Denk, Zal{\'a}n Borsos, Jesse Engel, Mauro Verzetti, Antoine Caillon, Qingqing Huang, Aren Jansen, Adam Roberts, Marco Tagliasacchi, et~al. 2023.
\newblock Musiclm: Generating music from text.
\newblock \emph{arXiv preprint arXiv:2301.11325}.

\bibitem[{Antol et~al.(2015)Antol, Agrawal, Lu, Mitchell, Batra, Zitnick, and Parikh}]{antol2015vqa}
Stanislaw Antol, Aishwarya Agrawal, Jiasen Lu, Margaret Mitchell, Dhruv Batra, C~Lawrence Zitnick, and Devi Parikh. 2015.
\newblock Vqa: Visual question answering.
\newblock In \emph{International Conference on Computer Vision}.

\bibitem[{Chen et~al.(2020)Chen, Xie, Vedaldi, and Zisserman}]{9053174}
Honglie Chen, Weidi Xie, Andrea Vedaldi, and Andrew Zisserman. 2020.
\newblock Vggsound: A large-scale audio-visual dataset.
\newblock In \emph{International Conference on Acoustics, Speech and Signal Processing}.

\bibitem[{Chen et~al.(2022)Chen, Du, Zhu, Ma, Berg-Kirkpatrick, and Dubnov}]{chen2022hts}
Ke~Chen, Xingjian Du, Bilei Zhu, Zejun Ma, Taylor Berg-Kirkpatrick, and Shlomo Dubnov. 2022.
\newblock Hts-at: A hierarchical token-semantic audio transformer for sound classification and detection.
\newblock In \emph{International Conference on Acoustics, Speech and Signal Processing}.

\bibitem[{Copet et~al.(2024)Copet, Kreuk, Gat, Remez, Kant, Synnaeve, Adi, and D{\'e}fossez}]{copet2024simple}
Jade Copet, Felix Kreuk, Itai Gat, Tal Remez, David Kant, Gabriel Synnaeve, Yossi Adi, and Alexandre D{\'e}fossez. 2024.
\newblock Simple and controllable music generation.
\newblock In \emph{Advances in Neural Information Processing Systems}.

\bibitem[{Dai et~al.(2022)Dai, Yu, and Dannenberg}]{dai2022missing}
Shuqi Dai, Huiran Yu, and Roger~B Dannenberg. 2022.
\newblock What is missing in deep music generation? a study of repetition and structure in popular music.
\newblock \emph{arXiv preprint arXiv:2209.00182}.

\bibitem[{Diao et~al.(2023)Diao, Cheng, and Cheng}]{diao2023av}
Xingjian Diao, Ming Cheng, and Shitong Cheng. 2023.
\newblock Av-maskenhancer: Enhancing video representations through audio-visual masked autoencoder.
\newblock In \emph{International Conference on Tools with Artificial Intelligence}.

\bibitem[{Dosovitskiy et~al.(2021)Dosovitskiy, Beyer, Kolesnikov, Weissenborn, Zhai, Unterthiner, Dehghani, Minderer, Heigold, Gelly et~al.}]{dosovitskiy2020image}
Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, et~al. 2021.
\newblock An image is worth 16x16 words: Transformers for image recognition at scale.
\newblock In \emph{International Conference on Learning Representations}.

\bibitem[{Duan et~al.(2024)Duan, Xia, Mingze, Tang, Zhu, and Zhao}]{duan2024cross}
Haoyi Duan, Yan Xia, Zhou Mingze, Li~Tang, Jieming Zhu, and Zhou Zhao. 2024.
\newblock Cross-modal prompts: Adapting large pre-trained models for audio-visual downstream tasks.
\newblock In \emph{Advances in Neural Information Processing Systems}.

\bibitem[{Fayek and Johnson(2020)}]{fayek2020temporal}
Haytham~M. Fayek and Justin Johnson. 2020.
\newblock Temporal reasoning via audio question answering.
\newblock \emph{Transactions on Audio, Speech, and Language Processing}.

\bibitem[{Garcia et~al.(2020)Garcia, Otani, Chu, and Nakashima}]{garcia2020knowit}
Noa Garcia, Mayu Otani, Chenhui Chu, and Yuta Nakashima. 2020.
\newblock Knowit vqa: Answering knowledge-based questions about videos.
\newblock In \emph{AAAI Conference on Artificial Intelligence}.

\bibitem[{Huang et~al.(2024)Huang, Li, Yang, Shi, Chang, Ye, Wu, Hong, Huang, Liu et~al.}]{huang2024audiogpt}
Rongjie Huang, Mingze Li, Dongchao Yang, Jiatong Shi, Xuankai Chang, Zhenhui Ye, Yuning Wu, Zhiqing Hong, Jiawei Huang, Jinglin Liu, et~al. 2024.
\newblock Audiogpt: Understanding and generating speech, music, sound, and talking head.
\newblock In \emph{AAAI Conference on Artificial Intelligence}.

\bibitem[{Kingma and Ba(2015)}]{kingma2015adam}
Diederick~P Kingma and Jimmy Ba. 2015.
\newblock Adam: A method for stochastic optimization.
\newblock In \emph{International Conference on Learning Representations}.

\bibitem[{Kong et~al.(2023)Kong, Chen, Liu, Du, Berg-Kirkpatrick, Dubnov, and Plumbley}]{kong2023universal}
Qiuqiang Kong, Ke~Chen, Haohe Liu, Xingjian Du, Taylor Berg-Kirkpatrick, Shlomo Dubnov, and Mark~D. Plumbley. 2023.
\newblock Universal source separation with weakly labelled data.
\newblock \emph{arXiv preprint arXiv:2305.07447}.

\bibitem[{Lei et~al.(2018)Lei, Yu, Bansal, and Berg}]{lei2018tvqa}
Jie Lei, Licheng Yu, Mohit Bansal, and Tamara~L Berg. 2018.
\newblock Tvqa: Localized, compositional video question answering.
\newblock In \emph{Conference on Empirical Methods in Natural Language Processing}.

\bibitem[{Li et~al.(2023{\natexlab{a}})Li, Hou, and Hu}]{li2023progressive}
Guangyao Li, Wenxuan Hou, and Di~Hu. 2023{\natexlab{a}}.
\newblock Progressive spatio-temporal perception for audio-visual question answering.
\newblock In \emph{International Conference on Multimedia}.

\bibitem[{Li et~al.(2022)Li, Wei, Tian, Xu, Wen, and Hu}]{li2022learning}
Guangyao Li, Yake Wei, Yapeng Tian, Chenliang Xu, Ji-Rong Wen, and Di~Hu. 2022.
\newblock Learning to answer questions in dynamic audio-visual scenarios.
\newblock In \emph{Conference on Computer Vision and Pattern Recognition}.

\bibitem[{Li et~al.(2023{\natexlab{b}})Li, Xu, and Hu}]{li2023multi}
Guangyao Li, Yixin Xu, and Di~Hu. 2023{\natexlab{b}}.
\newblock Multi-scale attention for audio question answering.
\newblock In \emph{Annual Conference of the International Speech Communication Association}.

\bibitem[{Lin et~al.(2023)Lin, Sung, Lei, Bansal, and Bertasius}]{lin2023vision}
Yan-Bo Lin, Yi-Lin Sung, Jie Lei, Mohit Bansal, and Gedas Bertasius. 2023.
\newblock Vision transformers are parameter-efficient audio-visual learners.
\newblock In \emph{Conference on Computer Vision and Pattern Recognition}.

\bibitem[{Lipping et~al.(2022)Lipping, Sudarsanam, Drossos, and Virtanen}]{lipping2022clotho}
Samuel Lipping, Parthasaarathy Sudarsanam, Konstantinos Drossos, and Tuomas Virtanen. 2022.
\newblock Clotho-aqa: A crowdsourced dataset for audio question answering.
\newblock In \emph{European Signal Processing Conference}.

\bibitem[{Liu et~al.(2023)Liu, Xie, Gao, and Yu}]{liu2023parameter}
Hongye Liu, Xianhai Xie, Yang Gao, and Zhou Yu. 2023.
\newblock Parameter-efficient transfer learning for audio-visual-language tasks.
\newblock In \emph{International Conference on Multimedia}.

\bibitem[{Liu et~al.(2024)Liu, Dong, and Zhang}]{liu2024tackling}
Xiulong Liu, Zhikang Dong, and Peng Zhang. 2024.
\newblock Tackling data bias in music-avqa: Crafting a balanced dataset for unbiased question-answering.
\newblock In \emph{Winter Conference on Applications of Computer Vision}.

\bibitem[{Liu et~al.(2022)Liu, Hu, Lin, Yao, Xie, Wei, Ning, Cao, Zhang, Dong et~al.}]{liu2022swin}
Ze~Liu, Han Hu, Yutong Lin, Zhuliang Yao, Zhenda Xie, Yixuan Wei, Jia Ning, Yue Cao, Zheng Zhang, Li~Dong, et~al. 2022.
\newblock Swin transformer v2: Scaling up capacity and resolution.
\newblock In \emph{Conference on Computer Vision and Pattern Recognition}.

\bibitem[{Lu et~al.(2023)Lu, Xu, Kang, Yu, Xing, Tan, and Bian}]{lu2023musecoco}
Peiling Lu, Xin Xu, Chenfei Kang, Botao Yu, Chengyi Xing, Xu~Tan, and Jiang Bian. 2023.
\newblock Musecoco: Generating symbolic music from text.
\newblock \emph{arXiv preprint arXiv:2306.00110}.

\bibitem[{Ngiam et~al.(2011)Ngiam, Khosla, Kim, Nam, Lee, and Ng}]{ngiam2011multimodal}
Jiquan Ngiam, Aditya Khosla, Mingyu Kim, Juhan Nam, Honglak Lee, and Andrew~Y Ng. 2011.
\newblock Multimodal deep learning.
\newblock In \emph{International Conference on Machine Learning}.

\bibitem[{Ravi et~al.(2023)Ravi, Chinchure, Sigal, Liao, and Shwartz}]{ravi2023vlc}
Sahithya Ravi, Aditya Chinchure, Leonid Sigal, Renjie Liao, and Vered Shwartz. 2023.
\newblock Vlc-bert: visual question answering with contextualized commonsense knowledge.
\newblock In \emph{Winter Conference on Applications of Computer Vision}.

\bibitem[{Saito et~al.(2024)Saito, Sohn, Lee, and Ushiku}]{saito2024unsupervised}
Kuniaki Saito, Kihyuk Sohn, Chen-Yu Lee, and Yoshitaka Ushiku. 2024.
\newblock Unsupervised llm adaptation for question answering.
\newblock \emph{arXiv preprint arXiv:2402.12170}.

\bibitem[{Shen et~al.(2024)Shen, Song, Tan, Li, Lu, and Zhuang}]{shen2024hugginggpt}
Yongliang Shen, Kaitao Song, Xu~Tan, Dongsheng Li, Weiming Lu, and Yueting Zhuang. 2024.
\newblock Hugginggpt: Solving ai tasks with chatgpt and its friends in hugging face.
\newblock \emph{Advances in Neural Information Processing Systems}.

\bibitem[{Srivastava and Salakhutdinov(2012)}]{srivastava2012multimodal}
Nitish Srivastava and Russ~R. Salakhutdinov. 2012.
\newblock Multimodal learning with deep boltzmann machines.
\newblock In \emph{Advances in Neural Information Processing Systems}.

\bibitem[{Sudarsanam and Virtanen(2023)}]{sudarsanam2023attention}
Parthasaarathy Sudarsanam and Tuomas Virtanen. 2023.
\newblock Attention-based methods for audio question answering.
\newblock In \emph{European Signal Processing Conference}.

\bibitem[{Tian et~al.(2020)Tian, Li, and Xu}]{tian2020unified}
Yapeng Tian, Dingzeyu Li, and Chenliang Xu. 2020.
\newblock Unified multisensory perception: Weakly-supervised audio-visual video parsing.
\newblock In \emph{European Conference on Computer Vision}.

\bibitem[{Ultralytics(2023)}]{Ultralytics2023yolov8}
Ultralytics. 2023.
\newblock Yolov8.
\newblock \url{https://github.com/ultralytics/ultralytics}.
\newblock Accessed: 2023-05-26.

\bibitem[{Vaswani et~al.(2017)Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez, Kaiser, and Polosukhin}]{NIPS2017_3f5ee243}
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan~N Gomez, \L~ukasz Kaiser, and Illia Polosukhin. 2017.
\newblock Attention is all you need.
\newblock In \emph{Advances in Neural Information Processing Systems}.

\bibitem[{Wang et~al.(2024)Wang, Li, Huang, and Rahmani}]{wang2024healthq}
Ziyu Wang, Hao Li, Di~Huang, and Amir~M. Rahmani. 2024.
\newblock Healthq: Unveiling questioning capabilities of llm chains in healthcare conversations.
\newblock \emph{arXiv preprint arXiv:2409.19487}.

\bibitem[{Yang et~al.(2022)Yang, Wang, Duan, Chen, Hou, Jin, and Zhu}]{yang2022avqa}
Pinci Yang, Xin Wang, Xuguang Duan, Hong Chen, Runze Hou, Cong Jin, and Wenwu Zhu. 2022.
\newblock Avqa: A dataset for audio-visual question answering on videos.
\newblock In \emph{International Conference on Multimedia}.

\bibitem[{Yu et~al.(2024)Yu, Cho, Yadav, and Bansal}]{yu2024self}
Shoubin Yu, Jaemin Cho, Prateek Yadav, and Mohit Bansal. 2024.
\newblock Self-chained image-language model for video localization and question answering.
\newblock In \emph{Advances in Neural Information Processing Systems}.

\bibitem[{Yu et~al.(2019)Yu, Xu, Yu, Yu, Zhao, Zhuang, and Tao}]{yu2019activitynet}
Zhou Yu, Dejing Xu, Jun Yu, Ting Yu, Zhou Zhao, Yueting Zhuang, and Dacheng Tao. 2019.
\newblock Activitynet-qa: A dataset for understanding complex web videos via question answering.
\newblock In \emph{AAAI Conference on Artificial Intelligence}.

\bibitem[{Yun et~al.(2021)Yun, Yu, Yang, Lee, and Kim}]{yun2021pano}
Heeseung Yun, Youngjae Yu, Wonsuk Yang, Kangil Lee, and Gunhee Kim. 2021.
\newblock Pano-avqa: Grounded audio-visual question answering on 360deg videos.
\newblock In \emph{International Conference on Computer Vision}.

\bibitem[{Zhao et~al.(2019)Zhao, Gan, Ma, and Torralba}]{zhao2019sound}
Hang Zhao, Chuang Gan, Wei-Chiu Ma, and Antonio Torralba. 2019.
\newblock The sound of motions.
\newblock In \emph{International Conference on Computer Vision}.

\bibitem[{Zhao et~al.(2018)Zhao, Gan, Rouditchenko, Vondrick, McDermott, and Torralba}]{zhao2018sound}
Hang Zhao, Chuang Gan, Andrew Rouditchenko, Carl Vondrick, Josh McDermott, and Antonio Torralba. 2018.
\newblock The sound of pixels.
\newblock In \emph{European Conference on Computer Vision}.

\bibitem[{Zhuang et~al.(2023)Zhuang, Yu, Wang, Sun, and Zhang}]{zhuang2023toolqa}
Yuchen Zhuang, Yue Yu, Kuan Wang, Haotian Sun, and Chao Zhang. 2023.
\newblock Toolqa: A dataset for llm question answering with external tools.
\newblock \emph{Advances in Neural Information Processing Systems}.

\end{thebibliography}
